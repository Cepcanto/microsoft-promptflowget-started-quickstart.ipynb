name: promptflow-release-testing-matrix
on:
  workflow_call:
  workflow_dispatch:
    inputs:
      # can leave empty when trigger manually
      # GitHub Actions API for trigger does not return workflow run id
      # there we reference below Stack Overflow solution:
      # https://stackoverflow.com/a/69500478
      # which adds an identifier in workflow run jobs and can be used for filter
      id:
        description: Identifier for the workflow run
        required: false
        type: string
env:
  packageSetupType: promptflow_with_extra
  testWorkingDirectory: src/promptflow
jobs:
  id:
    runs-on: ubuntu-latest
    steps:
      - name: workflow run id - ${{ inputs.id }}
        run: |
          echo "workflow run id: ${{ inputs.id }}"
  all_tests:
    strategy:
      fail-fast: false
      matrix:
        os: [ubuntu-latest, macos-latest]
        testType: [sdk-cli, executor]
        pythonVersion: ['3.8', '3.9', '3.10', '3.11', '3.12']
    runs-on: ${{ matrix.os }}
    steps:
    - name: checkout
      uses: actions/checkout@v3
    - name: Display and Set Environment Variables
      run: |
        env | sort >> $GITHUB_OUTPUT
      shell: bash -el {0}
    - name: Conda Setup - ${{ matrix.os }} - Python Version ${{ matrix.pythonVersion }}
      uses: "./.github/actions/step_create_conda_environment"
      with:
        pythonVersion: ${{ matrix.pythonVersion }}
    - name: Build wheel
      uses: "./.github/actions/step_sdk_setup"
      with:
        setupType: ${{ env.packageSetupType }}
        scriptPath: ${{ env.testWorkingDirectory }}
    - name: Azure Login
      uses: azure/login@v1
      with:
        creds: ${{ secrets.AZURE_CREDENTIALS }}
    - name: Generate Configs
      uses: "./.github/actions/step_generate_configs"
      with:
        targetFolder: ${{ env.testWorkingDirectory }}
    - name: Get number of CPU cores
      uses: SimenB/github-actions-cpu-cores@v1
      id: cpu-cores
    - name: Run SDK CLI Test
      if : ${{ matrix.testType == 'sdk-cli' }}
      shell: bash -l {0}
      working-directory: ${{ env.testWorkingDirectory }}
      run: |-
        set -x -e
        export IS_IN_CI_PIPELINE="true"
        az account show
        conda activate release-env
        export PYTHONPATH=${{ github.workspace }}/src/promptflow
        python "../../scripts/building/run_coverage_tests.py" \
          -p promptflow \
          -t ${{ github.workspace }}/src/promptflow/tests/sdk_cli_azure_test ${{ github.workspace }}/src/promptflow/tests/sdk_cli_test \
          -l eastus \
          -m "unittest or e2etest" \
          -n ${{ steps.cpu-cores.outputs.count }}
        mv ${{ github.workspace }}/${{ env.testWorkingDirectory }}/test-results.xml ${{ github.workspace }}/test-results-sdk-cli.xml
    - name: Run Executor Test
      if : ${{ matrix.testType == 'executor' }}
      shell: bash -l {0}
      working-directory: ${{ github.workspace }}
      run: |-
        set -x -e
        export IS_IN_CI_PIPELINE="true"
        az account show
        conda activate release-env
        export PYTHONPATH=${{ github.workspace }}/src/promptflow
        pip install langchain
        python scripts/building/run_coverage_tests.py \
          -p ${{ github.workspace }}/src/promptflow/promptflow \
          -t ${{ github.workspace }}/src/promptflow/tests/executor/e2etests ${{ github.workspace }}/src/promptflow/tests/executor/unittests \
          -l eastus \
          -m "all" \
          -n ${{ steps.cpu-cores.outputs.count }}
        mv ./test-results.xml ./test-results-executor.xml
    - name: Upload Test Results
      if: always()
      uses: actions/upload-artifact@v3
      with:
        name: Test Results (Python ${{ matrix.pythonVersion }}) (OS ${{ matrix.os }})
        path: |
          ${{ github.workspace }}/*.xml
  all_tests_win:
    strategy:
      fail-fast: false
      matrix:
        os: [windows-latest]
        testType: [sdk-cli, executor-e2e, executor-unit]
        pythonVersion: ['3.8', '3.9', '3.10', '3.11', '3.12']
    runs-on: ${{ matrix.os }}
    steps:
    - name: checkout
      uses: actions/checkout@v3
    - name: Display and Set Environment Variables
      run: 
        env | sort >> $GITHUB_OUTPUT
      shell: bash -el {0}
    - name: Conda Setup - ${{ matrix.os }} - Python Version ${{ matrix.pythonVersion }}
      uses: "./.github/actions/step_create_conda_environment"
      with:
        pythonVersion: ${{ matrix.pythonVersion }}
    - name: Build wheel
      uses: "./.github/actions/step_sdk_setup_win"
      with:
        setupType: promptflow_with_extra
        scriptPath: ${{ env.testWorkingDirectory }}
    - name: Azure Login
      uses: azure/login@v1
      with:
        creds: ${{ secrets.AZURE_CREDENTIALS }}
    - name: Generate Configs
      uses: "./.github/actions/step_generate_configs"
      with:
        targetFolder: ${{ env.testWorkingDirectory }}
    - name: Get number of CPU cores
      uses: SimenB/github-actions-cpu-cores@v1
      id: cpu-cores
    - name: Run SDK CLI Test
      if : ${{ matrix.testType == 'sdk-cli' }}
      shell: pwsh
      working-directory: ${{ env.testWorkingDirectory }}
      run: |-
        $env:IS_IN_CI_PIPELINE = "true"
        az account show
        conda activate release-env
        $env:PYTHONPATH = "${{ github.workspace }}\\src\\promptflow"
        python "../../scripts/building/run_coverage_tests.py" `
          -p promptflow `
          -t ${{ github.workspace }}/src/promptflow/tests/sdk_cli_azure_test ${{ github.workspace }}/src/promptflow/tests/sdk_cli_test `
          -l eastus `
          -m "unittest or e2etest" `
          -n ${{ steps.cpu-cores.outputs.count }}
        mv ${{ github.workspace }}/${{ env.testWorkingDirectory }}/test-results.xml ${{ github.workspace }}/test-results-sdk-cli.xml
    - name: Run Executor Test
      if : ${{ matrix.testType == 'executor' }}
      shell: pwsh
      working-directory: ${{ github.workspace }}
      run: |-
        $env:IS_IN_CI_PIPELINE = "true"
        az account show
        conda activate release-env
        $env:PYTHONPATH = "${{ github.workspace }}\\src\\promptflow"
        pip install langchain
        python scripts/building/run_coverage_tests.py `
          -p ${{ github.workspace }}/src/promptflow/promptflow `
          -t ${{ github.workspace }}/src/promptflow/tests/executor/e2etests ${{ github.workspace }}/src/promptflow/tests/executor/unittests `
          -l eastus `
          -m "all" `
          -n ${{ steps.cpu-cores.outputs.count }}
        mv ./test-results.xml ./test-results-executor.xml
    - name: Upload pytest test results (Python ${{ matrix.pythonVersion }}) (OS ${{ matrix.os }})
      if: ${{ always() }}
      uses: actions/upload-artifact@v3
      with:
        name: Test Results (Python ${{ matrix.pythonVersion }}) (OS ${{ matrix.os }})
        path: ${{ github.workspace }}/*.xml
  publish-test-results:
    name: "Publish Tests Results"
    needs:
      - all_tests
      - all_tests_win
    runs-on: ubuntu-latest
    permissions:
      checks: write
      pull-requests: write
      contents: read
      issues: read
    if: always()

    steps:
    - name: checkout
      uses: actions/checkout@v3
    - name: Publish Test Results
      uses: "./.github/actions/step_publish_test_results"
      with:
        testActionFileName: promptflow-release-testing-matrix.yml
        testResultTitle: Release Test Matrix
        token: ${{ secrets.GITHUB_TOKEN }}
        coverageThreshold: 0
