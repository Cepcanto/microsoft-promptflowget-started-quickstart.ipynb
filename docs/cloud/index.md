# Cloud

Prompt flow streamlines the process of developing AI applications based on LLM, easing prompt engineering, prototyping, evaluating, and fine-tuning for high-quality products.

Transitioning to production, however, typically requires a comprehensive **LLMOps process**. This can often be a complex task, demanding high availability and security, particularly vital for large-scale team collaboration and lifecycle management when deploying to production.

To assist in this journey, we've introduced **Azure AI**, a **cloud-based platform** tailored for executing LLMOps, focusing on boosting productivity for enterprises.

This could be beneficial for:
* Private data access and controls 
* Collaborative development
* Automating iterative experimentation and CI/CD
* Deployment and optimization 
* Safe and Responsible AI


<img src="../media/cloud/azureml/llmops_cloud_value.png" width=60%></img>

In prompt flow, you can develope your flow locally and seamlessly move the experience to azure cloud.

```{toctree}
:caption: AzureAI
:maxdepth: 1
azureai/quick-start
azureai/deploy-to-azure-appservice
azureai/use-flow-in-azure-ml-pipeline.md
azureai/faq
```