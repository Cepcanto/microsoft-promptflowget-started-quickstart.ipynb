# Prompt flow Community Eco System

The prompt flow community ecosystem aims to provide a comprehensive set of tools and resources for developers who want to leverage the power of prompt flow to experimentally tune their prompts, develop their LLM-based application in local environment. This documentation will guide you through the key components of our ecosystem, including the **Prompt Flow SDK** and the **VSCode extension**.

## Prompt flow SDK/CLI

The Prompt Flow SDK/CLI empowers developers to use code manage credentials, initialize flows, develop flows, and execute batch testing and evaluation of prompt flows locally.

It's designed for efficiency, allowing simultaneous trigger of large dataset-based flow tests and metric evaluations. Additionally, the SDK/CLI can be easily integrated into your CI/CD pipeline, automating the testing process.

To get started with the Prompt Flow SDK, explore and follow the SDK documentation. It includes thorough usage instructions, API references, and practical examples.

## VS Code Extension

Our ecosystem also provides a powerful VSCode extension specifically designed for enabling you to easily and interactively develop prompt flows, fine-tune your prompts, and test them with a user-friendly UI.

## Community Support

Our community ecosystem thrives on collaboration and support. Join our active community forums to connect with fellow developers, and contribute to the growth of the ecosystem.

GitHub Repository: [promptflow](https://github.com/microsoft/promptflow)

More detailed contribution guide can be found in our Github repository. For any questions or feedbacks, you can open Github issue directly or reach out to pf-feedback@microsoft.com.

## Go to production and collaboration in cloud

Once you've successfully developed and tested your prompt flow within our community ecosystem, the next step is transitioning to a production-grade Language Learning Model (LLM) application. Azure Machine Learning is recommended for this phase, ensuring safety, productivity, and scalability.

Leveraging Azure Machine Learning for your prompt flow allows you to manage, deploy, and monitor your production-grade LLM applications effectively. It offers robust tools and services that can facilitate the development, testing, and deployment of your applications, while also providing scalable and secure solutions for experimentation.

## Conclusion

The prompt flow community ecosystem empowers developers to build interactive and dynamic prompts with ease. By leveraging the Prompt Flow SDK and the VSCode extension, you can create compelling user experiences and fine-tune your prompts in a local environment.

Join our community and start exploring the possibilities of prompt flows today!