{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chat with PDF\n",
    "\n",
    "This is a simple flow that allow you to ask questions about the content of a PDF file and get answers.\n",
    "You can run the flow with a URL to a PDF file and question as argument.\n",
    "Once it's launched it will download the PDF and build an index of the content. \n",
    "Then when you ask a question, it will look up the index to retrieve relevant content and post the question with the relevant content to OpenAI chat model (gpt-3.5-turbo or gpt4) to get an answer.\n",
    "\n",
    "## 0. Install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -r requirements.txt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Create connections\n",
    "Connection in prompt flow is for managing settings of your application behaviors incl. how to talk to different services (Azure OpenAI for example).\n",
    "In many applications, configuration files or environment variables are used for this purpose. Chat_with_pdf also uses environment variables, to make it work with prompt flow and without changing how environment variables are used, we populate everything in the CustomConnection into environment variables.\n",
    "```python\n",
    "def setup_env(conn: CustomConnection):\n",
    "    if not conn:\n",
    "        return\n",
    "    for key in conn:\n",
    "        os.environ[key] = conn[key]\n",
    "```\n",
    "\n",
    "chat_with_pdf requires following env vars (thus for the custom connection named \"chat_with_pdf_custom_connection\"):\n",
    "```\n",
    "OPENAI_API_BASE=<AOAI_ENDPOINT>\n",
    "OPENAI_API_VERSION=2023-03-15-preview\n",
    "OPENAI_API_KEY=<AOAI_API_KEY>\n",
    "EMBEDDING_MODEL_DEPLOYMENT_NAME=text-embedding-ada-002\n",
    "CHAT_MODEL_DEPLOYMENT_NAME=gpt-35-turbo\n",
    "PROMPT_TOKEN_LIMIT=3000\n",
    "MAX_COMPLETION_TOKENS=256\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import promptflow\n",
    "\n",
    "pf = promptflow.PFClient()\n",
    "\n",
    "# List all the available connections\n",
    "for c in pf.connections.list():\n",
    "    print(c.name + \" (\" + c.type + \")\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from promptflow.entities import CustomConnection\n",
    "\n",
    "conn_name = \"chat_with_pdf_custom_connection\"\n",
    "\n",
    "if len([c for c in pf.connections.list() if c.name == conn_name]) == 0:\n",
    "    # Create the custom connection that is required by chat_with_pdf_tool\n",
    "    print(f\"Creating custom connection: {conn_name}\")\n",
    "    conn = CustomConnection(\n",
    "        name=conn_name,\n",
    "        configs={\n",
    "            \"OPENAI_API_VERSION\": \"2023-03-15-preview\",\n",
    "            \"EMBEDDING_MODEL_DEPLOYMENT_NAME\": \"text-embedding-ada-002\",\n",
    "            \"CHAT_MODEL_DEPLOYMENT_NAME\": \"gpt-35-turbo\",\n",
    "            \"PROMPT_TOKEN_LIMIT\": \"3000\",\n",
    "            \"MAX_COMPLETION_TOKENS\": \"256\",\n",
    "        },\n",
    "        secrets={\n",
    "            \"OPENAI_API_BASE\": \"AOAI_ENDPOINT\",  # replace this\n",
    "            \"OPENAI_API_KEY\": \"AOAI_API_KEY\",  # replace this\n",
    "        },\n",
    "    )\n",
    "    pf.connections.create_or_update(conn)\n",
    "    print(f\"Custom connection: {conn_name} created.\")\n",
    "else:\n",
    "    print(f\"Custom connection: {conn_name} found.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Test the flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = pf.flows.test(\n",
    "    \".\",\n",
    "    inputs={\n",
    "        \"chat_history\": [],\n",
    "        \"pdf_url\": \"https://arxiv.org/pdf/1810.04805.pdf\",\n",
    "        \"question\": \"what is BERT?\",\n",
    "    },\n",
    ")\n",
    "print(output)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Run the flow with a data file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flow_path = \".\"\n",
    "data_path = \"./data/bert-paper-qna-3-line.jsonl\"\n",
    "\n",
    "run = pf.run(flow=flow_path, data=data_path)\n",
    "pf.stream(run)\n",
    "\n",
    "print(run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pf.get_details(run)"
   ]
  }
 ],
 "metadata": {
  "description": "A tutorial of chat-with-pdf flow that allows user ask questions about the content of a PDF file and get answers",
  "kernelspec": {
   "display_name": "prompt-flow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
