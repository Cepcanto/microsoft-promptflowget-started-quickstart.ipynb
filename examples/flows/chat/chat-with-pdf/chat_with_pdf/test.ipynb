{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: what is BERT?\n",
      "Bot: BERT stands for Bidirectional Encoder Representations from Transformers.\n",
      "User: what NLP tasks does it perform well?\n",
      "Bot: BERT can perform well on various natural language processing (NLP) tasks such as text classification, named entity recognition, question answering, sentence similarity, sentiment analysis, language translation, and text summarization. Its ability to capture contextual information and understand the meaning of words in a sentence makes it effective for many NLP tasks.\n",
      "User: is BERT suitable for NER?\n",
      "Bot: Yes, BERT is indeed suitable for named entity recognition (NER) tasks. It has been successfully used for NER and achieved state-of-the-art results in various benchmarks and competitions. By understanding contextual information, BERT can effectively identify and classify named entities such as names of people, organizations, locations, dates, and more within a given text.\n",
      "User: is it better than GPT\n",
      "Bot: Both BERT and GPT are advanced natural language processing models, but they serve different purposes and have different strengths.\n",
      "\n",
      "BERT (Bidirectional Encoder Representations from Transformers) is primarily designed for tasks that require understanding the meaning and relationships between words within a sentence. It is proficient at tasks such as text classification, named entity recognition, question-answering, and sentiment analysis. BERT achieves this by capturing bidirectional contextual information during the training process.\n",
      "\n",
      "On the other hand, GPT (Generative Pre-trained Transformer) specializes in generating coherent and contextually relevant text. GPT is well-suited for tasks like language generation, text completion, and story writing due to its ability to generate human-like text given a prompt.\n",
      "\n",
      "To determine whether BERT is better than GPT or vice versa, it depends on the specific NLP task you are working on and what you value most. BERT is powerful for understanding sentence-level contextual information, while GPT excels in generating text that flows naturally.\n",
      "User: when was GPT come up?\n",
      "Bot: GPT, which stands for Generative Pre-trained Transformer, was developed in 2018 by OpenAI.\n",
      "User: when was BERT come up?\n",
      "Bot: BERT, which stands for Bidirectional Encoder Representations from Transformers, was developed by Google AI in 2018.\n",
      "User: so about same time?\n",
      "Bot: No, BERT and GPT were not developed around the same time. BERT was developed by Google AI in 2018, while GPT was developed by OpenAI, also in 2018.\n"
     ]
    }
   ],
   "source": [
    "from main import chat_with_pdf, print_stream_and_return_full_answer\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "bert_paper_url = 'https://arxiv.org/pdf/1810.04805.pdf'\n",
    "questions = [\n",
    "    'what is BERT?',\n",
    "    'what NLP tasks does it perform well?',\n",
    "    'is BERT suitable for NER?',\n",
    "    'is it better than GPT',\n",
    "    'when was GPT come up?',\n",
    "    \"when was BERT come up?\",\n",
    "    'so about same time?'\n",
    "]\n",
    "\n",
    "history = []\n",
    "for q in questions:\n",
    "    stream, context = chat_with_pdf(q, bert_paper_url, history)\n",
    "    print(\"User: \" + q, flush=True)\n",
    "    print(\"Bot: \", end=\"\", flush=True)\n",
    "    answer = print_stream_and_return_full_answer(stream)\n",
    "    history = history + [{\"role\":\"user\", \"content\": q}, {\"role\":\"assistant\", \"content\": answer}]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pfsdk",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
