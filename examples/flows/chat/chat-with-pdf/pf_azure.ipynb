{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install dependencies of this project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup Azure ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.identity import DefaultAzureCredential\n",
    "from azure.ai.ml import MLClient\n",
    "\n",
    "try:\n",
    "    credential = DefaultAzureCredential()\n",
    "    # Check if given credential can get token successfully.\n",
    "    credential.get_token(\"https://management.azure.com/.default\")\n",
    "except Exception as ex:\n",
    "    # Fall back to InteractiveBrowserCredential in case DefaultAzureCredential not work\n",
    "    credential = InteractiveBrowserCredential()\n",
    "\n",
    "ml_client = MLClient(\n",
    "    credential=credential,\n",
    "    subscription_id=\"d128f140-94e6-4175-87a7-954b9d27db16\",  # this will look like xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx\n",
    "    resource_group_name=\"jietong-test\",\n",
    "    workspace_name=\"jietong-test-4\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get familiar with the primary interface - PFClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import promptflow.azure as azure\n",
    "\n",
    "pf = azure.PFClient(ml_client)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create connections\n",
    "Connection in prompt flow is for managing settings of your application behaviors incl. how to talk to different services (Azure OpenAI for example).\n",
    "In many applications, configuration files or environment variables are used for this purpose. Chat_with_pdf also uses environment variables, to make it work with prompt flow and without changing how environment variables are used, we populate everything in the CustomConnection into environment variables.\n",
    "```python\n",
    "def setup_env(conn: CustomConnection):\n",
    "    if not conn:\n",
    "        return\n",
    "    for key in conn:\n",
    "        os.environ[key] = conn[key]\n",
    "```\n",
    "\n",
    "chat_with_pdf requires following env vars (thus for the custom connection named \"my_custom_connection\"):\n",
    "```\n",
    "OPENAI_API_BASE=<AOAI_ENDPOINT>\n",
    "OPENAI_API_VERSION=2023-03-15-preview\n",
    "OPENAI_API_KEY=<AOAI_API_KEY>\n",
    "EMBEDDING_MODEL_DEPLOYMENT_NAME=text-embedding-ada-002\n",
    "CHAT_MODEL_DEPLOYMENT_NAME=gpt-35-turbo\n",
    "PROMPT_TOKEN_LIMIT=3000\n",
    "MAX_COMPLETION_TOKENS=256\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from promptflow.entities import CustomConnection\n",
    "\n",
    "if len([c for c in client.connections.list() if c.name == \"my_custom_connection\"]) == 0:\n",
    "    # Create the custom connection that is required by chat_with_pdf_tool\n",
    "    print(\"Creating custom connection: my_custom_connection\")\n",
    "    conn = CustomConnection(\n",
    "        name = \"my_custom_connection\",\n",
    "        configs= {\n",
    "            \"OPENAI_API_VERSION\": \"2023-03-15-preview\",\n",
    "            \"EMBEDDING_MODEL_DEPLOYMENT_NAME\": \"text-embedding-ada-002\",\n",
    "            \"CHAT_MODEL_DEPLOYMENT_NAME\": \"gpt-35-turbo\",\n",
    "            \"PROMPT_TOKEN_LIMIT\": \"3000\",\n",
    "            \"MAX_COMPLETION_TOKENS\": \"256\"\n",
    "        },\n",
    "        secrets= {\n",
    "            \"OPENAI_API_BASE\": \"AOAI_ENDPOINT\", # replace this\n",
    "            \"OPENAI_API_KEY\": \"AOAI_API_KEY\", # replace this\n",
    "        })\n",
    "    client.connections.create_or_update(conn)\n",
    "    print(\"Custom connection: my_custom_connection created.\")\n",
    "else:\n",
    "    print(\"Custom connection: my_custom_connection found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run a flow with settings in custom connection (context size 3K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flow_path = \".\"\n",
    "data_path = \"./test_data/bert-paper-qna.jsonl\"\n",
    "\n",
    "run_3k_context = pf.run(\n",
    "    flow=flow_path, \n",
    "    data=data_path, \n",
    "    connections={\"setup_env\": {\"conn\": \"chat_with_pdf_custom_connection\"}},\n",
    "    runtime=\"chat_with_pdf_runtime\",\n",
    "    display_name=\"chat_with_pdf_3k_context\",\n",
    "    tags={\"chat_with_pdf\":\"\", \"2nd_round\":\"\"},\n",
    "    stream=True)\n",
    "pf.stream(run_3k_context)\n",
    "\n",
    "print(run_3k_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detail = pf.get_details(run_3k_context)\n",
    "\n",
    "detail"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run a flow with settings in custom connection (context size 2K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flow_path = \".\"\n",
    "data_path = \"./test_data/bert-paper-qna.jsonl\"\n",
    "\n",
    "run_2k_context = pf.run(\n",
    "    flow=flow_path, \n",
    "    data=data_path, \n",
    "    connections={\"setup_env\": {\"conn\": \"chat_with_pdf_custom_connection_smaller_context\"}},\n",
    "    runtime=\"chat_with_pdf_runtime\",\n",
    "    display_name=\"chat_with_pdf_2k_context\",\n",
    "    tags={\"chat_with_pdf\":\"\", \"2nd_round\":\"\"},\n",
    "    stream=True)\n",
    "pf.stream(run_2k_context)\n",
    "\n",
    "print(run_2k_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detail = pf.get_details(run_2k_context)\n",
    "\n",
    "detail"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "prompt-flow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
