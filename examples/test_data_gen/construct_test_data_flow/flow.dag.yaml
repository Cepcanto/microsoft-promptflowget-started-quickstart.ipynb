id: template_standard_flow
name: Template Standard Flow
environment:
  python_requirements_txt: requirements.txt
inputs:
  text_chunk:
    type: string
    is_chat_input: false
    default: >-
      Adding a Tool Icon

      A tool icon serves as a graphical representation of your tool in the user interface (UI). Follow this guidance to add a custom tool icon when developing your own tool package.


      Adding a custom tool icon is optional. If you do not provide one, the system uses a default icon.
outputs:
  question:
    type: string
    reference: ${generate_test_question.output.question}
  answer:
    type: string
    reference: ${generate_answer.output}
  context:
    type: string
    reference: ${generate_context.output}
  question_type:
    type: string
    reference: ${generate_test_question.output.question_type}
nodes:
- name: reasoning_prompt
  type: prompt
  source:
    type: code
    path: reasoning_prompt.jinja2
  inputs:
    context: ${inputs.text_chunk}
    question: ${generate_seed_question.output}
  use_variants: false
- name: conditional_prompt
  type: prompt
  source:
    type: code
    path: conditional_prompt.jinja2
  inputs:
    context: ${inputs.text_chunk}
    question: ${generate_seed_question.output}
  use_variants: false
- name: score_context_prompt
  type: prompt
  source:
    type: code
    path: score_context_prompt.jinja2
  inputs:
    context: ${inputs.text_chunk}
  use_variants: false
- name: score_seed_question_prompt
  type: prompt
  source:
    type: code
    path: score_question_prompt.jinja2
  inputs:
    question: ${generate_seed_question.output}
  use_variants: false
- name: seed_question_prompt
  type: prompt
  source:
    type: code
    path: seed_question_prompt.jinja2
  inputs:
    context: ${inputs.text_chunk}
  use_variants: false
- name: generate_context_prompt
  type: prompt
  source:
    type: code
    path: generate_context_prompt.jinja2
  inputs:
    context: ${inputs.text_chunk}
    question: ${generate_test_question.output.question}
  use_variants: false
- name: generate_answer_prompt
  type: prompt
  source:
    type: code
    path: generate_answer_prompt.jinja2
  inputs:
    context: ${generate_context.output}
    question: ${generate_test_question.output}
  use_variants: false
- name: generate_seed_question
  type: python
  source:
    type: code
    path: generate_seed_question.py
  inputs:
    connection: azure_openai_connection
    model: gpt-35-turbo
    score_context_prompt: ${score_context_prompt.output}
    seed_question_prompt: ${seed_question_prompt.output}
  use_variants: false
- name: generate_test_question
  type: python
  source:
    type: code
    path: generate_test_question.py
  inputs:
    connection: azure_openai_connection
    conditional_prompt: ${conditional_prompt.output}
    model: gpt-35-turbo
    reasoning_prompt: ${reasoning_prompt.output}
    score_seed_question_prompt: ${score_seed_question_prompt.output}
    seed_question: ${generate_seed_question.output}
  use_variants: false
- name: score_question_prompt
  type: prompt
  source:
    type: code
    path: score_question_prompt.jinja2
  inputs:
    question: ${generate_test_question.output.question}
  use_variants: false
- name: generate_context
  type: python
  source:
    type: code
    path: generate_context.py
  inputs:
    connection: azure_openai_connection
    generate_context_prompt: ${generate_context_prompt.output}
    model: gpt-35-turbo
    question_info: ${generate_test_question.output}
    score_question_prompt: ${score_question_prompt.output}
  use_variants: false
- name: generate_answer
  type: python
  source:
    type: code
    path: generate_answer.py
  inputs:
    connection: azure_openai_connection
    context: ${generate_context.output}
    generate_answer_prompt: ${generate_answer_prompt.output}
    model: gpt-35-turbo
  use_variants: false
