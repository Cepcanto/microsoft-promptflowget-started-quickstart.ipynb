# Prompt flow evaluators

[![Python package](https://img.shields.io/pypi/v/promptflow-tools)](https://pypi.org/project/promptflow-evals/)
[![License: MIT](https://img.shields.io/github/license/microsoft/promptflow)](https://github.com/microsoft/promptflow/blob/main/LICENSE)

## Introduction
Evaluators are prebuilt promptflow pipelines that are designed to measure the quality of the outputs from large language models.
The package includes
 - Chat evaluator
 - Coherence evaluator
 - F1 score evaluator
 - Fluency evaluator
 - Groundedness evaluator
 - QA evaluator
 - Relevance evaluator
 - Similarity evaluator
 - Content safety evaluators
   * Self harm evaluator
   * Hate/unfairness evaluator
   * Sexual evaluator
