{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c0b657f7-3ec9-4380-82b9-6d5bdd804201",
   "metadata": {},
   "source": [
    "# Loading DAG flows as evaluators.\n",
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49ddbf0d-10a2-4f6a-93b9-4e3cd0fa8390",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "from promptflow.client import load_flow\n",
    "from promptflow.core import Flow\n",
    "from promptflow.evals.evaluate import evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc68b67d-af0c-4ff1-83ab-15a9bae73681",
   "metadata": {},
   "source": [
    "In this example we will load the evaluator from `basic_dag` folder.  It contains simple script for calculation of similarity between answer and ground truth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e582b105-3225-445c-8270-85b5aa2396c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert os.path.isdir(\"basic_dag\"), \"Please download basic_dag folder into the directory with this notebook.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4092434-a6da-47ac-a3ba-876118465f56",
   "metadata": {},
   "source": [
    "## Data\n",
    "Now let us generate some data for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c5238b6-1776-467a-8c8a-fac5224d5aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_raw = pd.DataFrame(\n",
    "    {\n",
    "        \"question\": [\"What is the name of Alexander the Great horse?\", \"What is Sun?\"],\n",
    "        \"answer\": [\"Bucephalus\", \"The star.\"],\n",
    "        \"ground_truth\": [\"Binkey\", \"The star.\"],\n",
    "    }\n",
    ")\n",
    "data_raw.to_json(\"data.jsonl\", lines=True, orient=\"records\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64626913-2223-474e-a33b-347261d8f6e4",
   "metadata": {},
   "source": [
    "## Test the evaluator\n",
    "We will load evaluator in two ways:\n",
    "- Using `Flow.load` method;\n",
    "- Using `promptflow.client.load_flow` function.\n",
    "\n",
    "### Run using `promptflow.client.load_flow`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da5149b0-b45a-4e23-8bb7-622f7ee5ab4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dag_flow = load_flow(\"basic_dag\")\n",
    "dag_flow(**data_raw[:1].T[0].to_dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02c38174-5df3-4d04-800b-689f35dfcc1c",
   "metadata": {},
   "source": [
    "Now we will use the `evaluate` API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab365a53-8c84-42e5-a3db-9524c0ee09e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = evaluate(data=\"data.jsonl\", evaluators={\"similarity\": dag_flow})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d62497eb-44b0-4091-8c9a-6acd1f7faee0",
   "metadata": {},
   "source": [
    "View the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "936c5bfc-eb73-41ce-b7b2-02a88294280d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"{results['metrics']=}\")\n",
    "pd.DataFrame(results[\"rows\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f095d925-e19e-45d4-8db6-1fc9df435024",
   "metadata": {},
   "source": [
    "### Run using `Flow.load`\n",
    "<font color='red'> This section is commented out, because it used to fail </font><br>\n",
    "First we will try using flow as a function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ba548e5-8da0-41b9-a9a1-f96298a6277a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dag_flow = Flow.load(\"basic_dag\")\n",
    "dag_flow(**data_raw[:1].T[0].to_dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "660eecc3-592f-4437-9f7c-4fa64a944b3a",
   "metadata": {},
   "source": [
    "Now we will use the `evaluate` API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89443d21-4050-4710-a5ed-d7552c7e6419",
   "metadata": {},
   "outputs": [],
   "source": [
    "# results = evaluate(\n",
    "#     data='data.jsonl',\n",
    "#     evaluators = {'similarity': dag_flow}\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7682f4b-adfe-49e4-951c-63c1e9222e68",
   "metadata": {},
   "source": [
    "View the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49b9ab1f-763e-45ed-98f8-e644ea65a641",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(f\"{results['metrics']=}\")\n",
    "# pd.DataFrame(results[\"rows\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python311",
   "language": "python",
   "name": "python311"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
