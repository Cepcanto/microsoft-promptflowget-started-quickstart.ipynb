interactions:
- request:
    body: null
    headers:
      Accept:
      - application/json
      Accept-Encoding:
      - gzip, deflate
      Connection:
      - keep-alive
      User-Agent:
      - promptflow-sdk/0.0.1 azure-ai-ml/1.12.1 azsdk-python-mgmt-machinelearningservices/0.1.0
        Python/3.10.13 (Windows-10-10.0.22631-SP0)
    method: GET
    uri: https://management.azure.com/subscriptions/00000000-0000-0000-0000-000000000000/resourceGroups/00000/providers/Microsoft.MachineLearningServices/workspaces/00000
  response:
    body:
      string: '{"id": "/subscriptions/00000000-0000-0000-0000-000000000000/resourceGroups/00000/providers/Microsoft.MachineLearningServices/workspaces/00000",
        "name": "00000", "type": "Microsoft.MachineLearningServices/workspaces", "location":
        "eastus", "tags": {}, "etag": null, "kind": "Default", "sku": {"name": "Basic",
        "tier": "Basic"}, "properties": {"discoveryUrl": "https://eastus.api.azureml.ms/discovery"}}'
    headers:
      cache-control:
      - no-cache
      content-length:
      - '3630'
      content-type:
      - application/json; charset=utf-8
      expires:
      - '-1'
      pragma:
      - no-cache
      strict-transport-security:
      - max-age=31536000; includeSubDomains
      transfer-encoding:
      - chunked
      vary:
      - Accept-Encoding,Accept-Encoding
      x-content-type-options:
      - nosniff
      x-request-time:
      - '0.025'
    status:
      code: 200
      message: OK
- request:
    body: null
    headers:
      Accept:
      - application/json
      Accept-Encoding:
      - gzip, deflate
      Connection:
      - keep-alive
      User-Agent:
      - promptflow-sdk/0.0.1 azure-ai-ml/1.12.1 azsdk-python-mgmt-machinelearningservices/0.1.0
        Python/3.10.13 (Windows-10-10.0.22631-SP0)
    method: GET
    uri: https://management.azure.com/subscriptions/00000000-0000-0000-0000-000000000000/resourceGroups/00000/providers/Microsoft.MachineLearningServices/workspaces/00000/datastores?count=30&isDefault=true&orderByAsc=false
  response:
    body:
      string: '{"value": [{"id": "/subscriptions/00000000-0000-0000-0000-000000000000/resourceGroups/00000/providers/Microsoft.MachineLearningServices/workspaces/00000/datastores/workspaceblobstore",
        "name": "workspaceblobstore", "type": "Microsoft.MachineLearningServices/workspaces/datastores",
        "properties": {"description": null, "tags": null, "properties": null, "isDefault":
        true, "credentials": {"credentialsType": "AccountKey"}, "intellectualProperty":
        null, "subscriptionId": "00000000-0000-0000-0000-000000000000", "resourceGroup":
        "00000", "datastoreType": "AzureBlob", "accountName": "fake_account_name",
        "containerName": "fake-container-name", "endpoint": "core.windows.net", "protocol":
        "https", "serviceDataAccessAuthIdentity": "WorkspaceSystemAssignedIdentity"},
        "systemData": {"createdAt": "2023-04-08T02:53:06.5886442+00:00", "createdBy":
        "779301c0-18b2-4cdc-801b-a0a3368fee0a", "createdByType": "Application", "lastModifiedAt":
        "2023-04-08T02:53:07.521127+00:00", "lastModifiedBy": "779301c0-18b2-4cdc-801b-a0a3368fee0a",
        "lastModifiedByType": "Application"}}]}'
    headers:
      cache-control:
      - no-cache
      content-length:
      - '1372'
      content-type:
      - application/json; charset=utf-8
      expires:
      - '-1'
      pragma:
      - no-cache
      strict-transport-security:
      - max-age=31536000; includeSubDomains
      transfer-encoding:
      - chunked
      vary:
      - Accept-Encoding,Accept-Encoding
      x-content-type-options:
      - nosniff
      x-request-time:
      - '0.066'
    status:
      code: 200
      message: OK
- request:
    body: null
    headers:
      Accept:
      - application/json
      Accept-Encoding:
      - gzip, deflate
      Connection:
      - keep-alive
      User-Agent:
      - promptflow-sdk/0.0.1 azure-ai-ml/1.12.1 azsdk-python-mgmt-machinelearningservices/0.1.0
        Python/3.10.13 (Windows-10-10.0.22631-SP0)
    method: GET
    uri: https://management.azure.com/subscriptions/00000000-0000-0000-0000-000000000000/resourceGroups/00000/providers/Microsoft.MachineLearningServices/workspaces/00000/datastores/workspaceblobstore
  response:
    body:
      string: '{"id": "/subscriptions/00000000-0000-0000-0000-000000000000/resourceGroups/00000/providers/Microsoft.MachineLearningServices/workspaces/00000/datastores/workspaceblobstore",
        "name": "workspaceblobstore", "type": "Microsoft.MachineLearningServices/workspaces/datastores",
        "properties": {"description": null, "tags": null, "properties": null, "isDefault":
        true, "credentials": {"credentialsType": "AccountKey"}, "intellectualProperty":
        null, "subscriptionId": "00000000-0000-0000-0000-000000000000", "resourceGroup":
        "00000", "datastoreType": "AzureBlob", "accountName": "fake_account_name",
        "containerName": "fake-container-name", "endpoint": "core.windows.net", "protocol":
        "https", "serviceDataAccessAuthIdentity": "WorkspaceSystemAssignedIdentity"},
        "systemData": {"createdAt": "2023-04-08T02:53:06.5886442+00:00", "createdBy":
        "779301c0-18b2-4cdc-801b-a0a3368fee0a", "createdByType": "Application", "lastModifiedAt":
        "2023-04-08T02:53:07.521127+00:00", "lastModifiedBy": "779301c0-18b2-4cdc-801b-a0a3368fee0a",
        "lastModifiedByType": "Application"}}'
    headers:
      cache-control:
      - no-cache
      content-length:
      - '1227'
      content-type:
      - application/json; charset=utf-8
      expires:
      - '-1'
      pragma:
      - no-cache
      strict-transport-security:
      - max-age=31536000; includeSubDomains
      transfer-encoding:
      - chunked
      vary:
      - Accept-Encoding,Accept-Encoding
      x-content-type-options:
      - nosniff
      x-request-time:
      - '0.070'
    status:
      code: 200
      message: OK
- request:
    body: null
    headers:
      Accept:
      - application/json
      Accept-Encoding:
      - gzip, deflate
      Connection:
      - keep-alive
      Content-Length:
      - '0'
      User-Agent:
      - promptflow-sdk/0.0.1 azure-ai-ml/1.12.1 azsdk-python-mgmt-machinelearningservices/0.1.0
        Python/3.10.13 (Windows-10-10.0.22631-SP0)
    method: POST
    uri: https://management.azure.com/subscriptions/00000000-0000-0000-0000-000000000000/resourceGroups/00000/providers/Microsoft.MachineLearningServices/workspaces/00000/datastores/workspaceblobstore/listSecrets
  response:
    body:
      string: '{"secretsType": "AccountKey", "key": "dGhpcyBpcyBmYWtlIGtleQ=="}'
    headers:
      cache-control:
      - no-cache
      content-length:
      - '134'
      content-type:
      - application/json; charset=utf-8
      expires:
      - '-1'
      pragma:
      - no-cache
      strict-transport-security:
      - max-age=31536000; includeSubDomains
      transfer-encoding:
      - chunked
      vary:
      - Accept-Encoding
      x-content-type-options:
      - nosniff
      x-request-time:
      - '0.160'
    status:
      code: 200
      message: OK
- request:
    body: null
    headers:
      Accept:
      - application/xml
      Accept-Encoding:
      - gzip, deflate
      Connection:
      - keep-alive
      User-Agent:
      - azsdk-python-storage-blob/12.19.0 Python/3.10.13 (Windows-10-10.0.22631-SP0)
      x-ms-date:
      - Tue, 26 Dec 2023 10:12:19 GMT
      x-ms-version:
      - '2023-11-03'
    method: HEAD
    uri: https://fake_account_name.blob.core.windows.net/fake-container-name/LocalUpload/000000000000000000000000000000000000/numbers.jsonl
  response:
    body:
      string: ''
    headers:
      accept-ranges:
      - bytes
      content-length:
      - '290'
      content-md5:
      - O6LvdPMlN/PM6b7fPh75Jw==
      content-type:
      - application/octet-stream
      last-modified:
      - Tue, 26 Dec 2023 09:52:29 GMT
      server:
      - Windows-Azure-Blob/1.0 Microsoft-HTTPAPI/2.0
      vary:
      - Origin
      x-ms-blob-type:
      - BlockBlob
      x-ms-creation-time:
      - Tue, 26 Dec 2023 09:52:29 GMT
      x-ms-meta-name:
      - 229ce463-c199-4588-a9c4-c30e7a4bd25c
      x-ms-meta-upload_status:
      - completed
      x-ms-meta-version:
      - 4cda6a90-97ca-4ad5-b420-5e347369f614
      x-ms-version:
      - '2023-11-03'
    status:
      code: 200
      message: OK
- request:
    body: null
    headers:
      Accept:
      - application/xml
      Accept-Encoding:
      - gzip, deflate
      Connection:
      - keep-alive
      User-Agent:
      - azsdk-python-storage-blob/12.19.0 Python/3.10.13 (Windows-10-10.0.22631-SP0)
      x-ms-date:
      - Tue, 26 Dec 2023 10:12:20 GMT
      x-ms-version:
      - '2023-11-03'
    method: HEAD
    uri: https://fake_account_name.blob.core.windows.net/fake-container-name/az-ml-artifacts/000000000000000000000000000000000000/numbers.jsonl
  response:
    body:
      string: ''
    headers:
      server:
      - Windows-Azure-Blob/1.0 Microsoft-HTTPAPI/2.0
      transfer-encoding:
      - chunked
      vary:
      - Origin
      x-ms-error-code:
      - BlobNotFound
      x-ms-version:
      - '2023-11-03'
    status:
      code: 404
      message: The specified blob does not exist.
- request:
    body: null
    headers:
      Accept:
      - application/json
      Accept-Encoding:
      - gzip, deflate
      Connection:
      - keep-alive
      User-Agent:
      - promptflow-sdk/0.0.1 azure-ai-ml/1.12.1 azsdk-python-mgmt-machinelearningservices/0.1.0
        Python/3.10.13 (Windows-10-10.0.22631-SP0)
    method: GET
    uri: https://management.azure.com/subscriptions/00000000-0000-0000-0000-000000000000/resourceGroups/00000/providers/Microsoft.MachineLearningServices/workspaces/00000/datastores/workspaceblobstore
  response:
    body:
      string: '{"id": "/subscriptions/00000000-0000-0000-0000-000000000000/resourceGroups/00000/providers/Microsoft.MachineLearningServices/workspaces/00000/datastores/workspaceblobstore",
        "name": "workspaceblobstore", "type": "Microsoft.MachineLearningServices/workspaces/datastores",
        "properties": {"description": null, "tags": null, "properties": null, "isDefault":
        true, "credentials": {"credentialsType": "AccountKey"}, "intellectualProperty":
        null, "subscriptionId": "00000000-0000-0000-0000-000000000000", "resourceGroup":
        "00000", "datastoreType": "AzureBlob", "accountName": "fake_account_name",
        "containerName": "fake-container-name", "endpoint": "core.windows.net", "protocol":
        "https", "serviceDataAccessAuthIdentity": "WorkspaceSystemAssignedIdentity"},
        "systemData": {"createdAt": "2023-04-08T02:53:06.5886442+00:00", "createdBy":
        "779301c0-18b2-4cdc-801b-a0a3368fee0a", "createdByType": "Application", "lastModifiedAt":
        "2023-04-08T02:53:07.521127+00:00", "lastModifiedBy": "779301c0-18b2-4cdc-801b-a0a3368fee0a",
        "lastModifiedByType": "Application"}}'
    headers:
      cache-control:
      - no-cache
      content-length:
      - '1227'
      content-type:
      - application/json; charset=utf-8
      expires:
      - '-1'
      pragma:
      - no-cache
      strict-transport-security:
      - max-age=31536000; includeSubDomains
      transfer-encoding:
      - chunked
      vary:
      - Accept-Encoding,Accept-Encoding
      x-content-type-options:
      - nosniff
      x-request-time:
      - '0.102'
    status:
      code: 200
      message: OK
- request:
    body: null
    headers:
      Accept:
      - application/json
      Accept-Encoding:
      - gzip, deflate
      Connection:
      - keep-alive
      Content-Length:
      - '0'
      User-Agent:
      - promptflow-sdk/0.0.1 azure-ai-ml/1.12.1 azsdk-python-mgmt-machinelearningservices/0.1.0
        Python/3.10.13 (Windows-10-10.0.22631-SP0)
    method: POST
    uri: https://management.azure.com/subscriptions/00000000-0000-0000-0000-000000000000/resourceGroups/00000/providers/Microsoft.MachineLearningServices/workspaces/00000/datastores/workspaceblobstore/listSecrets
  response:
    body:
      string: '{"secretsType": "AccountKey", "key": "dGhpcyBpcyBmYWtlIGtleQ=="}'
    headers:
      cache-control:
      - no-cache
      content-length:
      - '134'
      content-type:
      - application/json; charset=utf-8
      expires:
      - '-1'
      pragma:
      - no-cache
      strict-transport-security:
      - max-age=31536000; includeSubDomains
      transfer-encoding:
      - chunked
      vary:
      - Accept-Encoding
      x-content-type-options:
      - nosniff
      x-request-time:
      - '0.089'
    status:
      code: 200
      message: OK
- request:
    body: null
    headers:
      Accept:
      - application/xml
      Accept-Encoding:
      - gzip, deflate
      Connection:
      - keep-alive
      User-Agent:
      - azsdk-python-storage-blob/12.19.0 Python/3.10.13 (Windows-10-10.0.22631-SP0)
      x-ms-date:
      - Tue, 26 Dec 2023 10:12:24 GMT
      x-ms-version:
      - '2023-11-03'
    method: HEAD
    uri: https://fake_account_name.blob.core.windows.net/fake-container-name/LocalUpload/000000000000000000000000000000000000/two/flow.dag.yaml
  response:
    body:
      string: ''
    headers:
      accept-ranges:
      - bytes
      content-length:
      - '242'
      content-md5:
      - ySItjr6//pwsGdjLZfgq0A==
      content-type:
      - application/octet-stream
      last-modified:
      - Tue, 26 Dec 2023 09:53:17 GMT
      server:
      - Windows-Azure-Blob/1.0 Microsoft-HTTPAPI/2.0
      vary:
      - Origin
      x-ms-blob-type:
      - BlockBlob
      x-ms-creation-time:
      - Tue, 26 Dec 2023 09:52:31 GMT
      x-ms-meta-name:
      - 5b163be8-ab29-4f62-bef0-cd64d56ab269
      x-ms-meta-upload_status:
      - completed
      x-ms-meta-version:
      - '1'
      x-ms-version:
      - '2023-11-03'
    status:
      code: 200
      message: OK
- request:
    body: null
    headers:
      Accept:
      - application/xml
      Accept-Encoding:
      - gzip, deflate
      Connection:
      - keep-alive
      User-Agent:
      - azsdk-python-storage-blob/12.19.0 Python/3.10.13 (Windows-10-10.0.22631-SP0)
      x-ms-date:
      - Tue, 26 Dec 2023 10:12:25 GMT
      x-ms-version:
      - '2023-11-03'
    method: HEAD
    uri: https://fake_account_name.blob.core.windows.net/fake-container-name/az-ml-artifacts/000000000000000000000000000000000000/two/flow.dag.yaml
  response:
    body:
      string: ''
    headers:
      server:
      - Windows-Azure-Blob/1.0 Microsoft-HTTPAPI/2.0
      transfer-encoding:
      - chunked
      vary:
      - Origin
      x-ms-error-code:
      - BlobNotFound
      x-ms-version:
      - '2023-11-03'
    status:
      code: 404
      message: The specified blob does not exist.
- request:
    body: '{"flowDefinitionDataStoreName": "workspaceblobstore", "flowDefinitionBlobPath":
      "LocalUpload/000000000000000000000000000000000000/two/flow.dag.yaml", "runId":
      "run1", "runDisplayName": "run1", "runExperimentName": "", "batchDataInput":
      {"dataUri": "azureml://datastores/workspaceblobstore/paths/LocalUpload/000000000000000000000000000000000000/numbers.jsonl"},
      "inputsMapping": {"number": "${data.value}"}, "connections": {}, "environmentVariables":
      {}, "runtimeName": "fake-runtime-name", "sessionId": "000000000000000000000000000000000000000000000000",
      "flowLineageId": "0000000000000000000000000000000000000000000000000000000000000000",
      "runDisplayNameGenerationType": "UserProvidedMacro"}'
    headers:
      Accept:
      - application/json
      Accept-Encoding:
      - gzip, deflate
      Connection:
      - keep-alive
      Content-Length:
      - '749'
      Content-Type:
      - application/json
      User-Agent:
      - promptflow-sdk/0.0.1 azsdk-python-azuremachinelearningdesignerserviceclient/unknown
        Python/3.10.13 (Windows-10-10.0.22631-SP0)
    method: POST
    uri: https://eastus.api.azureml.ms/flow/api/subscriptions/00000000-0000-0000-0000-000000000000/resourceGroups/00000/providers/Microsoft.MachineLearningServices/workspaces/00000/BulkRuns/submit
  response:
    body:
      string: '"run1"'
    headers:
      connection:
      - keep-alive
      content-length:
      - '38'
      content-type:
      - application/json; charset=utf-8
      strict-transport-security:
      - max-age=15724800; includeSubDomains; preload
      x-content-type-options:
      - nosniff
      x-request-time:
      - '5.939'
    status:
      code: 200
      message: OK
- request:
    body: null
    headers:
      Accept:
      - application/json
      Accept-Encoding:
      - gzip, deflate
      Connection:
      - keep-alive
      User-Agent:
      - promptflow-sdk/0.0.1 azsdk-python-azuremachinelearningdesignerserviceclient/unknown
        Python/3.10.13 (Windows-10-10.0.22631-SP0)
    method: GET
    uri: https://eastus.api.azureml.ms/flow/api/subscriptions/00000000-0000-0000-0000-000000000000/resourceGroups/00000/providers/Microsoft.MachineLearningServices/workspaces/00000/BulkRuns/run1
  response:
    body:
      string: '{"flowGraph": {"nodes": [{"name": "mod_two", "type": "python", "source":
        {"type": "code", "path": "mod_two.py"}, "inputs": {"number": "${inputs.number}"},
        "tool": "mod_two.py", "reduce": false}], "tools": [{"name": "Content Safety
        (Text Analyze)", "type": "python", "inputs": {"connection": {"type": ["AzureContentSafetyConnection"],
        "allow_manual_entry": false, "is_multi_select": false, "input_type": "default"},
        "hate_category": {"type": ["string"], "default": "medium_sensitivity", "enum":
        ["disable", "low_sensitivity", "medium_sensitivity", "high_sensitivity"],
        "allow_manual_entry": false, "is_multi_select": false, "input_type": "default"},
        "self_harm_category": {"type": ["string"], "default": "medium_sensitivity",
        "enum": ["disable", "low_sensitivity", "medium_sensitivity", "high_sensitivity"],
        "allow_manual_entry": false, "is_multi_select": false, "input_type": "default"},
        "sexual_category": {"type": ["string"], "default": "medium_sensitivity", "enum":
        ["disable", "low_sensitivity", "medium_sensitivity", "high_sensitivity"],
        "allow_manual_entry": false, "is_multi_select": false, "input_type": "default"},
        "text": {"type": ["string"], "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}, "violence_category": {"type": ["string"],
        "default": "medium_sensitivity", "enum": ["disable", "low_sensitivity", "medium_sensitivity",
        "high_sensitivity"], "allow_manual_entry": false, "is_multi_select": false,
        "input_type": "default"}}, "description": "Use Azure Content Safety to detect
        harmful content.", "module": "promptflow.tools.azure_content_safety", "function":
        "analyze_text", "is_builtin": true, "package": "promptflow-tools", "package_version":
        "0.0.216", "enable_kwargs": false, "deprecated_tools": ["content_safety_text.tools.content_safety_text_tool.analyze_text"],
        "tool_state": "stable"}, {"name": "Embedding", "type": "python", "inputs":
        {"connection": {"type": ["AzureOpenAIConnection", "OpenAIConnection"], "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "deployment_name":
        {"type": ["string"], "enabled_by": "connection", "enabled_by_type": ["AzureOpenAIConnection"],
        "model_list": ["text-embedding-ada-002", "text-search-ada-doc-001", "text-search-ada-query-001"],
        "capabilities": {"completion": false, "chat_completion": false, "embeddings":
        true}, "allow_manual_entry": false, "is_multi_select": false, "input_type":
        "default"}, "input": {"type": ["string"], "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}, "model": {"type": ["string"], "enum": ["text-embedding-ada-002",
        "text-search-ada-doc-001", "text-search-ada-query-001"], "enabled_by": "connection",
        "enabled_by_type": ["OpenAIConnection"], "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}}, "description": "Use Open AI''s embedding
        model to create an embedding vector representing the input text.", "module":
        "promptflow.tools.embedding", "function": "embedding", "is_builtin": true,
        "package": "promptflow-tools", "package_version": "0.0.216", "enable_kwargs":
        false, "tool_state": "stable"}, {"name": "Open Source LLM", "type": "custom_llm",
        "inputs": {"api": {"type": ["string"], "enum": ["chat", "completion"], "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "connection": {"type":
        ["CustomConnection"], "allow_manual_entry": false, "is_multi_select": false,
        "input_type": "default"}, "deployment_name": {"type": ["string"], "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "endpoint_name":
        {"type": ["string"], "default": "-- please enter an endpoint name --", "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "max_new_tokens":
        {"type": ["int"], "default": 500, "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}, "model_kwargs": {"type": ["object"], "default":
        "{}", "allow_manual_entry": false, "is_multi_select": false, "input_type":
        "default", "advanced": true}, "temperature": {"type": ["double"], "default":
        1.0, "allow_manual_entry": false, "is_multi_select": false, "input_type":
        "default"}, "top_p": {"type": ["double"], "default": 1.0, "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default", "advanced": true}},
        "description": "Use an Open Source model from the Azure Model catalog, deployed
        to an AzureML Online Endpoint for LLM Chat or Completion API calls.", "module":
        "promptflow.tools.open_source_llm", "class_name": "OpenSourceLLM", "function":
        "call", "icon": "data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAACgElEQVR4nGWSz2vcVRTFP/e9NzOZ1KDGohASslLEH6VLV0ak4l/QpeDCrfQPcNGliODKnVm4EBdBsIjQIlhciKW0ycKFVCSNbYnjdDLtmPnmO/nO9917XcxMkjYX3uLx7nnn3HOuMK2Nix4fP78ZdrYXVkLVWjf3l3B1B+HpcjzGFtmqa6cePz7/x0dnn1n5qhj3iBJPYREIURAJuCtpY8PjReDbrf9WG7H1fuefwQU9qKztTcMJT+PNnEFvjGVDBDlSsH6p/9MLzy6+NxwVqI8RAg4IPmWedMckdLYP6O6UpIaQfvyyXG012+e79/ZfHukoS1ISMT2hGTB1RkUmNgQ5QZ0w+a2VWDq73MbdEWmfnnv6UWe7oNzPaLapl5CwuLTXK9WUGBuCjqekzhP+z52ZXOrKMD3OJg0Hh778aiOuvpnYvp05d6GJO4iAO4QAe/eV36/X5LFRV4Zmn+AdkqlL8Vjp3oVioOz+WTPzzYEgsN+fgPLYyJVheSbPPVl2ikeGZRjtG52/8rHuaV9VOlpP2OtKyVndcRVCSqOhsvxa4vW359i6OuKdD+aP8Q4SYPdOzS/flGjt1JUSaMqZ5nwa1Y8qWb/Ud/eZZkHisYezEM0m+fcelDr8F1SqW2LNK6r1jXQwyLzy1hxvrLXZulry7ocL+FS6G4QIu3fG/Px1gdYeW7LIgXU2P/115TOA5G7e3Rmj2aS/m7l5pThiZzrCcE/d1XHzbln373nw7y6veeoUm5KCNKT/IPPwbiY1hYd/l5MIT65BMFt87sU4v9D7/JMflr44uV6hGh1+L4RCkg6z5iK2tAhNLeLsNGwYA4fDYnC/drvuuFxe86NV/x+Ut27g0FvykgAAAABJRU5ErkJggg==",
        "is_builtin": true, "package": "promptflow-tools", "package_version": "0.0.216",
        "enable_kwargs": false, "tool_state": "stable"}, {"name": "OpenAI GPT-4V",
        "type": "custom_llm", "inputs": {"connection": {"type": ["OpenAIConnection"],
        "allow_manual_entry": false, "is_multi_select": false, "input_type": "default"},
        "frequency_penalty": {"type": ["double"], "default": 0, "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "max_tokens": {"type":
        ["int"], "default": "", "allow_manual_entry": false, "is_multi_select": false,
        "input_type": "default"}, "model": {"type": ["string"], "enum": ["gpt-4-vision-preview"],
        "allow_manual_entry": true, "is_multi_select": false, "input_type": "default"},
        "presence_penalty": {"type": ["double"], "default": 0, "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "stop": {"type":
        ["list"], "default": "", "allow_manual_entry": false, "is_multi_select": false,
        "input_type": "default"}, "temperature": {"type": ["double"], "default": 1,
        "allow_manual_entry": false, "is_multi_select": false, "input_type": "default"},
        "top_p": {"type": ["double"], "default": 1, "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}}, "description": "Use OpenAI GPT-4V to leverage
        vision ability.", "module": "promptflow.tools.openai_gpt4v", "class_name":
        "OpenAI", "function": "chat", "is_builtin": true, "package": "promptflow-tools",
        "package_version": "0.0.216", "default_prompt": "# system:\nAs an AI assistant,
        your task involves interpreting images and responding to questions about the
        image.\nRemember to provide accurate answers based on the information present
        in the image.\n\n# user:\nCan you tell me what the image depicts?\n![image]({{image_input}})\n",
        "enable_kwargs": false, "tool_state": "stable"}, {"name": "Serp API", "type":
        "python", "inputs": {"connection": {"type": ["SerpConnection"], "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "engine": {"type":
        ["string"], "default": "google", "enum": ["google", "bing"], "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "location": {"type":
        ["string"], "default": "", "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}, "num": {"type": ["int"], "default": "10",
        "allow_manual_entry": false, "is_multi_select": false, "input_type": "default"},
        "query": {"type": ["string"], "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}, "safe": {"type": ["string"], "default": "off",
        "enum": ["active", "off"], "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}}, "description": "Use Serp API to obtain search
        results from a specific search engine.", "module": "promptflow.tools.serpapi",
        "class_name": "SerpAPI", "function": "search", "is_builtin": true, "package":
        "promptflow-tools", "package_version": "0.0.216", "enable_kwargs": false,
        "tool_state": "stable"}, {"name": "Faiss Index Lookup", "type": "python",
        "inputs": {"path": {"type": ["string"], "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}, "top_k": {"type": ["int"], "default": "3",
        "allow_manual_entry": false, "is_multi_select": false, "input_type": "default"},
        "vector": {"type": ["list"], "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}}, "description": "Search vector based query
        from the FAISS index file.", "module": "promptflow_vectordb.tool.faiss_index_lookup",
        "class_name": "FaissIndexLookup", "function": "search", "is_builtin": true,
        "package": "promptflow-vectordb", "package_version": "0.0.1", "enable_kwargs":
        false, "tool_state": "stable"}, {"name": "Vector DB Lookup", "type": "python",
        "inputs": {"class_name": {"type": ["string"], "enabled_by": "connection",
        "enabled_by_type": ["WeaviateConnection"], "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}, "collection_name": {"type": ["string"], "enabled_by":
        "connection", "enabled_by_type": ["QdrantConnection"], "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "connection": {"type":
        ["CognitiveSearchConnection", "QdrantConnection", "WeaviateConnection"], "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "index_name": {"type":
        ["string"], "enabled_by": "connection", "enabled_by_type": ["CognitiveSearchConnection"],
        "allow_manual_entry": false, "is_multi_select": false, "input_type": "default"},
        "search_filters": {"type": ["object"], "enabled_by": "connection", "enabled_by_type":
        ["CognitiveSearchConnection", "QdrantConnection"], "allow_manual_entry": false,
        "is_multi_select": false, "input_type": "default"}, "search_params": {"type":
        ["object"], "enabled_by": "connection", "enabled_by_type": ["CognitiveSearchConnection",
        "QdrantConnection"], "allow_manual_entry": false, "is_multi_select": false,
        "input_type": "default"}, "text_field": {"type": ["string"], "enabled_by":
        "connection", "enabled_by_type": ["CognitiveSearchConnection", "QdrantConnection",
        "WeaviateConnection"], "allow_manual_entry": false, "is_multi_select": false,
        "input_type": "default"}, "top_k": {"type": ["int"], "default": "3", "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "vector": {"type":
        ["list"], "allow_manual_entry": false, "is_multi_select": false, "input_type":
        "default"}, "vector_field": {"type": ["string"], "enabled_by": "connection",
        "enabled_by_type": ["CognitiveSearchConnection"], "allow_manual_entry": false,
        "is_multi_select": false, "input_type": "default"}}, "description": "Search
        vector based query from existing Vector Database.", "module": "promptflow_vectordb.tool.vector_db_lookup",
        "class_name": "VectorDBLookup", "function": "search", "is_builtin": true,
        "package": "promptflow-vectordb", "package_version": "0.0.1", "enable_kwargs":
        false, "tool_state": "stable"}, {"name": "Vector Index Lookup", "type": "python",
        "inputs": {"path": {"type": ["string"], "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}, "query": {"type": ["object"], "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "top_k": {"type":
        ["int"], "default": "3", "allow_manual_entry": false, "is_multi_select": false,
        "input_type": "default"}}, "description": "Search text or vector based query
        from AzureML Vector Index.", "module": "promptflow_vectordb.tool.vector_index_lookup",
        "class_name": "VectorIndexLookup", "function": "search", "is_builtin": true,
        "package": "promptflow-vectordb", "package_version": "0.0.1", "enable_kwargs":
        false, "tool_state": "stable"}, {"name": "mod_two.py", "type": "python", "inputs":
        {"number": {"type": ["int"], "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}}, "source": "mod_two.py", "function": "mod_two",
        "is_builtin": false, "enable_kwargs": false, "tool_state": "stable"}], "inputs":
        {"number": {"type": "int", "is_chat_input": false}}, "outputs": {"output":
        {"type": "int", "reference": "${mod_two.output.value}", "evaluation_only":
        false, "is_chat_output": false}}}, "flowRunResourceId": "azureml://locations/eastus/workspaces/00000/flows/run1/flowRuns/run1",
        "flowRunId": "run1", "flowRunDisplayName": "run1", "batchDataInput": {"dataUri":
        "azureml://datastores/workspaceblobstore/paths/LocalUpload/7e5ac781513436b66626132fefb20d1f/numbers.jsonl"},
        "flowRunType": "FlowRun", "flowType": "Default", "runtimeName": "test-runtime-ci",
        "inputsMapping": {"number": "${data.value}"}, "outputDatastoreName": "workspaceblobstore",
        "childRunBasePath": "promptflow/PromptFlowArtifacts/run1/flow_artifacts",
        "flowDagFileRelativePath": "flow.dag.yaml", "flowSnapshotId": "9db0d05b-bc15-4802-9391-43ba16c34ae1",
        "studioPortalEndpoint": "https://ml.azure.com/runs/run1?wsid=/subscriptions/00000000-0000-0000-0000-000000000000/resourcegroups/00000/providers/Microsoft.MachineLearningServices/workspaces/00000"}'
    headers:
      connection:
      - keep-alive
      content-length:
      - '12860'
      content-type:
      - application/json; charset=utf-8
      strict-transport-security:
      - max-age=15724800; includeSubDomains; preload
      transfer-encoding:
      - chunked
      vary:
      - Accept-Encoding
      x-content-type-options:
      - nosniff
      x-request-time:
      - '0.209'
    status:
      code: 200
      message: OK
- request:
    body: null
    headers:
      Accept:
      - application/json
      Accept-Encoding:
      - gzip, deflate
      Connection:
      - keep-alive
      User-Agent:
      - promptflow-sdk/0.0.1 azsdk-python-azuremachinelearningdesignerserviceclient/unknown
        Python/3.10.13 (Windows-10-10.0.22631-SP0)
    method: GET
    uri: https://eastus.api.azureml.ms/flow/api/subscriptions/00000000-0000-0000-0000-000000000000/resourceGroups/00000/providers/Microsoft.MachineLearningServices/workspaces/00000/BulkRuns/run1
  response:
    body:
      string: '{"flowGraph": {"nodes": [{"name": "mod_two", "type": "python", "source":
        {"type": "code", "path": "mod_two.py"}, "inputs": {"number": "${inputs.number}"},
        "tool": "mod_two.py", "reduce": false}], "tools": [{"name": "Content Safety
        (Text Analyze)", "type": "python", "inputs": {"connection": {"type": ["AzureContentSafetyConnection"],
        "allow_manual_entry": false, "is_multi_select": false, "input_type": "default"},
        "hate_category": {"type": ["string"], "default": "medium_sensitivity", "enum":
        ["disable", "low_sensitivity", "medium_sensitivity", "high_sensitivity"],
        "allow_manual_entry": false, "is_multi_select": false, "input_type": "default"},
        "self_harm_category": {"type": ["string"], "default": "medium_sensitivity",
        "enum": ["disable", "low_sensitivity", "medium_sensitivity", "high_sensitivity"],
        "allow_manual_entry": false, "is_multi_select": false, "input_type": "default"},
        "sexual_category": {"type": ["string"], "default": "medium_sensitivity", "enum":
        ["disable", "low_sensitivity", "medium_sensitivity", "high_sensitivity"],
        "allow_manual_entry": false, "is_multi_select": false, "input_type": "default"},
        "text": {"type": ["string"], "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}, "violence_category": {"type": ["string"],
        "default": "medium_sensitivity", "enum": ["disable", "low_sensitivity", "medium_sensitivity",
        "high_sensitivity"], "allow_manual_entry": false, "is_multi_select": false,
        "input_type": "default"}}, "description": "Use Azure Content Safety to detect
        harmful content.", "module": "promptflow.tools.azure_content_safety", "function":
        "analyze_text", "is_builtin": true, "package": "promptflow-tools", "package_version":
        "0.0.216", "enable_kwargs": false, "deprecated_tools": ["content_safety_text.tools.content_safety_text_tool.analyze_text"],
        "tool_state": "stable"}, {"name": "Embedding", "type": "python", "inputs":
        {"connection": {"type": ["AzureOpenAIConnection", "OpenAIConnection"], "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "deployment_name":
        {"type": ["string"], "enabled_by": "connection", "enabled_by_type": ["AzureOpenAIConnection"],
        "model_list": ["text-embedding-ada-002", "text-search-ada-doc-001", "text-search-ada-query-001"],
        "capabilities": {"completion": false, "chat_completion": false, "embeddings":
        true}, "allow_manual_entry": false, "is_multi_select": false, "input_type":
        "default"}, "input": {"type": ["string"], "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}, "model": {"type": ["string"], "enum": ["text-embedding-ada-002",
        "text-search-ada-doc-001", "text-search-ada-query-001"], "enabled_by": "connection",
        "enabled_by_type": ["OpenAIConnection"], "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}}, "description": "Use Open AI''s embedding
        model to create an embedding vector representing the input text.", "module":
        "promptflow.tools.embedding", "function": "embedding", "is_builtin": true,
        "package": "promptflow-tools", "package_version": "0.0.216", "enable_kwargs":
        false, "tool_state": "stable"}, {"name": "Open Source LLM", "type": "custom_llm",
        "inputs": {"api": {"type": ["string"], "enum": ["chat", "completion"], "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "connection": {"type":
        ["CustomConnection"], "allow_manual_entry": false, "is_multi_select": false,
        "input_type": "default"}, "deployment_name": {"type": ["string"], "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "endpoint_name":
        {"type": ["string"], "default": "-- please enter an endpoint name --", "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "max_new_tokens":
        {"type": ["int"], "default": 500, "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}, "model_kwargs": {"type": ["object"], "default":
        "{}", "allow_manual_entry": false, "is_multi_select": false, "input_type":
        "default", "advanced": true}, "temperature": {"type": ["double"], "default":
        1.0, "allow_manual_entry": false, "is_multi_select": false, "input_type":
        "default"}, "top_p": {"type": ["double"], "default": 1.0, "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default", "advanced": true}},
        "description": "Use an Open Source model from the Azure Model catalog, deployed
        to an AzureML Online Endpoint for LLM Chat or Completion API calls.", "module":
        "promptflow.tools.open_source_llm", "class_name": "OpenSourceLLM", "function":
        "call", "icon": "data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAACgElEQVR4nGWSz2vcVRTFP/e9NzOZ1KDGohASslLEH6VLV0ak4l/QpeDCrfQPcNGliODKnVm4EBdBsIjQIlhciKW0ycKFVCSNbYnjdDLtmPnmO/nO9917XcxMkjYX3uLx7nnn3HOuMK2Nix4fP78ZdrYXVkLVWjf3l3B1B+HpcjzGFtmqa6cePz7/x0dnn1n5qhj3iBJPYREIURAJuCtpY8PjReDbrf9WG7H1fuefwQU9qKztTcMJT+PNnEFvjGVDBDlSsH6p/9MLzy6+NxwVqI8RAg4IPmWedMckdLYP6O6UpIaQfvyyXG012+e79/ZfHukoS1ISMT2hGTB1RkUmNgQ5QZ0w+a2VWDq73MbdEWmfnnv6UWe7oNzPaLapl5CwuLTXK9WUGBuCjqekzhP+z52ZXOrKMD3OJg0Hh778aiOuvpnYvp05d6GJO4iAO4QAe/eV36/X5LFRV4Zmn+AdkqlL8Vjp3oVioOz+WTPzzYEgsN+fgPLYyJVheSbPPVl2ikeGZRjtG52/8rHuaV9VOlpP2OtKyVndcRVCSqOhsvxa4vW359i6OuKdD+aP8Q4SYPdOzS/flGjt1JUSaMqZ5nwa1Y8qWb/Ud/eZZkHisYezEM0m+fcelDr8F1SqW2LNK6r1jXQwyLzy1hxvrLXZulry7ocL+FS6G4QIu3fG/Px1gdYeW7LIgXU2P/115TOA5G7e3Rmj2aS/m7l5pThiZzrCcE/d1XHzbln373nw7y6veeoUm5KCNKT/IPPwbiY1hYd/l5MIT65BMFt87sU4v9D7/JMflr44uV6hGh1+L4RCkg6z5iK2tAhNLeLsNGwYA4fDYnC/drvuuFxe86NV/x+Ut27g0FvykgAAAABJRU5ErkJggg==",
        "is_builtin": true, "package": "promptflow-tools", "package_version": "0.0.216",
        "enable_kwargs": false, "tool_state": "stable"}, {"name": "OpenAI GPT-4V",
        "type": "custom_llm", "inputs": {"connection": {"type": ["OpenAIConnection"],
        "allow_manual_entry": false, "is_multi_select": false, "input_type": "default"},
        "frequency_penalty": {"type": ["double"], "default": 0, "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "max_tokens": {"type":
        ["int"], "default": "", "allow_manual_entry": false, "is_multi_select": false,
        "input_type": "default"}, "model": {"type": ["string"], "enum": ["gpt-4-vision-preview"],
        "allow_manual_entry": true, "is_multi_select": false, "input_type": "default"},
        "presence_penalty": {"type": ["double"], "default": 0, "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "stop": {"type":
        ["list"], "default": "", "allow_manual_entry": false, "is_multi_select": false,
        "input_type": "default"}, "temperature": {"type": ["double"], "default": 1,
        "allow_manual_entry": false, "is_multi_select": false, "input_type": "default"},
        "top_p": {"type": ["double"], "default": 1, "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}}, "description": "Use OpenAI GPT-4V to leverage
        vision ability.", "module": "promptflow.tools.openai_gpt4v", "class_name":
        "OpenAI", "function": "chat", "is_builtin": true, "package": "promptflow-tools",
        "package_version": "0.0.216", "default_prompt": "# system:\nAs an AI assistant,
        your task involves interpreting images and responding to questions about the
        image.\nRemember to provide accurate answers based on the information present
        in the image.\n\n# user:\nCan you tell me what the image depicts?\n![image]({{image_input}})\n",
        "enable_kwargs": false, "tool_state": "stable"}, {"name": "Serp API", "type":
        "python", "inputs": {"connection": {"type": ["SerpConnection"], "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "engine": {"type":
        ["string"], "default": "google", "enum": ["google", "bing"], "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "location": {"type":
        ["string"], "default": "", "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}, "num": {"type": ["int"], "default": "10",
        "allow_manual_entry": false, "is_multi_select": false, "input_type": "default"},
        "query": {"type": ["string"], "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}, "safe": {"type": ["string"], "default": "off",
        "enum": ["active", "off"], "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}}, "description": "Use Serp API to obtain search
        results from a specific search engine.", "module": "promptflow.tools.serpapi",
        "class_name": "SerpAPI", "function": "search", "is_builtin": true, "package":
        "promptflow-tools", "package_version": "0.0.216", "enable_kwargs": false,
        "tool_state": "stable"}, {"name": "Faiss Index Lookup", "type": "python",
        "inputs": {"path": {"type": ["string"], "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}, "top_k": {"type": ["int"], "default": "3",
        "allow_manual_entry": false, "is_multi_select": false, "input_type": "default"},
        "vector": {"type": ["list"], "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}}, "description": "Search vector based query
        from the FAISS index file.", "module": "promptflow_vectordb.tool.faiss_index_lookup",
        "class_name": "FaissIndexLookup", "function": "search", "is_builtin": true,
        "package": "promptflow-vectordb", "package_version": "0.0.1", "enable_kwargs":
        false, "tool_state": "stable"}, {"name": "Vector DB Lookup", "type": "python",
        "inputs": {"class_name": {"type": ["string"], "enabled_by": "connection",
        "enabled_by_type": ["WeaviateConnection"], "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}, "collection_name": {"type": ["string"], "enabled_by":
        "connection", "enabled_by_type": ["QdrantConnection"], "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "connection": {"type":
        ["CognitiveSearchConnection", "QdrantConnection", "WeaviateConnection"], "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "index_name": {"type":
        ["string"], "enabled_by": "connection", "enabled_by_type": ["CognitiveSearchConnection"],
        "allow_manual_entry": false, "is_multi_select": false, "input_type": "default"},
        "search_filters": {"type": ["object"], "enabled_by": "connection", "enabled_by_type":
        ["CognitiveSearchConnection", "QdrantConnection"], "allow_manual_entry": false,
        "is_multi_select": false, "input_type": "default"}, "search_params": {"type":
        ["object"], "enabled_by": "connection", "enabled_by_type": ["CognitiveSearchConnection",
        "QdrantConnection"], "allow_manual_entry": false, "is_multi_select": false,
        "input_type": "default"}, "text_field": {"type": ["string"], "enabled_by":
        "connection", "enabled_by_type": ["CognitiveSearchConnection", "QdrantConnection",
        "WeaviateConnection"], "allow_manual_entry": false, "is_multi_select": false,
        "input_type": "default"}, "top_k": {"type": ["int"], "default": "3", "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "vector": {"type":
        ["list"], "allow_manual_entry": false, "is_multi_select": false, "input_type":
        "default"}, "vector_field": {"type": ["string"], "enabled_by": "connection",
        "enabled_by_type": ["CognitiveSearchConnection"], "allow_manual_entry": false,
        "is_multi_select": false, "input_type": "default"}}, "description": "Search
        vector based query from existing Vector Database.", "module": "promptflow_vectordb.tool.vector_db_lookup",
        "class_name": "VectorDBLookup", "function": "search", "is_builtin": true,
        "package": "promptflow-vectordb", "package_version": "0.0.1", "enable_kwargs":
        false, "tool_state": "stable"}, {"name": "Vector Index Lookup", "type": "python",
        "inputs": {"path": {"type": ["string"], "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}, "query": {"type": ["object"], "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "top_k": {"type":
        ["int"], "default": "3", "allow_manual_entry": false, "is_multi_select": false,
        "input_type": "default"}}, "description": "Search text or vector based query
        from AzureML Vector Index.", "module": "promptflow_vectordb.tool.vector_index_lookup",
        "class_name": "VectorIndexLookup", "function": "search", "is_builtin": true,
        "package": "promptflow-vectordb", "package_version": "0.0.1", "enable_kwargs":
        false, "tool_state": "stable"}, {"name": "mod_two.py", "type": "python", "inputs":
        {"number": {"type": ["int"], "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}}, "source": "mod_two.py", "function": "mod_two",
        "is_builtin": false, "enable_kwargs": false, "tool_state": "stable"}], "inputs":
        {"number": {"type": "int", "is_chat_input": false}}, "outputs": {"output":
        {"type": "int", "reference": "${mod_two.output.value}", "evaluation_only":
        false, "is_chat_output": false}}}, "flowRunResourceId": "azureml://locations/eastus/workspaces/00000/flows/run1/flowRuns/run1",
        "flowRunId": "run1", "flowRunDisplayName": "run1", "batchDataInput": {"dataUri":
        "azureml://datastores/workspaceblobstore/paths/LocalUpload/7e5ac781513436b66626132fefb20d1f/numbers.jsonl"},
        "flowRunType": "FlowRun", "flowType": "Default", "runtimeName": "test-runtime-ci",
        "inputsMapping": {"number": "${data.value}"}, "outputDatastoreName": "workspaceblobstore",
        "childRunBasePath": "promptflow/PromptFlowArtifacts/run1/flow_artifacts",
        "flowDagFileRelativePath": "flow.dag.yaml", "flowSnapshotId": "9db0d05b-bc15-4802-9391-43ba16c34ae1",
        "studioPortalEndpoint": "https://ml.azure.com/runs/run1?wsid=/subscriptions/00000000-0000-0000-0000-000000000000/resourcegroups/00000/providers/Microsoft.MachineLearningServices/workspaces/00000"}'
    headers:
      connection:
      - keep-alive
      content-length:
      - '12860'
      content-type:
      - application/json; charset=utf-8
      strict-transport-security:
      - max-age=15724800; includeSubDomains; preload
      transfer-encoding:
      - chunked
      vary:
      - Accept-Encoding
      x-content-type-options:
      - nosniff
      x-request-time:
      - '0.244'
    status:
      code: 200
      message: OK
- request:
    body: null
    headers:
      Accept:
      - application/json
      Accept-Encoding:
      - gzip, deflate
      Connection:
      - keep-alive
      User-Agent:
      - promptflow-sdk/0.0.1 azsdk-python-azuremachinelearningdesignerserviceclient/unknown
        Python/3.10.13 (Windows-10-10.0.22631-SP0)
    method: GET
    uri: https://eastus.api.azureml.ms/flow/api/subscriptions/00000000-0000-0000-0000-000000000000/resourceGroups/00000/providers/Microsoft.MachineLearningServices/workspaces/00000/BulkRuns/run1
  response:
    body:
      string: '{"flowGraph": {"nodes": [{"name": "mod_two", "type": "python", "source":
        {"type": "code", "path": "mod_two.py"}, "inputs": {"number": "${inputs.number}"},
        "tool": "mod_two.py", "reduce": false}], "tools": [{"name": "Content Safety
        (Text Analyze)", "type": "python", "inputs": {"connection": {"type": ["AzureContentSafetyConnection"],
        "allow_manual_entry": false, "is_multi_select": false, "input_type": "default"},
        "hate_category": {"type": ["string"], "default": "medium_sensitivity", "enum":
        ["disable", "low_sensitivity", "medium_sensitivity", "high_sensitivity"],
        "allow_manual_entry": false, "is_multi_select": false, "input_type": "default"},
        "self_harm_category": {"type": ["string"], "default": "medium_sensitivity",
        "enum": ["disable", "low_sensitivity", "medium_sensitivity", "high_sensitivity"],
        "allow_manual_entry": false, "is_multi_select": false, "input_type": "default"},
        "sexual_category": {"type": ["string"], "default": "medium_sensitivity", "enum":
        ["disable", "low_sensitivity", "medium_sensitivity", "high_sensitivity"],
        "allow_manual_entry": false, "is_multi_select": false, "input_type": "default"},
        "text": {"type": ["string"], "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}, "violence_category": {"type": ["string"],
        "default": "medium_sensitivity", "enum": ["disable", "low_sensitivity", "medium_sensitivity",
        "high_sensitivity"], "allow_manual_entry": false, "is_multi_select": false,
        "input_type": "default"}}, "description": "Use Azure Content Safety to detect
        harmful content.", "module": "promptflow.tools.azure_content_safety", "function":
        "analyze_text", "is_builtin": true, "package": "promptflow-tools", "package_version":
        "0.0.216", "enable_kwargs": false, "deprecated_tools": ["content_safety_text.tools.content_safety_text_tool.analyze_text"],
        "tool_state": "stable"}, {"name": "Embedding", "type": "python", "inputs":
        {"connection": {"type": ["AzureOpenAIConnection", "OpenAIConnection"], "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "deployment_name":
        {"type": ["string"], "enabled_by": "connection", "enabled_by_type": ["AzureOpenAIConnection"],
        "model_list": ["text-embedding-ada-002", "text-search-ada-doc-001", "text-search-ada-query-001"],
        "capabilities": {"completion": false, "chat_completion": false, "embeddings":
        true}, "allow_manual_entry": false, "is_multi_select": false, "input_type":
        "default"}, "input": {"type": ["string"], "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}, "model": {"type": ["string"], "enum": ["text-embedding-ada-002",
        "text-search-ada-doc-001", "text-search-ada-query-001"], "enabled_by": "connection",
        "enabled_by_type": ["OpenAIConnection"], "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}}, "description": "Use Open AI''s embedding
        model to create an embedding vector representing the input text.", "module":
        "promptflow.tools.embedding", "function": "embedding", "is_builtin": true,
        "package": "promptflow-tools", "package_version": "0.0.216", "enable_kwargs":
        false, "tool_state": "stable"}, {"name": "Open Source LLM", "type": "custom_llm",
        "inputs": {"api": {"type": ["string"], "enum": ["chat", "completion"], "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "connection": {"type":
        ["CustomConnection"], "allow_manual_entry": false, "is_multi_select": false,
        "input_type": "default"}, "deployment_name": {"type": ["string"], "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "endpoint_name":
        {"type": ["string"], "default": "-- please enter an endpoint name --", "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "max_new_tokens":
        {"type": ["int"], "default": 500, "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}, "model_kwargs": {"type": ["object"], "default":
        "{}", "allow_manual_entry": false, "is_multi_select": false, "input_type":
        "default", "advanced": true}, "temperature": {"type": ["double"], "default":
        1.0, "allow_manual_entry": false, "is_multi_select": false, "input_type":
        "default"}, "top_p": {"type": ["double"], "default": 1.0, "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default", "advanced": true}},
        "description": "Use an Open Source model from the Azure Model catalog, deployed
        to an AzureML Online Endpoint for LLM Chat or Completion API calls.", "module":
        "promptflow.tools.open_source_llm", "class_name": "OpenSourceLLM", "function":
        "call", "icon": "data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAACgElEQVR4nGWSz2vcVRTFP/e9NzOZ1KDGohASslLEH6VLV0ak4l/QpeDCrfQPcNGliODKnVm4EBdBsIjQIlhciKW0ycKFVCSNbYnjdDLtmPnmO/nO9917XcxMkjYX3uLx7nnn3HOuMK2Nix4fP78ZdrYXVkLVWjf3l3B1B+HpcjzGFtmqa6cePz7/x0dnn1n5qhj3iBJPYREIURAJuCtpY8PjReDbrf9WG7H1fuefwQU9qKztTcMJT+PNnEFvjGVDBDlSsH6p/9MLzy6+NxwVqI8RAg4IPmWedMckdLYP6O6UpIaQfvyyXG012+e79/ZfHukoS1ISMT2hGTB1RkUmNgQ5QZ0w+a2VWDq73MbdEWmfnnv6UWe7oNzPaLapl5CwuLTXK9WUGBuCjqekzhP+z52ZXOrKMD3OJg0Hh778aiOuvpnYvp05d6GJO4iAO4QAe/eV36/X5LFRV4Zmn+AdkqlL8Vjp3oVioOz+WTPzzYEgsN+fgPLYyJVheSbPPVl2ikeGZRjtG52/8rHuaV9VOlpP2OtKyVndcRVCSqOhsvxa4vW359i6OuKdD+aP8Q4SYPdOzS/flGjt1JUSaMqZ5nwa1Y8qWb/Ud/eZZkHisYezEM0m+fcelDr8F1SqW2LNK6r1jXQwyLzy1hxvrLXZulry7ocL+FS6G4QIu3fG/Px1gdYeW7LIgXU2P/115TOA5G7e3Rmj2aS/m7l5pThiZzrCcE/d1XHzbln373nw7y6veeoUm5KCNKT/IPPwbiY1hYd/l5MIT65BMFt87sU4v9D7/JMflr44uV6hGh1+L4RCkg6z5iK2tAhNLeLsNGwYA4fDYnC/drvuuFxe86NV/x+Ut27g0FvykgAAAABJRU5ErkJggg==",
        "is_builtin": true, "package": "promptflow-tools", "package_version": "0.0.216",
        "enable_kwargs": false, "tool_state": "stable"}, {"name": "OpenAI GPT-4V",
        "type": "custom_llm", "inputs": {"connection": {"type": ["OpenAIConnection"],
        "allow_manual_entry": false, "is_multi_select": false, "input_type": "default"},
        "frequency_penalty": {"type": ["double"], "default": 0, "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "max_tokens": {"type":
        ["int"], "default": "", "allow_manual_entry": false, "is_multi_select": false,
        "input_type": "default"}, "model": {"type": ["string"], "enum": ["gpt-4-vision-preview"],
        "allow_manual_entry": true, "is_multi_select": false, "input_type": "default"},
        "presence_penalty": {"type": ["double"], "default": 0, "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "stop": {"type":
        ["list"], "default": "", "allow_manual_entry": false, "is_multi_select": false,
        "input_type": "default"}, "temperature": {"type": ["double"], "default": 1,
        "allow_manual_entry": false, "is_multi_select": false, "input_type": "default"},
        "top_p": {"type": ["double"], "default": 1, "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}}, "description": "Use OpenAI GPT-4V to leverage
        vision ability.", "module": "promptflow.tools.openai_gpt4v", "class_name":
        "OpenAI", "function": "chat", "is_builtin": true, "package": "promptflow-tools",
        "package_version": "0.0.216", "default_prompt": "# system:\nAs an AI assistant,
        your task involves interpreting images and responding to questions about the
        image.\nRemember to provide accurate answers based on the information present
        in the image.\n\n# user:\nCan you tell me what the image depicts?\n![image]({{image_input}})\n",
        "enable_kwargs": false, "tool_state": "stable"}, {"name": "Serp API", "type":
        "python", "inputs": {"connection": {"type": ["SerpConnection"], "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "engine": {"type":
        ["string"], "default": "google", "enum": ["google", "bing"], "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "location": {"type":
        ["string"], "default": "", "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}, "num": {"type": ["int"], "default": "10",
        "allow_manual_entry": false, "is_multi_select": false, "input_type": "default"},
        "query": {"type": ["string"], "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}, "safe": {"type": ["string"], "default": "off",
        "enum": ["active", "off"], "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}}, "description": "Use Serp API to obtain search
        results from a specific search engine.", "module": "promptflow.tools.serpapi",
        "class_name": "SerpAPI", "function": "search", "is_builtin": true, "package":
        "promptflow-tools", "package_version": "0.0.216", "enable_kwargs": false,
        "tool_state": "stable"}, {"name": "Faiss Index Lookup", "type": "python",
        "inputs": {"path": {"type": ["string"], "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}, "top_k": {"type": ["int"], "default": "3",
        "allow_manual_entry": false, "is_multi_select": false, "input_type": "default"},
        "vector": {"type": ["list"], "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}}, "description": "Search vector based query
        from the FAISS index file.", "module": "promptflow_vectordb.tool.faiss_index_lookup",
        "class_name": "FaissIndexLookup", "function": "search", "is_builtin": true,
        "package": "promptflow-vectordb", "package_version": "0.0.1", "enable_kwargs":
        false, "tool_state": "stable"}, {"name": "Vector DB Lookup", "type": "python",
        "inputs": {"class_name": {"type": ["string"], "enabled_by": "connection",
        "enabled_by_type": ["WeaviateConnection"], "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}, "collection_name": {"type": ["string"], "enabled_by":
        "connection", "enabled_by_type": ["QdrantConnection"], "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "connection": {"type":
        ["CognitiveSearchConnection", "QdrantConnection", "WeaviateConnection"], "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "index_name": {"type":
        ["string"], "enabled_by": "connection", "enabled_by_type": ["CognitiveSearchConnection"],
        "allow_manual_entry": false, "is_multi_select": false, "input_type": "default"},
        "search_filters": {"type": ["object"], "enabled_by": "connection", "enabled_by_type":
        ["CognitiveSearchConnection", "QdrantConnection"], "allow_manual_entry": false,
        "is_multi_select": false, "input_type": "default"}, "search_params": {"type":
        ["object"], "enabled_by": "connection", "enabled_by_type": ["CognitiveSearchConnection",
        "QdrantConnection"], "allow_manual_entry": false, "is_multi_select": false,
        "input_type": "default"}, "text_field": {"type": ["string"], "enabled_by":
        "connection", "enabled_by_type": ["CognitiveSearchConnection", "QdrantConnection",
        "WeaviateConnection"], "allow_manual_entry": false, "is_multi_select": false,
        "input_type": "default"}, "top_k": {"type": ["int"], "default": "3", "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "vector": {"type":
        ["list"], "allow_manual_entry": false, "is_multi_select": false, "input_type":
        "default"}, "vector_field": {"type": ["string"], "enabled_by": "connection",
        "enabled_by_type": ["CognitiveSearchConnection"], "allow_manual_entry": false,
        "is_multi_select": false, "input_type": "default"}}, "description": "Search
        vector based query from existing Vector Database.", "module": "promptflow_vectordb.tool.vector_db_lookup",
        "class_name": "VectorDBLookup", "function": "search", "is_builtin": true,
        "package": "promptflow-vectordb", "package_version": "0.0.1", "enable_kwargs":
        false, "tool_state": "stable"}, {"name": "Vector Index Lookup", "type": "python",
        "inputs": {"path": {"type": ["string"], "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}, "query": {"type": ["object"], "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "top_k": {"type":
        ["int"], "default": "3", "allow_manual_entry": false, "is_multi_select": false,
        "input_type": "default"}}, "description": "Search text or vector based query
        from AzureML Vector Index.", "module": "promptflow_vectordb.tool.vector_index_lookup",
        "class_name": "VectorIndexLookup", "function": "search", "is_builtin": true,
        "package": "promptflow-vectordb", "package_version": "0.0.1", "enable_kwargs":
        false, "tool_state": "stable"}, {"name": "mod_two.py", "type": "python", "inputs":
        {"number": {"type": ["int"], "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}}, "source": "mod_two.py", "function": "mod_two",
        "is_builtin": false, "enable_kwargs": false, "tool_state": "stable"}], "inputs":
        {"number": {"type": "int", "is_chat_input": false}}, "outputs": {"output":
        {"type": "int", "reference": "${mod_two.output.value}", "evaluation_only":
        false, "is_chat_output": false}}}, "flowRunResourceId": "azureml://locations/eastus/workspaces/00000/flows/run1/flowRuns/run1",
        "flowRunId": "run1", "flowRunDisplayName": "run1", "batchDataInput": {"dataUri":
        "azureml://datastores/workspaceblobstore/paths/LocalUpload/7e5ac781513436b66626132fefb20d1f/numbers.jsonl"},
        "flowRunType": "FlowRun", "flowType": "Default", "runtimeName": "test-runtime-ci",
        "inputsMapping": {"number": "${data.value}"}, "outputDatastoreName": "workspaceblobstore",
        "childRunBasePath": "promptflow/PromptFlowArtifacts/run1/flow_artifacts",
        "flowDagFileRelativePath": "flow.dag.yaml", "flowSnapshotId": "9db0d05b-bc15-4802-9391-43ba16c34ae1",
        "studioPortalEndpoint": "https://ml.azure.com/runs/run1?wsid=/subscriptions/00000000-0000-0000-0000-000000000000/resourcegroups/00000/providers/Microsoft.MachineLearningServices/workspaces/00000"}'
    headers:
      connection:
      - keep-alive
      content-length:
      - '12860'
      content-type:
      - application/json; charset=utf-8
      strict-transport-security:
      - max-age=15724800; includeSubDomains; preload
      transfer-encoding:
      - chunked
      vary:
      - Accept-Encoding
      x-content-type-options:
      - nosniff
      x-request-time:
      - '0.246'
    status:
      code: 200
      message: OK
- request:
    body: null
    headers:
      Accept:
      - application/json
      Accept-Encoding:
      - gzip, deflate
      Connection:
      - keep-alive
      User-Agent:
      - promptflow-sdk/0.0.1 azsdk-python-azuremachinelearningdesignerserviceclient/unknown
        Python/3.10.13 (Windows-10-10.0.22631-SP0)
    method: GET
    uri: https://eastus.api.azureml.ms/flow/api/subscriptions/00000000-0000-0000-0000-000000000000/resourceGroups/00000/providers/Microsoft.MachineLearningServices/workspaces/00000/BulkRuns/run1
  response:
    body:
      string: '{"flowGraph": {"nodes": [{"name": "mod_two", "type": "python", "source":
        {"type": "code", "path": "mod_two.py"}, "inputs": {"number": "${inputs.number}"},
        "tool": "mod_two.py", "reduce": false}], "tools": [{"name": "Content Safety
        (Text Analyze)", "type": "python", "inputs": {"connection": {"type": ["AzureContentSafetyConnection"],
        "allow_manual_entry": false, "is_multi_select": false, "input_type": "default"},
        "hate_category": {"type": ["string"], "default": "medium_sensitivity", "enum":
        ["disable", "low_sensitivity", "medium_sensitivity", "high_sensitivity"],
        "allow_manual_entry": false, "is_multi_select": false, "input_type": "default"},
        "self_harm_category": {"type": ["string"], "default": "medium_sensitivity",
        "enum": ["disable", "low_sensitivity", "medium_sensitivity", "high_sensitivity"],
        "allow_manual_entry": false, "is_multi_select": false, "input_type": "default"},
        "sexual_category": {"type": ["string"], "default": "medium_sensitivity", "enum":
        ["disable", "low_sensitivity", "medium_sensitivity", "high_sensitivity"],
        "allow_manual_entry": false, "is_multi_select": false, "input_type": "default"},
        "text": {"type": ["string"], "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}, "violence_category": {"type": ["string"],
        "default": "medium_sensitivity", "enum": ["disable", "low_sensitivity", "medium_sensitivity",
        "high_sensitivity"], "allow_manual_entry": false, "is_multi_select": false,
        "input_type": "default"}}, "description": "Use Azure Content Safety to detect
        harmful content.", "module": "promptflow.tools.azure_content_safety", "function":
        "analyze_text", "is_builtin": true, "package": "promptflow-tools", "package_version":
        "0.0.216", "enable_kwargs": false, "deprecated_tools": ["content_safety_text.tools.content_safety_text_tool.analyze_text"],
        "tool_state": "stable"}, {"name": "Embedding", "type": "python", "inputs":
        {"connection": {"type": ["AzureOpenAIConnection", "OpenAIConnection"], "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "deployment_name":
        {"type": ["string"], "enabled_by": "connection", "enabled_by_type": ["AzureOpenAIConnection"],
        "model_list": ["text-embedding-ada-002", "text-search-ada-doc-001", "text-search-ada-query-001"],
        "capabilities": {"completion": false, "chat_completion": false, "embeddings":
        true}, "allow_manual_entry": false, "is_multi_select": false, "input_type":
        "default"}, "input": {"type": ["string"], "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}, "model": {"type": ["string"], "enum": ["text-embedding-ada-002",
        "text-search-ada-doc-001", "text-search-ada-query-001"], "enabled_by": "connection",
        "enabled_by_type": ["OpenAIConnection"], "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}}, "description": "Use Open AI''s embedding
        model to create an embedding vector representing the input text.", "module":
        "promptflow.tools.embedding", "function": "embedding", "is_builtin": true,
        "package": "promptflow-tools", "package_version": "0.0.216", "enable_kwargs":
        false, "tool_state": "stable"}, {"name": "Open Source LLM", "type": "custom_llm",
        "inputs": {"api": {"type": ["string"], "enum": ["chat", "completion"], "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "connection": {"type":
        ["CustomConnection"], "allow_manual_entry": false, "is_multi_select": false,
        "input_type": "default"}, "deployment_name": {"type": ["string"], "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "endpoint_name":
        {"type": ["string"], "default": "-- please enter an endpoint name --", "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "max_new_tokens":
        {"type": ["int"], "default": 500, "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}, "model_kwargs": {"type": ["object"], "default":
        "{}", "allow_manual_entry": false, "is_multi_select": false, "input_type":
        "default", "advanced": true}, "temperature": {"type": ["double"], "default":
        1.0, "allow_manual_entry": false, "is_multi_select": false, "input_type":
        "default"}, "top_p": {"type": ["double"], "default": 1.0, "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default", "advanced": true}},
        "description": "Use an Open Source model from the Azure Model catalog, deployed
        to an AzureML Online Endpoint for LLM Chat or Completion API calls.", "module":
        "promptflow.tools.open_source_llm", "class_name": "OpenSourceLLM", "function":
        "call", "icon": "data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAACgElEQVR4nGWSz2vcVRTFP/e9NzOZ1KDGohASslLEH6VLV0ak4l/QpeDCrfQPcNGliODKnVm4EBdBsIjQIlhciKW0ycKFVCSNbYnjdDLtmPnmO/nO9917XcxMkjYX3uLx7nnn3HOuMK2Nix4fP78ZdrYXVkLVWjf3l3B1B+HpcjzGFtmqa6cePz7/x0dnn1n5qhj3iBJPYREIURAJuCtpY8PjReDbrf9WG7H1fuefwQU9qKztTcMJT+PNnEFvjGVDBDlSsH6p/9MLzy6+NxwVqI8RAg4IPmWedMckdLYP6O6UpIaQfvyyXG012+e79/ZfHukoS1ISMT2hGTB1RkUmNgQ5QZ0w+a2VWDq73MbdEWmfnnv6UWe7oNzPaLapl5CwuLTXK9WUGBuCjqekzhP+z52ZXOrKMD3OJg0Hh778aiOuvpnYvp05d6GJO4iAO4QAe/eV36/X5LFRV4Zmn+AdkqlL8Vjp3oVioOz+WTPzzYEgsN+fgPLYyJVheSbPPVl2ikeGZRjtG52/8rHuaV9VOlpP2OtKyVndcRVCSqOhsvxa4vW359i6OuKdD+aP8Q4SYPdOzS/flGjt1JUSaMqZ5nwa1Y8qWb/Ud/eZZkHisYezEM0m+fcelDr8F1SqW2LNK6r1jXQwyLzy1hxvrLXZulry7ocL+FS6G4QIu3fG/Px1gdYeW7LIgXU2P/115TOA5G7e3Rmj2aS/m7l5pThiZzrCcE/d1XHzbln373nw7y6veeoUm5KCNKT/IPPwbiY1hYd/l5MIT65BMFt87sU4v9D7/JMflr44uV6hGh1+L4RCkg6z5iK2tAhNLeLsNGwYA4fDYnC/drvuuFxe86NV/x+Ut27g0FvykgAAAABJRU5ErkJggg==",
        "is_builtin": true, "package": "promptflow-tools", "package_version": "0.0.216",
        "enable_kwargs": false, "tool_state": "stable"}, {"name": "OpenAI GPT-4V",
        "type": "custom_llm", "inputs": {"connection": {"type": ["OpenAIConnection"],
        "allow_manual_entry": false, "is_multi_select": false, "input_type": "default"},
        "frequency_penalty": {"type": ["double"], "default": 0, "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "max_tokens": {"type":
        ["int"], "default": "", "allow_manual_entry": false, "is_multi_select": false,
        "input_type": "default"}, "model": {"type": ["string"], "enum": ["gpt-4-vision-preview"],
        "allow_manual_entry": true, "is_multi_select": false, "input_type": "default"},
        "presence_penalty": {"type": ["double"], "default": 0, "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "stop": {"type":
        ["list"], "default": "", "allow_manual_entry": false, "is_multi_select": false,
        "input_type": "default"}, "temperature": {"type": ["double"], "default": 1,
        "allow_manual_entry": false, "is_multi_select": false, "input_type": "default"},
        "top_p": {"type": ["double"], "default": 1, "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}}, "description": "Use OpenAI GPT-4V to leverage
        vision ability.", "module": "promptflow.tools.openai_gpt4v", "class_name":
        "OpenAI", "function": "chat", "is_builtin": true, "package": "promptflow-tools",
        "package_version": "0.0.216", "default_prompt": "# system:\nAs an AI assistant,
        your task involves interpreting images and responding to questions about the
        image.\nRemember to provide accurate answers based on the information present
        in the image.\n\n# user:\nCan you tell me what the image depicts?\n![image]({{image_input}})\n",
        "enable_kwargs": false, "tool_state": "stable"}, {"name": "Serp API", "type":
        "python", "inputs": {"connection": {"type": ["SerpConnection"], "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "engine": {"type":
        ["string"], "default": "google", "enum": ["google", "bing"], "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "location": {"type":
        ["string"], "default": "", "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}, "num": {"type": ["int"], "default": "10",
        "allow_manual_entry": false, "is_multi_select": false, "input_type": "default"},
        "query": {"type": ["string"], "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}, "safe": {"type": ["string"], "default": "off",
        "enum": ["active", "off"], "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}}, "description": "Use Serp API to obtain search
        results from a specific search engine.", "module": "promptflow.tools.serpapi",
        "class_name": "SerpAPI", "function": "search", "is_builtin": true, "package":
        "promptflow-tools", "package_version": "0.0.216", "enable_kwargs": false,
        "tool_state": "stable"}, {"name": "Faiss Index Lookup", "type": "python",
        "inputs": {"path": {"type": ["string"], "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}, "top_k": {"type": ["int"], "default": "3",
        "allow_manual_entry": false, "is_multi_select": false, "input_type": "default"},
        "vector": {"type": ["list"], "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}}, "description": "Search vector based query
        from the FAISS index file.", "module": "promptflow_vectordb.tool.faiss_index_lookup",
        "class_name": "FaissIndexLookup", "function": "search", "is_builtin": true,
        "package": "promptflow-vectordb", "package_version": "0.0.1", "enable_kwargs":
        false, "tool_state": "stable"}, {"name": "Vector DB Lookup", "type": "python",
        "inputs": {"class_name": {"type": ["string"], "enabled_by": "connection",
        "enabled_by_type": ["WeaviateConnection"], "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}, "collection_name": {"type": ["string"], "enabled_by":
        "connection", "enabled_by_type": ["QdrantConnection"], "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "connection": {"type":
        ["CognitiveSearchConnection", "QdrantConnection", "WeaviateConnection"], "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "index_name": {"type":
        ["string"], "enabled_by": "connection", "enabled_by_type": ["CognitiveSearchConnection"],
        "allow_manual_entry": false, "is_multi_select": false, "input_type": "default"},
        "search_filters": {"type": ["object"], "enabled_by": "connection", "enabled_by_type":
        ["CognitiveSearchConnection", "QdrantConnection"], "allow_manual_entry": false,
        "is_multi_select": false, "input_type": "default"}, "search_params": {"type":
        ["object"], "enabled_by": "connection", "enabled_by_type": ["CognitiveSearchConnection",
        "QdrantConnection"], "allow_manual_entry": false, "is_multi_select": false,
        "input_type": "default"}, "text_field": {"type": ["string"], "enabled_by":
        "connection", "enabled_by_type": ["CognitiveSearchConnection", "QdrantConnection",
        "WeaviateConnection"], "allow_manual_entry": false, "is_multi_select": false,
        "input_type": "default"}, "top_k": {"type": ["int"], "default": "3", "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "vector": {"type":
        ["list"], "allow_manual_entry": false, "is_multi_select": false, "input_type":
        "default"}, "vector_field": {"type": ["string"], "enabled_by": "connection",
        "enabled_by_type": ["CognitiveSearchConnection"], "allow_manual_entry": false,
        "is_multi_select": false, "input_type": "default"}}, "description": "Search
        vector based query from existing Vector Database.", "module": "promptflow_vectordb.tool.vector_db_lookup",
        "class_name": "VectorDBLookup", "function": "search", "is_builtin": true,
        "package": "promptflow-vectordb", "package_version": "0.0.1", "enable_kwargs":
        false, "tool_state": "stable"}, {"name": "Vector Index Lookup", "type": "python",
        "inputs": {"path": {"type": ["string"], "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}, "query": {"type": ["object"], "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "top_k": {"type":
        ["int"], "default": "3", "allow_manual_entry": false, "is_multi_select": false,
        "input_type": "default"}}, "description": "Search text or vector based query
        from AzureML Vector Index.", "module": "promptflow_vectordb.tool.vector_index_lookup",
        "class_name": "VectorIndexLookup", "function": "search", "is_builtin": true,
        "package": "promptflow-vectordb", "package_version": "0.0.1", "enable_kwargs":
        false, "tool_state": "stable"}, {"name": "mod_two.py", "type": "python", "inputs":
        {"number": {"type": ["int"], "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}}, "source": "mod_two.py", "function": "mod_two",
        "is_builtin": false, "enable_kwargs": false, "tool_state": "stable"}], "inputs":
        {"number": {"type": "int", "is_chat_input": false}}, "outputs": {"output":
        {"type": "int", "reference": "${mod_two.output.value}", "evaluation_only":
        false, "is_chat_output": false}}}, "flowRunResourceId": "azureml://locations/eastus/workspaces/00000/flows/run1/flowRuns/run1",
        "flowRunId": "run1", "flowRunDisplayName": "run1", "batchDataInput": {"dataUri":
        "azureml://datastores/workspaceblobstore/paths/LocalUpload/7e5ac781513436b66626132fefb20d1f/numbers.jsonl"},
        "flowRunType": "FlowRun", "flowType": "Default", "runtimeName": "test-runtime-ci",
        "inputsMapping": {"number": "${data.value}"}, "outputDatastoreName": "workspaceblobstore",
        "childRunBasePath": "promptflow/PromptFlowArtifacts/run1/flow_artifacts",
        "flowDagFileRelativePath": "flow.dag.yaml", "flowSnapshotId": "9db0d05b-bc15-4802-9391-43ba16c34ae1",
        "studioPortalEndpoint": "https://ml.azure.com/runs/run1?wsid=/subscriptions/00000000-0000-0000-0000-000000000000/resourcegroups/00000/providers/Microsoft.MachineLearningServices/workspaces/00000"}'
    headers:
      connection:
      - keep-alive
      content-length:
      - '12860'
      content-type:
      - application/json; charset=utf-8
      strict-transport-security:
      - max-age=15724800; includeSubDomains; preload
      transfer-encoding:
      - chunked
      vary:
      - Accept-Encoding
      x-content-type-options:
      - nosniff
      x-request-time:
      - '0.294'
    status:
      code: 200
      message: OK
- request:
    body: null
    headers:
      Accept:
      - application/json
      Accept-Encoding:
      - gzip, deflate
      Connection:
      - keep-alive
      User-Agent:
      - promptflow-sdk/0.0.1 azsdk-python-azuremachinelearningdesignerserviceclient/unknown
        Python/3.10.13 (Windows-10-10.0.22631-SP0)
    method: GET
    uri: https://eastus.api.azureml.ms/flow/api/subscriptions/00000000-0000-0000-0000-000000000000/resourceGroups/00000/providers/Microsoft.MachineLearningServices/workspaces/00000/BulkRuns/run1
  response:
    body:
      string: '{"flowGraph": {"nodes": [{"name": "mod_two", "type": "python", "source":
        {"type": "code", "path": "mod_two.py"}, "inputs": {"number": "${inputs.number}"},
        "tool": "mod_two.py", "reduce": false}], "tools": [{"name": "Content Safety
        (Text Analyze)", "type": "python", "inputs": {"connection": {"type": ["AzureContentSafetyConnection"],
        "allow_manual_entry": false, "is_multi_select": false, "input_type": "default"},
        "hate_category": {"type": ["string"], "default": "medium_sensitivity", "enum":
        ["disable", "low_sensitivity", "medium_sensitivity", "high_sensitivity"],
        "allow_manual_entry": false, "is_multi_select": false, "input_type": "default"},
        "self_harm_category": {"type": ["string"], "default": "medium_sensitivity",
        "enum": ["disable", "low_sensitivity", "medium_sensitivity", "high_sensitivity"],
        "allow_manual_entry": false, "is_multi_select": false, "input_type": "default"},
        "sexual_category": {"type": ["string"], "default": "medium_sensitivity", "enum":
        ["disable", "low_sensitivity", "medium_sensitivity", "high_sensitivity"],
        "allow_manual_entry": false, "is_multi_select": false, "input_type": "default"},
        "text": {"type": ["string"], "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}, "violence_category": {"type": ["string"],
        "default": "medium_sensitivity", "enum": ["disable", "low_sensitivity", "medium_sensitivity",
        "high_sensitivity"], "allow_manual_entry": false, "is_multi_select": false,
        "input_type": "default"}}, "description": "Use Azure Content Safety to detect
        harmful content.", "module": "promptflow.tools.azure_content_safety", "function":
        "analyze_text", "is_builtin": true, "package": "promptflow-tools", "package_version":
        "0.0.216", "enable_kwargs": false, "deprecated_tools": ["content_safety_text.tools.content_safety_text_tool.analyze_text"],
        "tool_state": "stable"}, {"name": "Embedding", "type": "python", "inputs":
        {"connection": {"type": ["AzureOpenAIConnection", "OpenAIConnection"], "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "deployment_name":
        {"type": ["string"], "enabled_by": "connection", "enabled_by_type": ["AzureOpenAIConnection"],
        "model_list": ["text-embedding-ada-002", "text-search-ada-doc-001", "text-search-ada-query-001"],
        "capabilities": {"completion": false, "chat_completion": false, "embeddings":
        true}, "allow_manual_entry": false, "is_multi_select": false, "input_type":
        "default"}, "input": {"type": ["string"], "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}, "model": {"type": ["string"], "enum": ["text-embedding-ada-002",
        "text-search-ada-doc-001", "text-search-ada-query-001"], "enabled_by": "connection",
        "enabled_by_type": ["OpenAIConnection"], "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}}, "description": "Use Open AI''s embedding
        model to create an embedding vector representing the input text.", "module":
        "promptflow.tools.embedding", "function": "embedding", "is_builtin": true,
        "package": "promptflow-tools", "package_version": "0.0.216", "enable_kwargs":
        false, "tool_state": "stable"}, {"name": "Open Source LLM", "type": "custom_llm",
        "inputs": {"api": {"type": ["string"], "enum": ["chat", "completion"], "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "connection": {"type":
        ["CustomConnection"], "allow_manual_entry": false, "is_multi_select": false,
        "input_type": "default"}, "deployment_name": {"type": ["string"], "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "endpoint_name":
        {"type": ["string"], "default": "-- please enter an endpoint name --", "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "max_new_tokens":
        {"type": ["int"], "default": 500, "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}, "model_kwargs": {"type": ["object"], "default":
        "{}", "allow_manual_entry": false, "is_multi_select": false, "input_type":
        "default", "advanced": true}, "temperature": {"type": ["double"], "default":
        1.0, "allow_manual_entry": false, "is_multi_select": false, "input_type":
        "default"}, "top_p": {"type": ["double"], "default": 1.0, "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default", "advanced": true}},
        "description": "Use an Open Source model from the Azure Model catalog, deployed
        to an AzureML Online Endpoint for LLM Chat or Completion API calls.", "module":
        "promptflow.tools.open_source_llm", "class_name": "OpenSourceLLM", "function":
        "call", "icon": "data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAACgElEQVR4nGWSz2vcVRTFP/e9NzOZ1KDGohASslLEH6VLV0ak4l/QpeDCrfQPcNGliODKnVm4EBdBsIjQIlhciKW0ycKFVCSNbYnjdDLtmPnmO/nO9917XcxMkjYX3uLx7nnn3HOuMK2Nix4fP78ZdrYXVkLVWjf3l3B1B+HpcjzGFtmqa6cePz7/x0dnn1n5qhj3iBJPYREIURAJuCtpY8PjReDbrf9WG7H1fuefwQU9qKztTcMJT+PNnEFvjGVDBDlSsH6p/9MLzy6+NxwVqI8RAg4IPmWedMckdLYP6O6UpIaQfvyyXG012+e79/ZfHukoS1ISMT2hGTB1RkUmNgQ5QZ0w+a2VWDq73MbdEWmfnnv6UWe7oNzPaLapl5CwuLTXK9WUGBuCjqekzhP+z52ZXOrKMD3OJg0Hh778aiOuvpnYvp05d6GJO4iAO4QAe/eV36/X5LFRV4Zmn+AdkqlL8Vjp3oVioOz+WTPzzYEgsN+fgPLYyJVheSbPPVl2ikeGZRjtG52/8rHuaV9VOlpP2OtKyVndcRVCSqOhsvxa4vW359i6OuKdD+aP8Q4SYPdOzS/flGjt1JUSaMqZ5nwa1Y8qWb/Ud/eZZkHisYezEM0m+fcelDr8F1SqW2LNK6r1jXQwyLzy1hxvrLXZulry7ocL+FS6G4QIu3fG/Px1gdYeW7LIgXU2P/115TOA5G7e3Rmj2aS/m7l5pThiZzrCcE/d1XHzbln373nw7y6veeoUm5KCNKT/IPPwbiY1hYd/l5MIT65BMFt87sU4v9D7/JMflr44uV6hGh1+L4RCkg6z5iK2tAhNLeLsNGwYA4fDYnC/drvuuFxe86NV/x+Ut27g0FvykgAAAABJRU5ErkJggg==",
        "is_builtin": true, "package": "promptflow-tools", "package_version": "0.0.216",
        "enable_kwargs": false, "tool_state": "stable"}, {"name": "OpenAI GPT-4V",
        "type": "custom_llm", "inputs": {"connection": {"type": ["OpenAIConnection"],
        "allow_manual_entry": false, "is_multi_select": false, "input_type": "default"},
        "frequency_penalty": {"type": ["double"], "default": 0, "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "max_tokens": {"type":
        ["int"], "default": "", "allow_manual_entry": false, "is_multi_select": false,
        "input_type": "default"}, "model": {"type": ["string"], "enum": ["gpt-4-vision-preview"],
        "allow_manual_entry": true, "is_multi_select": false, "input_type": "default"},
        "presence_penalty": {"type": ["double"], "default": 0, "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "stop": {"type":
        ["list"], "default": "", "allow_manual_entry": false, "is_multi_select": false,
        "input_type": "default"}, "temperature": {"type": ["double"], "default": 1,
        "allow_manual_entry": false, "is_multi_select": false, "input_type": "default"},
        "top_p": {"type": ["double"], "default": 1, "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}}, "description": "Use OpenAI GPT-4V to leverage
        vision ability.", "module": "promptflow.tools.openai_gpt4v", "class_name":
        "OpenAI", "function": "chat", "is_builtin": true, "package": "promptflow-tools",
        "package_version": "0.0.216", "default_prompt": "# system:\nAs an AI assistant,
        your task involves interpreting images and responding to questions about the
        image.\nRemember to provide accurate answers based on the information present
        in the image.\n\n# user:\nCan you tell me what the image depicts?\n![image]({{image_input}})\n",
        "enable_kwargs": false, "tool_state": "stable"}, {"name": "Serp API", "type":
        "python", "inputs": {"connection": {"type": ["SerpConnection"], "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "engine": {"type":
        ["string"], "default": "google", "enum": ["google", "bing"], "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "location": {"type":
        ["string"], "default": "", "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}, "num": {"type": ["int"], "default": "10",
        "allow_manual_entry": false, "is_multi_select": false, "input_type": "default"},
        "query": {"type": ["string"], "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}, "safe": {"type": ["string"], "default": "off",
        "enum": ["active", "off"], "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}}, "description": "Use Serp API to obtain search
        results from a specific search engine.", "module": "promptflow.tools.serpapi",
        "class_name": "SerpAPI", "function": "search", "is_builtin": true, "package":
        "promptflow-tools", "package_version": "0.0.216", "enable_kwargs": false,
        "tool_state": "stable"}, {"name": "Faiss Index Lookup", "type": "python",
        "inputs": {"path": {"type": ["string"], "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}, "top_k": {"type": ["int"], "default": "3",
        "allow_manual_entry": false, "is_multi_select": false, "input_type": "default"},
        "vector": {"type": ["list"], "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}}, "description": "Search vector based query
        from the FAISS index file.", "module": "promptflow_vectordb.tool.faiss_index_lookup",
        "class_name": "FaissIndexLookup", "function": "search", "is_builtin": true,
        "package": "promptflow-vectordb", "package_version": "0.0.1", "enable_kwargs":
        false, "tool_state": "stable"}, {"name": "Vector DB Lookup", "type": "python",
        "inputs": {"class_name": {"type": ["string"], "enabled_by": "connection",
        "enabled_by_type": ["WeaviateConnection"], "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}, "collection_name": {"type": ["string"], "enabled_by":
        "connection", "enabled_by_type": ["QdrantConnection"], "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "connection": {"type":
        ["CognitiveSearchConnection", "QdrantConnection", "WeaviateConnection"], "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "index_name": {"type":
        ["string"], "enabled_by": "connection", "enabled_by_type": ["CognitiveSearchConnection"],
        "allow_manual_entry": false, "is_multi_select": false, "input_type": "default"},
        "search_filters": {"type": ["object"], "enabled_by": "connection", "enabled_by_type":
        ["CognitiveSearchConnection", "QdrantConnection"], "allow_manual_entry": false,
        "is_multi_select": false, "input_type": "default"}, "search_params": {"type":
        ["object"], "enabled_by": "connection", "enabled_by_type": ["CognitiveSearchConnection",
        "QdrantConnection"], "allow_manual_entry": false, "is_multi_select": false,
        "input_type": "default"}, "text_field": {"type": ["string"], "enabled_by":
        "connection", "enabled_by_type": ["CognitiveSearchConnection", "QdrantConnection",
        "WeaviateConnection"], "allow_manual_entry": false, "is_multi_select": false,
        "input_type": "default"}, "top_k": {"type": ["int"], "default": "3", "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "vector": {"type":
        ["list"], "allow_manual_entry": false, "is_multi_select": false, "input_type":
        "default"}, "vector_field": {"type": ["string"], "enabled_by": "connection",
        "enabled_by_type": ["CognitiveSearchConnection"], "allow_manual_entry": false,
        "is_multi_select": false, "input_type": "default"}}, "description": "Search
        vector based query from existing Vector Database.", "module": "promptflow_vectordb.tool.vector_db_lookup",
        "class_name": "VectorDBLookup", "function": "search", "is_builtin": true,
        "package": "promptflow-vectordb", "package_version": "0.0.1", "enable_kwargs":
        false, "tool_state": "stable"}, {"name": "Vector Index Lookup", "type": "python",
        "inputs": {"path": {"type": ["string"], "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}, "query": {"type": ["object"], "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "top_k": {"type":
        ["int"], "default": "3", "allow_manual_entry": false, "is_multi_select": false,
        "input_type": "default"}}, "description": "Search text or vector based query
        from AzureML Vector Index.", "module": "promptflow_vectordb.tool.vector_index_lookup",
        "class_name": "VectorIndexLookup", "function": "search", "is_builtin": true,
        "package": "promptflow-vectordb", "package_version": "0.0.1", "enable_kwargs":
        false, "tool_state": "stable"}, {"name": "mod_two.py", "type": "python", "inputs":
        {"number": {"type": ["int"], "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}}, "source": "mod_two.py", "function": "mod_two",
        "is_builtin": false, "enable_kwargs": false, "tool_state": "stable"}], "inputs":
        {"number": {"type": "int", "is_chat_input": false}}, "outputs": {"output":
        {"type": "int", "reference": "${mod_two.output.value}", "evaluation_only":
        false, "is_chat_output": false}}}, "flowRunResourceId": "azureml://locations/eastus/workspaces/00000/flows/run1/flowRuns/run1",
        "flowRunId": "run1", "flowRunDisplayName": "run1", "batchDataInput": {"dataUri":
        "azureml://datastores/workspaceblobstore/paths/LocalUpload/7e5ac781513436b66626132fefb20d1f/numbers.jsonl"},
        "flowRunType": "FlowRun", "flowType": "Default", "runtimeName": "test-runtime-ci",
        "inputsMapping": {"number": "${data.value}"}, "outputDatastoreName": "workspaceblobstore",
        "childRunBasePath": "promptflow/PromptFlowArtifacts/run1/flow_artifacts",
        "flowDagFileRelativePath": "flow.dag.yaml", "flowSnapshotId": "9db0d05b-bc15-4802-9391-43ba16c34ae1",
        "studioPortalEndpoint": "https://ml.azure.com/runs/run1?wsid=/subscriptions/00000000-0000-0000-0000-000000000000/resourcegroups/00000/providers/Microsoft.MachineLearningServices/workspaces/00000"}'
    headers:
      connection:
      - keep-alive
      content-length:
      - '12860'
      content-type:
      - application/json; charset=utf-8
      strict-transport-security:
      - max-age=15724800; includeSubDomains; preload
      transfer-encoding:
      - chunked
      vary:
      - Accept-Encoding
      x-content-type-options:
      - nosniff
      x-request-time:
      - '0.538'
    status:
      code: 200
      message: OK
- request:
    body: null
    headers:
      Accept:
      - application/json
      Accept-Encoding:
      - gzip, deflate
      Connection:
      - keep-alive
      User-Agent:
      - promptflow-sdk/0.0.1 azsdk-python-azuremachinelearningdesignerserviceclient/unknown
        Python/3.10.13 (Windows-10-10.0.22631-SP0)
    method: GET
    uri: https://eastus.api.azureml.ms/flow/api/subscriptions/00000000-0000-0000-0000-000000000000/resourceGroups/00000/providers/Microsoft.MachineLearningServices/workspaces/00000/BulkRuns/run1
  response:
    body:
      string: '{"flowGraph": {"nodes": [{"name": "mod_two", "type": "python", "source":
        {"type": "code", "path": "mod_two.py"}, "inputs": {"number": "${inputs.number}"},
        "tool": "mod_two.py", "reduce": false}], "tools": [{"name": "Content Safety
        (Text Analyze)", "type": "python", "inputs": {"connection": {"type": ["AzureContentSafetyConnection"],
        "allow_manual_entry": false, "is_multi_select": false, "input_type": "default"},
        "hate_category": {"type": ["string"], "default": "medium_sensitivity", "enum":
        ["disable", "low_sensitivity", "medium_sensitivity", "high_sensitivity"],
        "allow_manual_entry": false, "is_multi_select": false, "input_type": "default"},
        "self_harm_category": {"type": ["string"], "default": "medium_sensitivity",
        "enum": ["disable", "low_sensitivity", "medium_sensitivity", "high_sensitivity"],
        "allow_manual_entry": false, "is_multi_select": false, "input_type": "default"},
        "sexual_category": {"type": ["string"], "default": "medium_sensitivity", "enum":
        ["disable", "low_sensitivity", "medium_sensitivity", "high_sensitivity"],
        "allow_manual_entry": false, "is_multi_select": false, "input_type": "default"},
        "text": {"type": ["string"], "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}, "violence_category": {"type": ["string"],
        "default": "medium_sensitivity", "enum": ["disable", "low_sensitivity", "medium_sensitivity",
        "high_sensitivity"], "allow_manual_entry": false, "is_multi_select": false,
        "input_type": "default"}}, "description": "Use Azure Content Safety to detect
        harmful content.", "module": "promptflow.tools.azure_content_safety", "function":
        "analyze_text", "is_builtin": true, "package": "promptflow-tools", "package_version":
        "0.0.216", "enable_kwargs": false, "deprecated_tools": ["content_safety_text.tools.content_safety_text_tool.analyze_text"],
        "tool_state": "stable"}, {"name": "Embedding", "type": "python", "inputs":
        {"connection": {"type": ["AzureOpenAIConnection", "OpenAIConnection"], "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "deployment_name":
        {"type": ["string"], "enabled_by": "connection", "enabled_by_type": ["AzureOpenAIConnection"],
        "model_list": ["text-embedding-ada-002", "text-search-ada-doc-001", "text-search-ada-query-001"],
        "capabilities": {"completion": false, "chat_completion": false, "embeddings":
        true}, "allow_manual_entry": false, "is_multi_select": false, "input_type":
        "default"}, "input": {"type": ["string"], "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}, "model": {"type": ["string"], "enum": ["text-embedding-ada-002",
        "text-search-ada-doc-001", "text-search-ada-query-001"], "enabled_by": "connection",
        "enabled_by_type": ["OpenAIConnection"], "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}}, "description": "Use Open AI''s embedding
        model to create an embedding vector representing the input text.", "module":
        "promptflow.tools.embedding", "function": "embedding", "is_builtin": true,
        "package": "promptflow-tools", "package_version": "0.0.216", "enable_kwargs":
        false, "tool_state": "stable"}, {"name": "Open Source LLM", "type": "custom_llm",
        "inputs": {"api": {"type": ["string"], "enum": ["chat", "completion"], "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "connection": {"type":
        ["CustomConnection"], "allow_manual_entry": false, "is_multi_select": false,
        "input_type": "default"}, "deployment_name": {"type": ["string"], "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "endpoint_name":
        {"type": ["string"], "default": "-- please enter an endpoint name --", "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "max_new_tokens":
        {"type": ["int"], "default": 500, "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}, "model_kwargs": {"type": ["object"], "default":
        "{}", "allow_manual_entry": false, "is_multi_select": false, "input_type":
        "default", "advanced": true}, "temperature": {"type": ["double"], "default":
        1.0, "allow_manual_entry": false, "is_multi_select": false, "input_type":
        "default"}, "top_p": {"type": ["double"], "default": 1.0, "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default", "advanced": true}},
        "description": "Use an Open Source model from the Azure Model catalog, deployed
        to an AzureML Online Endpoint for LLM Chat or Completion API calls.", "module":
        "promptflow.tools.open_source_llm", "class_name": "OpenSourceLLM", "function":
        "call", "icon": "data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAACgElEQVR4nGWSz2vcVRTFP/e9NzOZ1KDGohASslLEH6VLV0ak4l/QpeDCrfQPcNGliODKnVm4EBdBsIjQIlhciKW0ycKFVCSNbYnjdDLtmPnmO/nO9917XcxMkjYX3uLx7nnn3HOuMK2Nix4fP78ZdrYXVkLVWjf3l3B1B+HpcjzGFtmqa6cePz7/x0dnn1n5qhj3iBJPYREIURAJuCtpY8PjReDbrf9WG7H1fuefwQU9qKztTcMJT+PNnEFvjGVDBDlSsH6p/9MLzy6+NxwVqI8RAg4IPmWedMckdLYP6O6UpIaQfvyyXG012+e79/ZfHukoS1ISMT2hGTB1RkUmNgQ5QZ0w+a2VWDq73MbdEWmfnnv6UWe7oNzPaLapl5CwuLTXK9WUGBuCjqekzhP+z52ZXOrKMD3OJg0Hh778aiOuvpnYvp05d6GJO4iAO4QAe/eV36/X5LFRV4Zmn+AdkqlL8Vjp3oVioOz+WTPzzYEgsN+fgPLYyJVheSbPPVl2ikeGZRjtG52/8rHuaV9VOlpP2OtKyVndcRVCSqOhsvxa4vW359i6OuKdD+aP8Q4SYPdOzS/flGjt1JUSaMqZ5nwa1Y8qWb/Ud/eZZkHisYezEM0m+fcelDr8F1SqW2LNK6r1jXQwyLzy1hxvrLXZulry7ocL+FS6G4QIu3fG/Px1gdYeW7LIgXU2P/115TOA5G7e3Rmj2aS/m7l5pThiZzrCcE/d1XHzbln373nw7y6veeoUm5KCNKT/IPPwbiY1hYd/l5MIT65BMFt87sU4v9D7/JMflr44uV6hGh1+L4RCkg6z5iK2tAhNLeLsNGwYA4fDYnC/drvuuFxe86NV/x+Ut27g0FvykgAAAABJRU5ErkJggg==",
        "is_builtin": true, "package": "promptflow-tools", "package_version": "0.0.216",
        "enable_kwargs": false, "tool_state": "stable"}, {"name": "OpenAI GPT-4V",
        "type": "custom_llm", "inputs": {"connection": {"type": ["OpenAIConnection"],
        "allow_manual_entry": false, "is_multi_select": false, "input_type": "default"},
        "frequency_penalty": {"type": ["double"], "default": 0, "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "max_tokens": {"type":
        ["int"], "default": "", "allow_manual_entry": false, "is_multi_select": false,
        "input_type": "default"}, "model": {"type": ["string"], "enum": ["gpt-4-vision-preview"],
        "allow_manual_entry": true, "is_multi_select": false, "input_type": "default"},
        "presence_penalty": {"type": ["double"], "default": 0, "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "stop": {"type":
        ["list"], "default": "", "allow_manual_entry": false, "is_multi_select": false,
        "input_type": "default"}, "temperature": {"type": ["double"], "default": 1,
        "allow_manual_entry": false, "is_multi_select": false, "input_type": "default"},
        "top_p": {"type": ["double"], "default": 1, "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}}, "description": "Use OpenAI GPT-4V to leverage
        vision ability.", "module": "promptflow.tools.openai_gpt4v", "class_name":
        "OpenAI", "function": "chat", "is_builtin": true, "package": "promptflow-tools",
        "package_version": "0.0.216", "default_prompt": "# system:\nAs an AI assistant,
        your task involves interpreting images and responding to questions about the
        image.\nRemember to provide accurate answers based on the information present
        in the image.\n\n# user:\nCan you tell me what the image depicts?\n![image]({{image_input}})\n",
        "enable_kwargs": false, "tool_state": "stable"}, {"name": "Serp API", "type":
        "python", "inputs": {"connection": {"type": ["SerpConnection"], "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "engine": {"type":
        ["string"], "default": "google", "enum": ["google", "bing"], "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "location": {"type":
        ["string"], "default": "", "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}, "num": {"type": ["int"], "default": "10",
        "allow_manual_entry": false, "is_multi_select": false, "input_type": "default"},
        "query": {"type": ["string"], "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}, "safe": {"type": ["string"], "default": "off",
        "enum": ["active", "off"], "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}}, "description": "Use Serp API to obtain search
        results from a specific search engine.", "module": "promptflow.tools.serpapi",
        "class_name": "SerpAPI", "function": "search", "is_builtin": true, "package":
        "promptflow-tools", "package_version": "0.0.216", "enable_kwargs": false,
        "tool_state": "stable"}, {"name": "Faiss Index Lookup", "type": "python",
        "inputs": {"path": {"type": ["string"], "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}, "top_k": {"type": ["int"], "default": "3",
        "allow_manual_entry": false, "is_multi_select": false, "input_type": "default"},
        "vector": {"type": ["list"], "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}}, "description": "Search vector based query
        from the FAISS index file.", "module": "promptflow_vectordb.tool.faiss_index_lookup",
        "class_name": "FaissIndexLookup", "function": "search", "is_builtin": true,
        "package": "promptflow-vectordb", "package_version": "0.0.1", "enable_kwargs":
        false, "tool_state": "stable"}, {"name": "Vector DB Lookup", "type": "python",
        "inputs": {"class_name": {"type": ["string"], "enabled_by": "connection",
        "enabled_by_type": ["WeaviateConnection"], "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}, "collection_name": {"type": ["string"], "enabled_by":
        "connection", "enabled_by_type": ["QdrantConnection"], "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "connection": {"type":
        ["CognitiveSearchConnection", "QdrantConnection", "WeaviateConnection"], "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "index_name": {"type":
        ["string"], "enabled_by": "connection", "enabled_by_type": ["CognitiveSearchConnection"],
        "allow_manual_entry": false, "is_multi_select": false, "input_type": "default"},
        "search_filters": {"type": ["object"], "enabled_by": "connection", "enabled_by_type":
        ["CognitiveSearchConnection", "QdrantConnection"], "allow_manual_entry": false,
        "is_multi_select": false, "input_type": "default"}, "search_params": {"type":
        ["object"], "enabled_by": "connection", "enabled_by_type": ["CognitiveSearchConnection",
        "QdrantConnection"], "allow_manual_entry": false, "is_multi_select": false,
        "input_type": "default"}, "text_field": {"type": ["string"], "enabled_by":
        "connection", "enabled_by_type": ["CognitiveSearchConnection", "QdrantConnection",
        "WeaviateConnection"], "allow_manual_entry": false, "is_multi_select": false,
        "input_type": "default"}, "top_k": {"type": ["int"], "default": "3", "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "vector": {"type":
        ["list"], "allow_manual_entry": false, "is_multi_select": false, "input_type":
        "default"}, "vector_field": {"type": ["string"], "enabled_by": "connection",
        "enabled_by_type": ["CognitiveSearchConnection"], "allow_manual_entry": false,
        "is_multi_select": false, "input_type": "default"}}, "description": "Search
        vector based query from existing Vector Database.", "module": "promptflow_vectordb.tool.vector_db_lookup",
        "class_name": "VectorDBLookup", "function": "search", "is_builtin": true,
        "package": "promptflow-vectordb", "package_version": "0.0.1", "enable_kwargs":
        false, "tool_state": "stable"}, {"name": "Vector Index Lookup", "type": "python",
        "inputs": {"path": {"type": ["string"], "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}, "query": {"type": ["object"], "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "top_k": {"type":
        ["int"], "default": "3", "allow_manual_entry": false, "is_multi_select": false,
        "input_type": "default"}}, "description": "Search text or vector based query
        from AzureML Vector Index.", "module": "promptflow_vectordb.tool.vector_index_lookup",
        "class_name": "VectorIndexLookup", "function": "search", "is_builtin": true,
        "package": "promptflow-vectordb", "package_version": "0.0.1", "enable_kwargs":
        false, "tool_state": "stable"}, {"name": "mod_two.py", "type": "python", "inputs":
        {"number": {"type": ["int"], "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}}, "source": "mod_two.py", "function": "mod_two",
        "is_builtin": false, "enable_kwargs": false, "tool_state": "stable"}], "inputs":
        {"number": {"type": "int", "is_chat_input": false}}, "outputs": {"output":
        {"type": "int", "reference": "${mod_two.output.value}", "evaluation_only":
        false, "is_chat_output": false}}}, "flowRunResourceId": "azureml://locations/eastus/workspaces/00000/flows/run1/flowRuns/run1",
        "flowRunId": "run1", "flowRunDisplayName": "run1", "batchDataInput": {"dataUri":
        "azureml://datastores/workspaceblobstore/paths/LocalUpload/7e5ac781513436b66626132fefb20d1f/numbers.jsonl"},
        "flowRunType": "FlowRun", "flowType": "Default", "runtimeName": "test-runtime-ci",
        "inputsMapping": {"number": "${data.value}"}, "outputDatastoreName": "workspaceblobstore",
        "childRunBasePath": "promptflow/PromptFlowArtifacts/run1/flow_artifacts",
        "flowDagFileRelativePath": "flow.dag.yaml", "flowSnapshotId": "9db0d05b-bc15-4802-9391-43ba16c34ae1",
        "studioPortalEndpoint": "https://ml.azure.com/runs/run1?wsid=/subscriptions/00000000-0000-0000-0000-000000000000/resourcegroups/00000/providers/Microsoft.MachineLearningServices/workspaces/00000"}'
    headers:
      connection:
      - keep-alive
      content-length:
      - '12860'
      content-type:
      - application/json; charset=utf-8
      strict-transport-security:
      - max-age=15724800; includeSubDomains; preload
      transfer-encoding:
      - chunked
      vary:
      - Accept-Encoding
      x-content-type-options:
      - nosniff
      x-request-time:
      - '0.272'
    status:
      code: 200
      message: OK
- request:
    body: null
    headers:
      Accept:
      - application/json
      Accept-Encoding:
      - gzip, deflate
      Connection:
      - keep-alive
      User-Agent:
      - promptflow-sdk/0.0.1 azsdk-python-azuremachinelearningdesignerserviceclient/unknown
        Python/3.10.13 (Windows-10-10.0.22631-SP0)
    method: GET
    uri: https://eastus.api.azureml.ms/flow/api/subscriptions/00000000-0000-0000-0000-000000000000/resourceGroups/00000/providers/Microsoft.MachineLearningServices/workspaces/00000/BulkRuns/run1
  response:
    body:
      string: '{"flowGraph": {"nodes": [{"name": "mod_two", "type": "python", "source":
        {"type": "code", "path": "mod_two.py"}, "inputs": {"number": "${inputs.number}"},
        "tool": "mod_two.py", "reduce": false}], "tools": [{"name": "Content Safety
        (Text Analyze)", "type": "python", "inputs": {"connection": {"type": ["AzureContentSafetyConnection"],
        "allow_manual_entry": false, "is_multi_select": false, "input_type": "default"},
        "hate_category": {"type": ["string"], "default": "medium_sensitivity", "enum":
        ["disable", "low_sensitivity", "medium_sensitivity", "high_sensitivity"],
        "allow_manual_entry": false, "is_multi_select": false, "input_type": "default"},
        "self_harm_category": {"type": ["string"], "default": "medium_sensitivity",
        "enum": ["disable", "low_sensitivity", "medium_sensitivity", "high_sensitivity"],
        "allow_manual_entry": false, "is_multi_select": false, "input_type": "default"},
        "sexual_category": {"type": ["string"], "default": "medium_sensitivity", "enum":
        ["disable", "low_sensitivity", "medium_sensitivity", "high_sensitivity"],
        "allow_manual_entry": false, "is_multi_select": false, "input_type": "default"},
        "text": {"type": ["string"], "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}, "violence_category": {"type": ["string"],
        "default": "medium_sensitivity", "enum": ["disable", "low_sensitivity", "medium_sensitivity",
        "high_sensitivity"], "allow_manual_entry": false, "is_multi_select": false,
        "input_type": "default"}}, "description": "Use Azure Content Safety to detect
        harmful content.", "module": "promptflow.tools.azure_content_safety", "function":
        "analyze_text", "is_builtin": true, "package": "promptflow-tools", "package_version":
        "0.0.216", "enable_kwargs": false, "deprecated_tools": ["content_safety_text.tools.content_safety_text_tool.analyze_text"],
        "tool_state": "stable"}, {"name": "Embedding", "type": "python", "inputs":
        {"connection": {"type": ["AzureOpenAIConnection", "OpenAIConnection"], "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "deployment_name":
        {"type": ["string"], "enabled_by": "connection", "enabled_by_type": ["AzureOpenAIConnection"],
        "model_list": ["text-embedding-ada-002", "text-search-ada-doc-001", "text-search-ada-query-001"],
        "capabilities": {"completion": false, "chat_completion": false, "embeddings":
        true}, "allow_manual_entry": false, "is_multi_select": false, "input_type":
        "default"}, "input": {"type": ["string"], "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}, "model": {"type": ["string"], "enum": ["text-embedding-ada-002",
        "text-search-ada-doc-001", "text-search-ada-query-001"], "enabled_by": "connection",
        "enabled_by_type": ["OpenAIConnection"], "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}}, "description": "Use Open AI''s embedding
        model to create an embedding vector representing the input text.", "module":
        "promptflow.tools.embedding", "function": "embedding", "is_builtin": true,
        "package": "promptflow-tools", "package_version": "0.0.216", "enable_kwargs":
        false, "tool_state": "stable"}, {"name": "Open Source LLM", "type": "custom_llm",
        "inputs": {"api": {"type": ["string"], "enum": ["chat", "completion"], "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "connection": {"type":
        ["CustomConnection"], "allow_manual_entry": false, "is_multi_select": false,
        "input_type": "default"}, "deployment_name": {"type": ["string"], "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "endpoint_name":
        {"type": ["string"], "default": "-- please enter an endpoint name --", "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "max_new_tokens":
        {"type": ["int"], "default": 500, "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}, "model_kwargs": {"type": ["object"], "default":
        "{}", "allow_manual_entry": false, "is_multi_select": false, "input_type":
        "default", "advanced": true}, "temperature": {"type": ["double"], "default":
        1.0, "allow_manual_entry": false, "is_multi_select": false, "input_type":
        "default"}, "top_p": {"type": ["double"], "default": 1.0, "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default", "advanced": true}},
        "description": "Use an Open Source model from the Azure Model catalog, deployed
        to an AzureML Online Endpoint for LLM Chat or Completion API calls.", "module":
        "promptflow.tools.open_source_llm", "class_name": "OpenSourceLLM", "function":
        "call", "icon": "data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAACgElEQVR4nGWSz2vcVRTFP/e9NzOZ1KDGohASslLEH6VLV0ak4l/QpeDCrfQPcNGliODKnVm4EBdBsIjQIlhciKW0ycKFVCSNbYnjdDLtmPnmO/nO9917XcxMkjYX3uLx7nnn3HOuMK2Nix4fP78ZdrYXVkLVWjf3l3B1B+HpcjzGFtmqa6cePz7/x0dnn1n5qhj3iBJPYREIURAJuCtpY8PjReDbrf9WG7H1fuefwQU9qKztTcMJT+PNnEFvjGVDBDlSsH6p/9MLzy6+NxwVqI8RAg4IPmWedMckdLYP6O6UpIaQfvyyXG012+e79/ZfHukoS1ISMT2hGTB1RkUmNgQ5QZ0w+a2VWDq73MbdEWmfnnv6UWe7oNzPaLapl5CwuLTXK9WUGBuCjqekzhP+z52ZXOrKMD3OJg0Hh778aiOuvpnYvp05d6GJO4iAO4QAe/eV36/X5LFRV4Zmn+AdkqlL8Vjp3oVioOz+WTPzzYEgsN+fgPLYyJVheSbPPVl2ikeGZRjtG52/8rHuaV9VOlpP2OtKyVndcRVCSqOhsvxa4vW359i6OuKdD+aP8Q4SYPdOzS/flGjt1JUSaMqZ5nwa1Y8qWb/Ud/eZZkHisYezEM0m+fcelDr8F1SqW2LNK6r1jXQwyLzy1hxvrLXZulry7ocL+FS6G4QIu3fG/Px1gdYeW7LIgXU2P/115TOA5G7e3Rmj2aS/m7l5pThiZzrCcE/d1XHzbln373nw7y6veeoUm5KCNKT/IPPwbiY1hYd/l5MIT65BMFt87sU4v9D7/JMflr44uV6hGh1+L4RCkg6z5iK2tAhNLeLsNGwYA4fDYnC/drvuuFxe86NV/x+Ut27g0FvykgAAAABJRU5ErkJggg==",
        "is_builtin": true, "package": "promptflow-tools", "package_version": "0.0.216",
        "enable_kwargs": false, "tool_state": "stable"}, {"name": "OpenAI GPT-4V",
        "type": "custom_llm", "inputs": {"connection": {"type": ["OpenAIConnection"],
        "allow_manual_entry": false, "is_multi_select": false, "input_type": "default"},
        "frequency_penalty": {"type": ["double"], "default": 0, "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "max_tokens": {"type":
        ["int"], "default": "", "allow_manual_entry": false, "is_multi_select": false,
        "input_type": "default"}, "model": {"type": ["string"], "enum": ["gpt-4-vision-preview"],
        "allow_manual_entry": true, "is_multi_select": false, "input_type": "default"},
        "presence_penalty": {"type": ["double"], "default": 0, "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "stop": {"type":
        ["list"], "default": "", "allow_manual_entry": false, "is_multi_select": false,
        "input_type": "default"}, "temperature": {"type": ["double"], "default": 1,
        "allow_manual_entry": false, "is_multi_select": false, "input_type": "default"},
        "top_p": {"type": ["double"], "default": 1, "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}}, "description": "Use OpenAI GPT-4V to leverage
        vision ability.", "module": "promptflow.tools.openai_gpt4v", "class_name":
        "OpenAI", "function": "chat", "is_builtin": true, "package": "promptflow-tools",
        "package_version": "0.0.216", "default_prompt": "# system:\nAs an AI assistant,
        your task involves interpreting images and responding to questions about the
        image.\nRemember to provide accurate answers based on the information present
        in the image.\n\n# user:\nCan you tell me what the image depicts?\n![image]({{image_input}})\n",
        "enable_kwargs": false, "tool_state": "stable"}, {"name": "Serp API", "type":
        "python", "inputs": {"connection": {"type": ["SerpConnection"], "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "engine": {"type":
        ["string"], "default": "google", "enum": ["google", "bing"], "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "location": {"type":
        ["string"], "default": "", "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}, "num": {"type": ["int"], "default": "10",
        "allow_manual_entry": false, "is_multi_select": false, "input_type": "default"},
        "query": {"type": ["string"], "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}, "safe": {"type": ["string"], "default": "off",
        "enum": ["active", "off"], "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}}, "description": "Use Serp API to obtain search
        results from a specific search engine.", "module": "promptflow.tools.serpapi",
        "class_name": "SerpAPI", "function": "search", "is_builtin": true, "package":
        "promptflow-tools", "package_version": "0.0.216", "enable_kwargs": false,
        "tool_state": "stable"}, {"name": "Faiss Index Lookup", "type": "python",
        "inputs": {"path": {"type": ["string"], "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}, "top_k": {"type": ["int"], "default": "3",
        "allow_manual_entry": false, "is_multi_select": false, "input_type": "default"},
        "vector": {"type": ["list"], "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}}, "description": "Search vector based query
        from the FAISS index file.", "module": "promptflow_vectordb.tool.faiss_index_lookup",
        "class_name": "FaissIndexLookup", "function": "search", "is_builtin": true,
        "package": "promptflow-vectordb", "package_version": "0.0.1", "enable_kwargs":
        false, "tool_state": "stable"}, {"name": "Vector DB Lookup", "type": "python",
        "inputs": {"class_name": {"type": ["string"], "enabled_by": "connection",
        "enabled_by_type": ["WeaviateConnection"], "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}, "collection_name": {"type": ["string"], "enabled_by":
        "connection", "enabled_by_type": ["QdrantConnection"], "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "connection": {"type":
        ["CognitiveSearchConnection", "QdrantConnection", "WeaviateConnection"], "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "index_name": {"type":
        ["string"], "enabled_by": "connection", "enabled_by_type": ["CognitiveSearchConnection"],
        "allow_manual_entry": false, "is_multi_select": false, "input_type": "default"},
        "search_filters": {"type": ["object"], "enabled_by": "connection", "enabled_by_type":
        ["CognitiveSearchConnection", "QdrantConnection"], "allow_manual_entry": false,
        "is_multi_select": false, "input_type": "default"}, "search_params": {"type":
        ["object"], "enabled_by": "connection", "enabled_by_type": ["CognitiveSearchConnection",
        "QdrantConnection"], "allow_manual_entry": false, "is_multi_select": false,
        "input_type": "default"}, "text_field": {"type": ["string"], "enabled_by":
        "connection", "enabled_by_type": ["CognitiveSearchConnection", "QdrantConnection",
        "WeaviateConnection"], "allow_manual_entry": false, "is_multi_select": false,
        "input_type": "default"}, "top_k": {"type": ["int"], "default": "3", "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "vector": {"type":
        ["list"], "allow_manual_entry": false, "is_multi_select": false, "input_type":
        "default"}, "vector_field": {"type": ["string"], "enabled_by": "connection",
        "enabled_by_type": ["CognitiveSearchConnection"], "allow_manual_entry": false,
        "is_multi_select": false, "input_type": "default"}}, "description": "Search
        vector based query from existing Vector Database.", "module": "promptflow_vectordb.tool.vector_db_lookup",
        "class_name": "VectorDBLookup", "function": "search", "is_builtin": true,
        "package": "promptflow-vectordb", "package_version": "0.0.1", "enable_kwargs":
        false, "tool_state": "stable"}, {"name": "Vector Index Lookup", "type": "python",
        "inputs": {"path": {"type": ["string"], "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}, "query": {"type": ["object"], "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "top_k": {"type":
        ["int"], "default": "3", "allow_manual_entry": false, "is_multi_select": false,
        "input_type": "default"}}, "description": "Search text or vector based query
        from AzureML Vector Index.", "module": "promptflow_vectordb.tool.vector_index_lookup",
        "class_name": "VectorIndexLookup", "function": "search", "is_builtin": true,
        "package": "promptflow-vectordb", "package_version": "0.0.1", "enable_kwargs":
        false, "tool_state": "stable"}, {"name": "mod_two.py", "type": "python", "inputs":
        {"number": {"type": ["int"], "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}}, "source": "mod_two.py", "function": "mod_two",
        "is_builtin": false, "enable_kwargs": false, "tool_state": "stable"}], "inputs":
        {"number": {"type": "int", "is_chat_input": false}}, "outputs": {"output":
        {"type": "int", "reference": "${mod_two.output.value}", "evaluation_only":
        false, "is_chat_output": false}}}, "flowRunResourceId": "azureml://locations/eastus/workspaces/00000/flows/run1/flowRuns/run1",
        "flowRunId": "run1", "flowRunDisplayName": "run1", "batchDataInput": {"dataUri":
        "azureml://datastores/workspaceblobstore/paths/LocalUpload/7e5ac781513436b66626132fefb20d1f/numbers.jsonl"},
        "flowRunType": "FlowRun", "flowType": "Default", "runtimeName": "test-runtime-ci",
        "inputsMapping": {"number": "${data.value}"}, "outputDatastoreName": "workspaceblobstore",
        "childRunBasePath": "promptflow/PromptFlowArtifacts/run1/flow_artifacts",
        "flowDagFileRelativePath": "flow.dag.yaml", "flowSnapshotId": "9db0d05b-bc15-4802-9391-43ba16c34ae1",
        "studioPortalEndpoint": "https://ml.azure.com/runs/run1?wsid=/subscriptions/00000000-0000-0000-0000-000000000000/resourcegroups/00000/providers/Microsoft.MachineLearningServices/workspaces/00000"}'
    headers:
      connection:
      - keep-alive
      content-length:
      - '12860'
      content-type:
      - application/json; charset=utf-8
      strict-transport-security:
      - max-age=15724800; includeSubDomains; preload
      transfer-encoding:
      - chunked
      vary:
      - Accept-Encoding
      x-content-type-options:
      - nosniff
      x-request-time:
      - '0.291'
    status:
      code: 200
      message: OK
- request:
    body: null
    headers:
      Accept:
      - application/json
      Accept-Encoding:
      - gzip, deflate
      Connection:
      - keep-alive
      User-Agent:
      - promptflow-sdk/0.0.1 azsdk-python-azuremachinelearningdesignerserviceclient/unknown
        Python/3.10.13 (Windows-10-10.0.22631-SP0)
    method: GET
    uri: https://eastus.api.azureml.ms/flow/api/subscriptions/00000000-0000-0000-0000-000000000000/resourceGroups/00000/providers/Microsoft.MachineLearningServices/workspaces/00000/BulkRuns/run1/childRuns?endIndex=24&startIndex=0
  response:
    body:
      string: '[{"run_id": "run1_0", "status": "Completed", "error": null, "inputs":
        {"number": 0, "line_number": 0}, "output": {"output": 0}, "metrics": null,
        "request": null, "parent_run_id": "run1", "root_run_id": "run1", "source_run_id":
        null, "flow_id": "default_flow_id", "start_time": "2023-12-26T10:12:47.355006Z",
        "end_time": "2023-12-26T10:12:47.370302Z", "index": 0, "api_calls": [{"name":
        "mod_two", "type": "Tool", "inputs": {"number": 0}, "output": {"value": 0},
        "start_time": 1703585567.366799, "end_time": 1703585567.36778, "error": null,
        "children": null, "node_name": "mod_two"}], "variant_id": "", "name": "",
        "description": "", "tags": null, "system_metrics": {"duration": 0.015296,
        "prompt_tokens": 0, "completion_tokens": 0, "total_tokens": 0}, "result":
        {"output": 0}, "upload_metrics": false}, {"run_id": "run1_1", "status": "Failed",
        "error": {"message": "Execution failure in ''mod_two'': (Exception) cannot
        mod 2!", "messageFormat": "Execution failure in ''{node_name}'': {error_type_and_message}",
        "messageParameters": {"node_name": "mod_two", "error_type_and_message": "(Exception)
        cannot mod 2!"}, "referenceCode": "Tool/__pf_main__", "code": "UserError",
        "innerError": {"code": "ToolExecutionError", "innerError": null}, "additionalInfo":
        [{"type": "ToolExecutionErrorDetails", "info": {"type": "Exception", "message":
        "cannot mod 2!", "traceback": "Traceback (most recent call last):\n  File
        \"/mnt/host/service/app/39571/requests/run1/mod_two.py\", line 7, in mod_two\n    raise
        Exception(\"cannot mod 2!\")\nException: cannot mod 2!\n", "filename": "/mnt/host/service/app/39571/requests/run1/mod_two.py",
        "lineno": 7, "name": "mod_two"}}], "debugInfo": {"type": "ToolExecutionError",
        "message": "Execution failure in ''mod_two'': (Exception) cannot mod 2!",
        "stackTrace": "\nThe above exception was the direct cause of the following
        exception:\n\nTraceback (most recent call last):\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/executor/flow_executor.py\",
        line 804, in _exec\n    output, nodes_outputs = self._traverse_nodes(inputs,
        context)\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/executor/flow_executor.py\",
        line 890, in _traverse_nodes\n    nodes_outputs, bypassed_nodes = self._submit_to_scheduler(context,
        inputs, batch_nodes)\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/executor/flow_executor.py\",
        line 910, in _submit_to_scheduler\n    return FlowNodesScheduler(self._tools_manager,
        inputs, nodes, self._node_concurrency, context).execute()\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/executor/_flow_nodes_scheduler.py\",
        line 69, in execute\n    raise e\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/executor/_flow_nodes_scheduler.py\",
        line 58, in execute\n    self._dag_manager.complete_nodes(self._collect_outputs(completed_futures))\n  File
        \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/executor/_flow_nodes_scheduler.py\",
        line 90, in _collect_outputs\n    each_node_result = each_future.result()\n  File
        \"/azureml-envs/prompt-flow/runtime/lib/python3.10/concurrent/futures/_base.py\",
        line 451, in result\n    return self.__get_result()\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/concurrent/futures/_base.py\",
        line 403, in __get_result\n    raise self._exception\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/concurrent/futures/thread.py\",
        line 58, in run\n    result = self.fn(*self.args, **self.kwargs)\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/executor/_flow_nodes_scheduler.py\",
        line 111, in _exec_single_node_in_thread\n    result = context.invoke_tool(node,
        f, kwargs=kwargs)\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/_core/flow_execution_context.py\",
        line 89, in invoke_tool\n    result = self._invoke_tool_with_timer(node, f,
        kwargs)\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/_core/flow_execution_context.py\",
        line 196, in _invoke_tool_with_timer\n    raise ToolExecutionError(node_name=node_name,
        module=module) from e\n", "innerException": {"type": "Exception", "message":
        "cannot mod 2!", "stackTrace": "Traceback (most recent call last):\n  File
        \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/_core/flow_execution_context.py\",
        line 185, in _invoke_tool_with_timer\n    return f(**kwargs)\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/_core/tool.py\",
        line 106, in decorated_tool\n    output = func(*args, **kwargs)\n  File \"/mnt/host/service/app/39571/requests/run1/mod_two.py\",
        line 7, in mod_two\n    raise Exception(\"cannot mod 2!\")\n", "innerException":
        null}}}, "inputs": {"number": 1, "line_number": 1}, "output": null, "metrics":
        null, "request": null, "parent_run_id": "run1", "root_run_id": "run1", "source_run_id":
        null, "flow_id": "default_flow_id", "start_time": "2023-12-26T10:12:47.366642Z",
        "end_time": "2023-12-26T10:12:47.460676Z", "index": 1, "api_calls": [{"name":
        "mod_two", "type": "Tool", "inputs": {"number": 1}, "output": null, "start_time":
        1703585567.378396, "end_time": 1703585567.379194, "error": {"message": "cannot
        mod 2!", "type": "Exception"}, "children": null, "node_name": "mod_two"}],
        "variant_id": "", "name": "", "description": "", "tags": null, "system_metrics":
        {"duration": 0.094034, "prompt_tokens": 0, "completion_tokens": 0, "total_tokens":
        0}, "result": null, "upload_metrics": false}, {"run_id": "run1_5", "status":
        "Failed", "error": {"message": "Execution failure in ''mod_two'': (Exception)
        cannot mod 2!", "messageFormat": "Execution failure in ''{node_name}'': {error_type_and_message}",
        "messageParameters": {"node_name": "mod_two", "error_type_and_message": "(Exception)
        cannot mod 2!"}, "referenceCode": "Tool/__pf_main__", "code": "UserError",
        "innerError": {"code": "ToolExecutionError", "innerError": null}, "additionalInfo":
        [{"type": "ToolExecutionErrorDetails", "info": {"type": "Exception", "message":
        "cannot mod 2!", "traceback": "Traceback (most recent call last):\n  File
        \"/mnt/host/service/app/39571/requests/run1/mod_two.py\", line 7, in mod_two\n    raise
        Exception(\"cannot mod 2!\")\nException: cannot mod 2!\n", "filename": "/mnt/host/service/app/39571/requests/run1/mod_two.py",
        "lineno": 7, "name": "mod_two"}}], "debugInfo": {"type": "ToolExecutionError",
        "message": "Execution failure in ''mod_two'': (Exception) cannot mod 2!",
        "stackTrace": "\nThe above exception was the direct cause of the following
        exception:\n\nTraceback (most recent call last):\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/executor/flow_executor.py\",
        line 804, in _exec\n    output, nodes_outputs = self._traverse_nodes(inputs,
        context)\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/executor/flow_executor.py\",
        line 890, in _traverse_nodes\n    nodes_outputs, bypassed_nodes = self._submit_to_scheduler(context,
        inputs, batch_nodes)\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/executor/flow_executor.py\",
        line 910, in _submit_to_scheduler\n    return FlowNodesScheduler(self._tools_manager,
        inputs, nodes, self._node_concurrency, context).execute()\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/executor/_flow_nodes_scheduler.py\",
        line 69, in execute\n    raise e\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/executor/_flow_nodes_scheduler.py\",
        line 58, in execute\n    self._dag_manager.complete_nodes(self._collect_outputs(completed_futures))\n  File
        \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/executor/_flow_nodes_scheduler.py\",
        line 90, in _collect_outputs\n    each_node_result = each_future.result()\n  File
        \"/azureml-envs/prompt-flow/runtime/lib/python3.10/concurrent/futures/_base.py\",
        line 451, in result\n    return self.__get_result()\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/concurrent/futures/_base.py\",
        line 403, in __get_result\n    raise self._exception\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/concurrent/futures/thread.py\",
        line 58, in run\n    result = self.fn(*self.args, **self.kwargs)\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/executor/_flow_nodes_scheduler.py\",
        line 111, in _exec_single_node_in_thread\n    result = context.invoke_tool(node,
        f, kwargs=kwargs)\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/_core/flow_execution_context.py\",
        line 89, in invoke_tool\n    result = self._invoke_tool_with_timer(node, f,
        kwargs)\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/_core/flow_execution_context.py\",
        line 196, in _invoke_tool_with_timer\n    raise ToolExecutionError(node_name=node_name,
        module=module) from e\n", "innerException": {"type": "Exception", "message":
        "cannot mod 2!", "stackTrace": "Traceback (most recent call last):\n  File
        \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/_core/flow_execution_context.py\",
        line 185, in _invoke_tool_with_timer\n    return f(**kwargs)\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/_core/tool.py\",
        line 106, in decorated_tool\n    output = func(*args, **kwargs)\n  File \"/mnt/host/service/app/39571/requests/run1/mod_two.py\",
        line 7, in mod_two\n    raise Exception(\"cannot mod 2!\")\n", "innerException":
        null}}}, "inputs": {"number": 5, "line_number": 5}, "output": null, "metrics":
        null, "request": null, "parent_run_id": "run1", "root_run_id": "run1", "source_run_id":
        null, "flow_id": "default_flow_id", "start_time": "2023-12-26T10:12:47.500849Z",
        "end_time": "2023-12-26T10:12:47.53599Z", "index": 5, "api_calls": [{"name":
        "mod_two", "type": "Tool", "inputs": {"number": 5}, "output": null, "start_time":
        1703585567.528194, "end_time": 1703585567.529116, "error": {"message": "cannot
        mod 2!", "type": "Exception"}, "children": null, "node_name": "mod_two"}],
        "variant_id": "", "name": "", "description": "", "tags": null, "system_metrics":
        {"duration": 0.035141, "prompt_tokens": 0, "completion_tokens": 0, "total_tokens":
        0}, "result": null, "upload_metrics": false}, {"run_id": "run1_3", "status":
        "Failed", "error": {"message": "Execution failure in ''mod_two'': (Exception)
        cannot mod 2!", "messageFormat": "Execution failure in ''{node_name}'': {error_type_and_message}",
        "messageParameters": {"node_name": "mod_two", "error_type_and_message": "(Exception)
        cannot mod 2!"}, "referenceCode": "Tool/__pf_main__", "code": "UserError",
        "innerError": {"code": "ToolExecutionError", "innerError": null}, "additionalInfo":
        [{"type": "ToolExecutionErrorDetails", "info": {"type": "Exception", "message":
        "cannot mod 2!", "traceback": "Traceback (most recent call last):\n  File
        \"/mnt/host/service/app/39571/requests/run1/mod_two.py\", line 7, in mod_two\n    raise
        Exception(\"cannot mod 2!\")\nException: cannot mod 2!\n", "filename": "/mnt/host/service/app/39571/requests/run1/mod_two.py",
        "lineno": 7, "name": "mod_two"}}], "debugInfo": {"type": "ToolExecutionError",
        "message": "Execution failure in ''mod_two'': (Exception) cannot mod 2!",
        "stackTrace": "\nThe above exception was the direct cause of the following
        exception:\n\nTraceback (most recent call last):\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/executor/flow_executor.py\",
        line 804, in _exec\n    output, nodes_outputs = self._traverse_nodes(inputs,
        context)\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/executor/flow_executor.py\",
        line 890, in _traverse_nodes\n    nodes_outputs, bypassed_nodes = self._submit_to_scheduler(context,
        inputs, batch_nodes)\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/executor/flow_executor.py\",
        line 910, in _submit_to_scheduler\n    return FlowNodesScheduler(self._tools_manager,
        inputs, nodes, self._node_concurrency, context).execute()\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/executor/_flow_nodes_scheduler.py\",
        line 69, in execute\n    raise e\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/executor/_flow_nodes_scheduler.py\",
        line 58, in execute\n    self._dag_manager.complete_nodes(self._collect_outputs(completed_futures))\n  File
        \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/executor/_flow_nodes_scheduler.py\",
        line 90, in _collect_outputs\n    each_node_result = each_future.result()\n  File
        \"/azureml-envs/prompt-flow/runtime/lib/python3.10/concurrent/futures/_base.py\",
        line 451, in result\n    return self.__get_result()\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/concurrent/futures/_base.py\",
        line 403, in __get_result\n    raise self._exception\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/concurrent/futures/thread.py\",
        line 58, in run\n    result = self.fn(*self.args, **self.kwargs)\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/executor/_flow_nodes_scheduler.py\",
        line 111, in _exec_single_node_in_thread\n    result = context.invoke_tool(node,
        f, kwargs=kwargs)\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/_core/flow_execution_context.py\",
        line 89, in invoke_tool\n    result = self._invoke_tool_with_timer(node, f,
        kwargs)\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/_core/flow_execution_context.py\",
        line 196, in _invoke_tool_with_timer\n    raise ToolExecutionError(node_name=node_name,
        module=module) from e\n", "innerException": {"type": "Exception", "message":
        "cannot mod 2!", "stackTrace": "Traceback (most recent call last):\n  File
        \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/_core/flow_execution_context.py\",
        line 185, in _invoke_tool_with_timer\n    return f(**kwargs)\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/_core/tool.py\",
        line 106, in decorated_tool\n    output = func(*args, **kwargs)\n  File \"/mnt/host/service/app/39571/requests/run1/mod_two.py\",
        line 7, in mod_two\n    raise Exception(\"cannot mod 2!\")\n", "innerException":
        null}}}, "inputs": {"number": 3, "line_number": 3}, "output": null, "metrics":
        null, "request": null, "parent_run_id": "run1", "root_run_id": "run1", "source_run_id":
        null, "flow_id": "default_flow_id", "start_time": "2023-12-26T10:12:47.475423Z",
        "end_time": "2023-12-26T10:12:47.637535Z", "index": 3, "api_calls": [{"name":
        "mod_two", "type": "Tool", "inputs": {"number": 3}, "output": null, "start_time":
        1703585567.510321, "end_time": 1703585567.511491, "error": {"message": "cannot
        mod 2!", "type": "Exception"}, "children": null, "node_name": "mod_two"}],
        "variant_id": "", "name": "", "description": "", "tags": null, "system_metrics":
        {"duration": 0.162112, "prompt_tokens": 0, "completion_tokens": 0, "total_tokens":
        0}, "result": null, "upload_metrics": false}, {"run_id": "run1_2", "status":
        "Completed", "error": null, "inputs": {"number": 2, "line_number": 2}, "output":
        {"output": 2}, "metrics": null, "request": null, "parent_run_id": "run1",
        "root_run_id": "run1", "source_run_id": null, "flow_id": "default_flow_id",
        "start_time": "2023-12-26T10:12:47.429305Z", "end_time": "2023-12-26T10:12:47.46051Z",
        "index": 2, "api_calls": [{"name": "mod_two", "type": "Tool", "inputs": {"number":
        2}, "output": {"value": 2}, "start_time": 1703585567.457015, "end_time": 1703585567.457843,
        "error": null, "children": null, "node_name": "mod_two"}], "variant_id": "",
        "name": "", "description": "", "tags": null, "system_metrics": {"duration":
        0.031205, "prompt_tokens": 0, "completion_tokens": 0, "total_tokens": 0},
        "result": {"output": 2}, "upload_metrics": false}, {"run_id": "run1_4", "status":
        "Completed", "error": null, "inputs": {"number": 4, "line_number": 4}, "output":
        {"output": 4}, "metrics": null, "request": null, "parent_run_id": "run1",
        "root_run_id": "run1", "source_run_id": null, "flow_id": "default_flow_id",
        "start_time": "2023-12-26T10:12:47.493972Z", "end_time": "2023-12-26T10:12:47.523331Z",
        "index": 4, "api_calls": [{"name": "mod_two", "type": "Tool", "inputs": {"number":
        4}, "output": {"value": 4}, "start_time": 1703585567.519488, "end_time": 1703585567.520447,
        "error": null, "children": null, "node_name": "mod_two"}], "variant_id": "",
        "name": "", "description": "", "tags": null, "system_metrics": {"duration":
        0.029359, "prompt_tokens": 0, "completion_tokens": 0, "total_tokens": 0},
        "result": {"output": 4}, "upload_metrics": false}, {"run_id": "run1_6", "status":
        "Completed", "error": null, "inputs": {"number": 6, "line_number": 6}, "output":
        {"output": 6}, "metrics": null, "request": null, "parent_run_id": "run1",
        "root_run_id": "run1", "source_run_id": null, "flow_id": "default_flow_id",
        "start_time": "2023-12-26T10:12:47.562861Z", "end_time": "2023-12-26T10:12:47.601751Z",
        "index": 6, "api_calls": [{"name": "mod_two", "type": "Tool", "inputs": {"number":
        6}, "output": {"value": 6}, "start_time": 1703585567.598276, "end_time": 1703585567.599137,
        "error": null, "children": null, "node_name": "mod_two"}], "variant_id": "",
        "name": "", "description": "", "tags": null, "system_metrics": {"duration":
        0.03889, "prompt_tokens": 0, "completion_tokens": 0, "total_tokens": 0}, "result":
        {"output": 6}, "upload_metrics": false}, {"run_id": "run1_7", "status": "Failed",
        "error": {"message": "Execution failure in ''mod_two'': (Exception) cannot
        mod 2!", "messageFormat": "Execution failure in ''{node_name}'': {error_type_and_message}",
        "messageParameters": {"node_name": "mod_two", "error_type_and_message": "(Exception)
        cannot mod 2!"}, "referenceCode": "Tool/__pf_main__", "code": "UserError",
        "innerError": {"code": "ToolExecutionError", "innerError": null}, "additionalInfo":
        [{"type": "ToolExecutionErrorDetails", "info": {"type": "Exception", "message":
        "cannot mod 2!", "traceback": "Traceback (most recent call last):\n  File
        \"/mnt/host/service/app/39571/requests/run1/mod_two.py\", line 7, in mod_two\n    raise
        Exception(\"cannot mod 2!\")\nException: cannot mod 2!\n", "filename": "/mnt/host/service/app/39571/requests/run1/mod_two.py",
        "lineno": 7, "name": "mod_two"}}], "debugInfo": {"type": "ToolExecutionError",
        "message": "Execution failure in ''mod_two'': (Exception) cannot mod 2!",
        "stackTrace": "\nThe above exception was the direct cause of the following
        exception:\n\nTraceback (most recent call last):\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/executor/flow_executor.py\",
        line 804, in _exec\n    output, nodes_outputs = self._traverse_nodes(inputs,
        context)\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/executor/flow_executor.py\",
        line 890, in _traverse_nodes\n    nodes_outputs, bypassed_nodes = self._submit_to_scheduler(context,
        inputs, batch_nodes)\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/executor/flow_executor.py\",
        line 910, in _submit_to_scheduler\n    return FlowNodesScheduler(self._tools_manager,
        inputs, nodes, self._node_concurrency, context).execute()\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/executor/_flow_nodes_scheduler.py\",
        line 69, in execute\n    raise e\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/executor/_flow_nodes_scheduler.py\",
        line 58, in execute\n    self._dag_manager.complete_nodes(self._collect_outputs(completed_futures))\n  File
        \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/executor/_flow_nodes_scheduler.py\",
        line 90, in _collect_outputs\n    each_node_result = each_future.result()\n  File
        \"/azureml-envs/prompt-flow/runtime/lib/python3.10/concurrent/futures/_base.py\",
        line 451, in result\n    return self.__get_result()\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/concurrent/futures/_base.py\",
        line 403, in __get_result\n    raise self._exception\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/concurrent/futures/thread.py\",
        line 58, in run\n    result = self.fn(*self.args, **self.kwargs)\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/executor/_flow_nodes_scheduler.py\",
        line 111, in _exec_single_node_in_thread\n    result = context.invoke_tool(node,
        f, kwargs=kwargs)\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/_core/flow_execution_context.py\",
        line 89, in invoke_tool\n    result = self._invoke_tool_with_timer(node, f,
        kwargs)\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/_core/flow_execution_context.py\",
        line 196, in _invoke_tool_with_timer\n    raise ToolExecutionError(node_name=node_name,
        module=module) from e\n", "innerException": {"type": "Exception", "message":
        "cannot mod 2!", "stackTrace": "Traceback (most recent call last):\n  File
        \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/_core/flow_execution_context.py\",
        line 185, in _invoke_tool_with_timer\n    return f(**kwargs)\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/_core/tool.py\",
        line 106, in decorated_tool\n    output = func(*args, **kwargs)\n  File \"/mnt/host/service/app/39571/requests/run1/mod_two.py\",
        line 7, in mod_two\n    raise Exception(\"cannot mod 2!\")\n", "innerException":
        null}}}, "inputs": {"number": 7, "line_number": 7}, "output": null, "metrics":
        null, "request": null, "parent_run_id": "run1", "root_run_id": "run1", "source_run_id":
        null, "flow_id": "default_flow_id", "start_time": "2023-12-26T10:12:47.564388Z",
        "end_time": "2023-12-26T10:12:47.592472Z", "index": 7, "api_calls": [{"name":
        "mod_two", "type": "Tool", "inputs": {"number": 7}, "output": null, "start_time":
        1703585567.586574, "end_time": 1703585567.587515, "error": {"message": "cannot
        mod 2!", "type": "Exception"}, "children": null, "node_name": "mod_two"}],
        "variant_id": "", "name": "", "description": "", "tags": null, "system_metrics":
        {"duration": 0.028084, "prompt_tokens": 0, "completion_tokens": 0, "total_tokens":
        0}, "result": null, "upload_metrics": false}, {"run_id": "run1_8", "status":
        "Completed", "error": null, "inputs": {"number": 8, "line_number": 8}, "output":
        {"output": 8}, "metrics": null, "request": null, "parent_run_id": "run1",
        "root_run_id": "run1", "source_run_id": null, "flow_id": "default_flow_id",
        "start_time": "2023-12-26T10:12:47.585321Z", "end_time": "2023-12-26T10:12:47.606832Z",
        "index": 8, "api_calls": [{"name": "mod_two", "type": "Tool", "inputs": {"number":
        8}, "output": {"value": 8}, "start_time": 1703585567.596337, "end_time": 1703585567.597198,
        "error": null, "children": null, "node_name": "mod_two"}], "variant_id": "",
        "name": "", "description": "", "tags": null, "system_metrics": {"duration":
        0.021511, "prompt_tokens": 0, "completion_tokens": 0, "total_tokens": 0},
        "result": {"output": 8}, "upload_metrics": false}, {"run_id": "run1_9", "status":
        "Failed", "error": {"message": "Execution failure in ''mod_two'': (Exception)
        cannot mod 2!", "messageFormat": "Execution failure in ''{node_name}'': {error_type_and_message}",
        "messageParameters": {"node_name": "mod_two", "error_type_and_message": "(Exception)
        cannot mod 2!"}, "referenceCode": "Tool/__pf_main__", "code": "UserError",
        "innerError": {"code": "ToolExecutionError", "innerError": null}, "additionalInfo":
        [{"type": "ToolExecutionErrorDetails", "info": {"type": "Exception", "message":
        "cannot mod 2!", "traceback": "Traceback (most recent call last):\n  File
        \"/mnt/host/service/app/39571/requests/run1/mod_two.py\", line 7, in mod_two\n    raise
        Exception(\"cannot mod 2!\")\nException: cannot mod 2!\n", "filename": "/mnt/host/service/app/39571/requests/run1/mod_two.py",
        "lineno": 7, "name": "mod_two"}}], "debugInfo": {"type": "ToolExecutionError",
        "message": "Execution failure in ''mod_two'': (Exception) cannot mod 2!",
        "stackTrace": "\nThe above exception was the direct cause of the following
        exception:\n\nTraceback (most recent call last):\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/executor/flow_executor.py\",
        line 804, in _exec\n    output, nodes_outputs = self._traverse_nodes(inputs,
        context)\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/executor/flow_executor.py\",
        line 890, in _traverse_nodes\n    nodes_outputs, bypassed_nodes = self._submit_to_scheduler(context,
        inputs, batch_nodes)\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/executor/flow_executor.py\",
        line 910, in _submit_to_scheduler\n    return FlowNodesScheduler(self._tools_manager,
        inputs, nodes, self._node_concurrency, context).execute()\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/executor/_flow_nodes_scheduler.py\",
        line 69, in execute\n    raise e\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/executor/_flow_nodes_scheduler.py\",
        line 58, in execute\n    self._dag_manager.complete_nodes(self._collect_outputs(completed_futures))\n  File
        \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/executor/_flow_nodes_scheduler.py\",
        line 90, in _collect_outputs\n    each_node_result = each_future.result()\n  File
        \"/azureml-envs/prompt-flow/runtime/lib/python3.10/concurrent/futures/_base.py\",
        line 451, in result\n    return self.__get_result()\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/concurrent/futures/_base.py\",
        line 403, in __get_result\n    raise self._exception\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/concurrent/futures/thread.py\",
        line 58, in run\n    result = self.fn(*self.args, **self.kwargs)\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/executor/_flow_nodes_scheduler.py\",
        line 111, in _exec_single_node_in_thread\n    result = context.invoke_tool(node,
        f, kwargs=kwargs)\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/_core/flow_execution_context.py\",
        line 89, in invoke_tool\n    result = self._invoke_tool_with_timer(node, f,
        kwargs)\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/_core/flow_execution_context.py\",
        line 196, in _invoke_tool_with_timer\n    raise ToolExecutionError(node_name=node_name,
        module=module) from e\n", "innerException": {"type": "Exception", "message":
        "cannot mod 2!", "stackTrace": "Traceback (most recent call last):\n  File
        \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/_core/flow_execution_context.py\",
        line 185, in _invoke_tool_with_timer\n    return f(**kwargs)\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/_core/tool.py\",
        line 106, in decorated_tool\n    output = func(*args, **kwargs)\n  File \"/mnt/host/service/app/39571/requests/run1/mod_two.py\",
        line 7, in mod_two\n    raise Exception(\"cannot mod 2!\")\n", "innerException":
        null}}}, "inputs": {"number": 9, "line_number": 9}, "output": null, "metrics":
        null, "request": null, "parent_run_id": "run1", "root_run_id": "run1", "source_run_id":
        null, "flow_id": "default_flow_id", "start_time": "2023-12-26T10:12:47.585312Z",
        "end_time": "2023-12-26T10:12:47.606861Z", "index": 9, "api_calls": [{"name":
        "mod_two", "type": "Tool", "inputs": {"number": 9}, "output": null, "start_time":
        1703585567.595876, "end_time": 1703585567.596635, "error": {"message": "cannot
        mod 2!", "type": "Exception"}, "children": null, "node_name": "mod_two"}],
        "variant_id": "", "name": "", "description": "", "tags": null, "system_metrics":
        {"duration": 0.021549, "prompt_tokens": 0, "completion_tokens": 0, "total_tokens":
        0}, "result": null, "upload_metrics": false}, {"run_id": "run1_10", "status":
        "Completed", "error": null, "inputs": {"number": 10, "line_number": 10}, "output":
        {"output": 10}, "metrics": null, "request": null, "parent_run_id": "run1",
        "root_run_id": "run1", "source_run_id": null, "flow_id": "default_flow_id",
        "start_time": "2023-12-26T10:12:47.61718Z", "end_time": "2023-12-26T10:12:47.625641Z",
        "index": 10, "api_calls": [{"name": "mod_two", "type": "Tool", "inputs": {"number":
        10}, "output": {"value": 10}, "start_time": 1703585567.622119, "end_time":
        1703585567.623081, "error": null, "children": null, "node_name": "mod_two"}],
        "variant_id": "", "name": "", "description": "", "tags": null, "system_metrics":
        {"duration": 0.008461, "prompt_tokens": 0, "completion_tokens": 0, "total_tokens":
        0}, "result": {"output": 10}, "upload_metrics": false}, {"run_id": "run1_12",
        "status": "Completed", "error": null, "inputs": {"number": 12, "line_number":
        12}, "output": {"output": 12}, "metrics": null, "request": null, "parent_run_id":
        "run1", "root_run_id": "run1", "source_run_id": null, "flow_id": "default_flow_id",
        "start_time": "2023-12-26T10:12:47.71897Z", "end_time": "2023-12-26T10:12:47.728357Z",
        "index": 12, "api_calls": [{"name": "mod_two", "type": "Tool", "inputs": {"number":
        12}, "output": {"value": 12}, "start_time": 1703585567.725239, "end_time":
        1703585567.72613, "error": null, "children": null, "node_name": "mod_two"}],
        "variant_id": "", "name": "", "description": "", "tags": null, "system_metrics":
        {"duration": 0.009387, "prompt_tokens": 0, "completion_tokens": 0, "total_tokens":
        0}, "result": {"output": 12}, "upload_metrics": false}, {"run_id": "run1_11",
        "status": "Failed", "error": {"message": "Execution failure in ''mod_two'':
        (Exception) cannot mod 2!", "messageFormat": "Execution failure in ''{node_name}'':
        {error_type_and_message}", "messageParameters": {"node_name": "mod_two", "error_type_and_message":
        "(Exception) cannot mod 2!"}, "referenceCode": "Tool/__pf_main__", "code":
        "UserError", "innerError": {"code": "ToolExecutionError", "innerError": null},
        "additionalInfo": [{"type": "ToolExecutionErrorDetails", "info": {"type":
        "Exception", "message": "cannot mod 2!", "traceback": "Traceback (most recent
        call last):\n  File \"/mnt/host/service/app/39571/requests/run1/mod_two.py\",
        line 7, in mod_two\n    raise Exception(\"cannot mod 2!\")\nException: cannot
        mod 2!\n", "filename": "/mnt/host/service/app/39571/requests/run1/mod_two.py",
        "lineno": 7, "name": "mod_two"}}], "debugInfo": {"type": "ToolExecutionError",
        "message": "Execution failure in ''mod_two'': (Exception) cannot mod 2!",
        "stackTrace": "\nThe above exception was the direct cause of the following
        exception:\n\nTraceback (most recent call last):\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/executor/flow_executor.py\",
        line 804, in _exec\n    output, nodes_outputs = self._traverse_nodes(inputs,
        context)\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/executor/flow_executor.py\",
        line 890, in _traverse_nodes\n    nodes_outputs, bypassed_nodes = self._submit_to_scheduler(context,
        inputs, batch_nodes)\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/executor/flow_executor.py\",
        line 910, in _submit_to_scheduler\n    return FlowNodesScheduler(self._tools_manager,
        inputs, nodes, self._node_concurrency, context).execute()\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/executor/_flow_nodes_scheduler.py\",
        line 69, in execute\n    raise e\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/executor/_flow_nodes_scheduler.py\",
        line 58, in execute\n    self._dag_manager.complete_nodes(self._collect_outputs(completed_futures))\n  File
        \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/executor/_flow_nodes_scheduler.py\",
        line 90, in _collect_outputs\n    each_node_result = each_future.result()\n  File
        \"/azureml-envs/prompt-flow/runtime/lib/python3.10/concurrent/futures/_base.py\",
        line 451, in result\n    return self.__get_result()\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/concurrent/futures/_base.py\",
        line 403, in __get_result\n    raise self._exception\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/concurrent/futures/thread.py\",
        line 58, in run\n    result = self.fn(*self.args, **self.kwargs)\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/executor/_flow_nodes_scheduler.py\",
        line 111, in _exec_single_node_in_thread\n    result = context.invoke_tool(node,
        f, kwargs=kwargs)\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/_core/flow_execution_context.py\",
        line 89, in invoke_tool\n    result = self._invoke_tool_with_timer(node, f,
        kwargs)\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/_core/flow_execution_context.py\",
        line 196, in _invoke_tool_with_timer\n    raise ToolExecutionError(node_name=node_name,
        module=module) from e\n", "innerException": {"type": "Exception", "message":
        "cannot mod 2!", "stackTrace": "Traceback (most recent call last):\n  File
        \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/_core/flow_execution_context.py\",
        line 185, in _invoke_tool_with_timer\n    return f(**kwargs)\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/_core/tool.py\",
        line 106, in decorated_tool\n    output = func(*args, **kwargs)\n  File \"/mnt/host/service/app/39571/requests/run1/mod_two.py\",
        line 7, in mod_two\n    raise Exception(\"cannot mod 2!\")\n", "innerException":
        null}}}, "inputs": {"number": 11, "line_number": 11}, "output": null, "metrics":
        null, "request": null, "parent_run_id": "run1", "root_run_id": "run1", "source_run_id":
        null, "flow_id": "default_flow_id", "start_time": "2023-12-26T10:12:47.618122Z",
        "end_time": "2023-12-26T10:12:47.708064Z", "index": 11, "api_calls": [{"name":
        "mod_two", "type": "Tool", "inputs": {"number": 11}, "output": null, "start_time":
        1703585567.63319, "end_time": 1703585567.634137, "error": {"message": "cannot
        mod 2!", "type": "Exception"}, "children": null, "node_name": "mod_two"}],
        "variant_id": "", "name": "", "description": "", "tags": null, "system_metrics":
        {"duration": 0.089942, "prompt_tokens": 0, "completion_tokens": 0, "total_tokens":
        0}, "result": null, "upload_metrics": false}, {"run_id": "run1_13", "status":
        "Failed", "error": {"message": "Execution failure in ''mod_two'': (Exception)
        cannot mod 2!", "messageFormat": "Execution failure in ''{node_name}'': {error_type_and_message}",
        "messageParameters": {"node_name": "mod_two", "error_type_and_message": "(Exception)
        cannot mod 2!"}, "referenceCode": "Tool/__pf_main__", "code": "UserError",
        "innerError": {"code": "ToolExecutionError", "innerError": null}, "additionalInfo":
        [{"type": "ToolExecutionErrorDetails", "info": {"type": "Exception", "message":
        "cannot mod 2!", "traceback": "Traceback (most recent call last):\n  File
        \"/mnt/host/service/app/39571/requests/run1/mod_two.py\", line 7, in mod_two\n    raise
        Exception(\"cannot mod 2!\")\nException: cannot mod 2!\n", "filename": "/mnt/host/service/app/39571/requests/run1/mod_two.py",
        "lineno": 7, "name": "mod_two"}}], "debugInfo": {"type": "ToolExecutionError",
        "message": "Execution failure in ''mod_two'': (Exception) cannot mod 2!",
        "stackTrace": "\nThe above exception was the direct cause of the following
        exception:\n\nTraceback (most recent call last):\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/executor/flow_executor.py\",
        line 804, in _exec\n    output, nodes_outputs = self._traverse_nodes(inputs,
        context)\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/executor/flow_executor.py\",
        line 890, in _traverse_nodes\n    nodes_outputs, bypassed_nodes = self._submit_to_scheduler(context,
        inputs, batch_nodes)\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/executor/flow_executor.py\",
        line 910, in _submit_to_scheduler\n    return FlowNodesScheduler(self._tools_manager,
        inputs, nodes, self._node_concurrency, context).execute()\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/executor/_flow_nodes_scheduler.py\",
        line 69, in execute\n    raise e\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/executor/_flow_nodes_scheduler.py\",
        line 58, in execute\n    self._dag_manager.complete_nodes(self._collect_outputs(completed_futures))\n  File
        \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/executor/_flow_nodes_scheduler.py\",
        line 90, in _collect_outputs\n    each_node_result = each_future.result()\n  File
        \"/azureml-envs/prompt-flow/runtime/lib/python3.10/concurrent/futures/_base.py\",
        line 451, in result\n    return self.__get_result()\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/concurrent/futures/_base.py\",
        line 403, in __get_result\n    raise self._exception\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/concurrent/futures/thread.py\",
        line 58, in run\n    result = self.fn(*self.args, **self.kwargs)\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/executor/_flow_nodes_scheduler.py\",
        line 111, in _exec_single_node_in_thread\n    result = context.invoke_tool(node,
        f, kwargs=kwargs)\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/_core/flow_execution_context.py\",
        line 89, in invoke_tool\n    result = self._invoke_tool_with_timer(node, f,
        kwargs)\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/_core/flow_execution_context.py\",
        line 196, in _invoke_tool_with_timer\n    raise ToolExecutionError(node_name=node_name,
        module=module) from e\n", "innerException": {"type": "Exception", "message":
        "cannot mod 2!", "stackTrace": "Traceback (most recent call last):\n  File
        \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/_core/flow_execution_context.py\",
        line 185, in _invoke_tool_with_timer\n    return f(**kwargs)\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/_core/tool.py\",
        line 106, in decorated_tool\n    output = func(*args, **kwargs)\n  File \"/mnt/host/service/app/39571/requests/run1/mod_two.py\",
        line 7, in mod_two\n    raise Exception(\"cannot mod 2!\")\n", "innerException":
        null}}}, "inputs": {"number": 13, "line_number": 13}, "output": null, "metrics":
        null, "request": null, "parent_run_id": "run1", "root_run_id": "run1", "source_run_id":
        null, "flow_id": "default_flow_id", "start_time": "2023-12-26T10:12:47.999985Z",
        "end_time": "2023-12-26T10:12:48.034354Z", "index": 13, "api_calls": [{"name":
        "mod_two", "type": "Tool", "inputs": {"number": 13}, "output": null, "start_time":
        1703585568.0018, "end_time": 1703585568.001879, "error": {"message": "cannot
        mod 2!", "type": "Exception"}, "children": null, "node_name": "mod_two"}],
        "variant_id": "", "name": "", "description": "", "tags": null, "system_metrics":
        {"duration": 0.034369, "prompt_tokens": 0, "completion_tokens": 0, "total_tokens":
        0}, "result": null, "upload_metrics": false}, {"run_id": "run1_14", "status":
        "Completed", "error": null, "inputs": {"number": 14, "line_number": 14}, "output":
        {"output": 14}, "metrics": null, "request": null, "parent_run_id": "run1",
        "root_run_id": "run1", "source_run_id": null, "flow_id": "default_flow_id",
        "start_time": "2023-12-26T10:12:48.034519Z", "end_time": "2023-12-26T10:12:48.036696Z",
        "index": 14, "api_calls": [{"name": "mod_two", "type": "Tool", "inputs": {"number":
        14}, "output": {"value": 14}, "start_time": 1703585568.035915, "end_time":
        1703585568.035991, "error": null, "children": null, "node_name": "mod_two"}],
        "variant_id": "", "name": "", "description": "", "tags": null, "system_metrics":
        {"duration": 0.002177, "prompt_tokens": 0, "completion_tokens": 0, "total_tokens":
        0}, "result": {"output": 14}, "upload_metrics": false}, {"run_id": "run1_15",
        "status": "Failed", "error": {"message": "Execution failure in ''mod_two'':
        (Exception) cannot mod 2!", "messageFormat": "Execution failure in ''{node_name}'':
        {error_type_and_message}", "messageParameters": {"node_name": "mod_two", "error_type_and_message":
        "(Exception) cannot mod 2!"}, "referenceCode": "Tool/__pf_main__", "code":
        "UserError", "innerError": {"code": "ToolExecutionError", "innerError": null},
        "additionalInfo": [{"type": "ToolExecutionErrorDetails", "info": {"type":
        "Exception", "message": "cannot mod 2!", "traceback": "Traceback (most recent
        call last):\n  File \"/mnt/host/service/app/39571/requests/run1/mod_two.py\",
        line 7, in mod_two\n    raise Exception(\"cannot mod 2!\")\nException: cannot
        mod 2!\n", "filename": "/mnt/host/service/app/39571/requests/run1/mod_two.py",
        "lineno": 7, "name": "mod_two"}}], "debugInfo": {"type": "ToolExecutionError",
        "message": "Execution failure in ''mod_two'': (Exception) cannot mod 2!",
        "stackTrace": "\nThe above exception was the direct cause of the following
        exception:\n\nTraceback (most recent call last):\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/executor/flow_executor.py\",
        line 804, in _exec\n    output, nodes_outputs = self._traverse_nodes(inputs,
        context)\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/executor/flow_executor.py\",
        line 890, in _traverse_nodes\n    nodes_outputs, bypassed_nodes = self._submit_to_scheduler(context,
        inputs, batch_nodes)\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/executor/flow_executor.py\",
        line 910, in _submit_to_scheduler\n    return FlowNodesScheduler(self._tools_manager,
        inputs, nodes, self._node_concurrency, context).execute()\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/executor/_flow_nodes_scheduler.py\",
        line 69, in execute\n    raise e\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/executor/_flow_nodes_scheduler.py\",
        line 58, in execute\n    self._dag_manager.complete_nodes(self._collect_outputs(completed_futures))\n  File
        \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/executor/_flow_nodes_scheduler.py\",
        line 90, in _collect_outputs\n    each_node_result = each_future.result()\n  File
        \"/azureml-envs/prompt-flow/runtime/lib/python3.10/concurrent/futures/_base.py\",
        line 451, in result\n    return self.__get_result()\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/concurrent/futures/_base.py\",
        line 403, in __get_result\n    raise self._exception\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/concurrent/futures/thread.py\",
        line 58, in run\n    result = self.fn(*self.args, **self.kwargs)\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/executor/_flow_nodes_scheduler.py\",
        line 111, in _exec_single_node_in_thread\n    result = context.invoke_tool(node,
        f, kwargs=kwargs)\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/_core/flow_execution_context.py\",
        line 89, in invoke_tool\n    result = self._invoke_tool_with_timer(node, f,
        kwargs)\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/_core/flow_execution_context.py\",
        line 196, in _invoke_tool_with_timer\n    raise ToolExecutionError(node_name=node_name,
        module=module) from e\n", "innerException": {"type": "Exception", "message":
        "cannot mod 2!", "stackTrace": "Traceback (most recent call last):\n  File
        \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/_core/flow_execution_context.py\",
        line 185, in _invoke_tool_with_timer\n    return f(**kwargs)\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/_core/tool.py\",
        line 106, in decorated_tool\n    output = func(*args, **kwargs)\n  File \"/mnt/host/service/app/39571/requests/run1/mod_two.py\",
        line 7, in mod_two\n    raise Exception(\"cannot mod 2!\")\n", "innerException":
        null}}}, "inputs": {"number": 15, "line_number": 15}, "output": null, "metrics":
        null, "request": null, "parent_run_id": "run1", "root_run_id": "run1", "source_run_id":
        null, "flow_id": "default_flow_id", "start_time": "2023-12-26T10:12:48.061511Z",
        "end_time": "2023-12-26T10:12:48.066084Z", "index": 15, "api_calls": [{"name":
        "mod_two", "type": "Tool", "inputs": {"number": 15}, "output": null, "start_time":
        1703585568.06265, "end_time": 1703585568.062853, "error": {"message": "cannot
        mod 2!", "type": "Exception"}, "children": null, "node_name": "mod_two"}],
        "variant_id": "", "name": "", "description": "", "tags": null, "system_metrics":
        {"duration": 0.004573, "prompt_tokens": 0, "completion_tokens": 0, "total_tokens":
        0}, "result": null, "upload_metrics": false}, {"run_id": "run1_16", "status":
        "Completed", "error": null, "inputs": {"number": 16, "line_number": 16}, "output":
        {"output": 16}, "metrics": null, "request": null, "parent_run_id": "run1",
        "root_run_id": "run1", "source_run_id": null, "flow_id": "default_flow_id",
        "start_time": "2023-12-26T10:12:48.074942Z", "end_time": "2023-12-26T10:12:48.077593Z",
        "index": 16, "api_calls": [{"name": "mod_two", "type": "Tool", "inputs": {"number":
        16}, "output": {"value": 16}, "start_time": 1703585568.076025, "end_time":
        1703585568.076395, "error": null, "children": null, "node_name": "mod_two"}],
        "variant_id": "", "name": "", "description": "", "tags": null, "system_metrics":
        {"duration": 0.002651, "prompt_tokens": 0, "completion_tokens": 0, "total_tokens":
        0}, "result": {"output": 16}, "upload_metrics": false}, {"run_id": "run1_17",
        "status": "Failed", "error": {"message": "Execution failure in ''mod_two'':
        (Exception) cannot mod 2!", "messageFormat": "Execution failure in ''{node_name}'':
        {error_type_and_message}", "messageParameters": {"node_name": "mod_two", "error_type_and_message":
        "(Exception) cannot mod 2!"}, "referenceCode": "Tool/__pf_main__", "code":
        "UserError", "innerError": {"code": "ToolExecutionError", "innerError": null},
        "additionalInfo": [{"type": "ToolExecutionErrorDetails", "info": {"type":
        "Exception", "message": "cannot mod 2!", "traceback": "Traceback (most recent
        call last):\n  File \"/mnt/host/service/app/39571/requests/run1/mod_two.py\",
        line 7, in mod_two\n    raise Exception(\"cannot mod 2!\")\nException: cannot
        mod 2!\n", "filename": "/mnt/host/service/app/39571/requests/run1/mod_two.py",
        "lineno": 7, "name": "mod_two"}}], "debugInfo": {"type": "ToolExecutionError",
        "message": "Execution failure in ''mod_two'': (Exception) cannot mod 2!",
        "stackTrace": "\nThe above exception was the direct cause of the following
        exception:\n\nTraceback (most recent call last):\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/executor/flow_executor.py\",
        line 804, in _exec\n    output, nodes_outputs = self._traverse_nodes(inputs,
        context)\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/executor/flow_executor.py\",
        line 890, in _traverse_nodes\n    nodes_outputs, bypassed_nodes = self._submit_to_scheduler(context,
        inputs, batch_nodes)\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/executor/flow_executor.py\",
        line 910, in _submit_to_scheduler\n    return FlowNodesScheduler(self._tools_manager,
        inputs, nodes, self._node_concurrency, context).execute()\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/executor/_flow_nodes_scheduler.py\",
        line 69, in execute\n    raise e\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/executor/_flow_nodes_scheduler.py\",
        line 58, in execute\n    self._dag_manager.complete_nodes(self._collect_outputs(completed_futures))\n  File
        \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/executor/_flow_nodes_scheduler.py\",
        line 90, in _collect_outputs\n    each_node_result = each_future.result()\n  File
        \"/azureml-envs/prompt-flow/runtime/lib/python3.10/concurrent/futures/_base.py\",
        line 451, in result\n    return self.__get_result()\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/concurrent/futures/_base.py\",
        line 403, in __get_result\n    raise self._exception\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/concurrent/futures/thread.py\",
        line 58, in run\n    result = self.fn(*self.args, **self.kwargs)\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/executor/_flow_nodes_scheduler.py\",
        line 111, in _exec_single_node_in_thread\n    result = context.invoke_tool(node,
        f, kwargs=kwargs)\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/_core/flow_execution_context.py\",
        line 89, in invoke_tool\n    result = self._invoke_tool_with_timer(node, f,
        kwargs)\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/_core/flow_execution_context.py\",
        line 196, in _invoke_tool_with_timer\n    raise ToolExecutionError(node_name=node_name,
        module=module) from e\n", "innerException": {"type": "Exception", "message":
        "cannot mod 2!", "stackTrace": "Traceback (most recent call last):\n  File
        \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/_core/flow_execution_context.py\",
        line 185, in _invoke_tool_with_timer\n    return f(**kwargs)\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/_core/tool.py\",
        line 106, in decorated_tool\n    output = func(*args, **kwargs)\n  File \"/mnt/host/service/app/39571/requests/run1/mod_two.py\",
        line 7, in mod_two\n    raise Exception(\"cannot mod 2!\")\n", "innerException":
        null}}}, "inputs": {"number": 17, "line_number": 17}, "output": null, "metrics":
        null, "request": null, "parent_run_id": "run1", "root_run_id": "run1", "source_run_id":
        null, "flow_id": "default_flow_id", "start_time": "2023-12-26T10:12:48.101239Z",
        "end_time": "2023-12-26T10:12:48.105799Z", "index": 17, "api_calls": [{"name":
        "mod_two", "type": "Tool", "inputs": {"number": 17}, "output": null, "start_time":
        1703585568.102293, "end_time": 1703585568.102502, "error": {"message": "cannot
        mod 2!", "type": "Exception"}, "children": null, "node_name": "mod_two"}],
        "variant_id": "", "name": "", "description": "", "tags": null, "system_metrics":
        {"duration": 0.00456, "prompt_tokens": 0, "completion_tokens": 0, "total_tokens":
        0}, "result": null, "upload_metrics": false}, {"run_id": "run1_18", "status":
        "Completed", "error": null, "inputs": {"number": 18, "line_number": 18}, "output":
        {"output": 18}, "metrics": null, "request": null, "parent_run_id": "run1",
        "root_run_id": "run1", "source_run_id": null, "flow_id": "default_flow_id",
        "start_time": "2023-12-26T10:12:48.113874Z", "end_time": "2023-12-26T10:12:48.116536Z",
        "index": 18, "api_calls": [{"name": "mod_two", "type": "Tool", "inputs": {"number":
        18}, "output": {"value": 18}, "start_time": 1703585568.115189, "end_time":
        1703585568.115358, "error": null, "children": null, "node_name": "mod_two"}],
        "variant_id": "", "name": "", "description": "", "tags": null, "system_metrics":
        {"duration": 0.002662, "prompt_tokens": 0, "completion_tokens": 0, "total_tokens":
        0}, "result": {"output": 18}, "upload_metrics": false}, {"run_id": "run1_19",
        "status": "Failed", "error": {"message": "Execution failure in ''mod_two'':
        (Exception) cannot mod 2!", "messageFormat": "Execution failure in ''{node_name}'':
        {error_type_and_message}", "messageParameters": {"node_name": "mod_two", "error_type_and_message":
        "(Exception) cannot mod 2!"}, "referenceCode": "Tool/__pf_main__", "code":
        "UserError", "innerError": {"code": "ToolExecutionError", "innerError": null},
        "additionalInfo": [{"type": "ToolExecutionErrorDetails", "info": {"type":
        "Exception", "message": "cannot mod 2!", "traceback": "Traceback (most recent
        call last):\n  File \"/mnt/host/service/app/39571/requests/run1/mod_two.py\",
        line 7, in mod_two\n    raise Exception(\"cannot mod 2!\")\nException: cannot
        mod 2!\n", "filename": "/mnt/host/service/app/39571/requests/run1/mod_two.py",
        "lineno": 7, "name": "mod_two"}}], "debugInfo": {"type": "ToolExecutionError",
        "message": "Execution failure in ''mod_two'': (Exception) cannot mod 2!",
        "stackTrace": "\nThe above exception was the direct cause of the following
        exception:\n\nTraceback (most recent call last):\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/executor/flow_executor.py\",
        line 804, in _exec\n    output, nodes_outputs = self._traverse_nodes(inputs,
        context)\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/executor/flow_executor.py\",
        line 890, in _traverse_nodes\n    nodes_outputs, bypassed_nodes = self._submit_to_scheduler(context,
        inputs, batch_nodes)\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/executor/flow_executor.py\",
        line 910, in _submit_to_scheduler\n    return FlowNodesScheduler(self._tools_manager,
        inputs, nodes, self._node_concurrency, context).execute()\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/executor/_flow_nodes_scheduler.py\",
        line 69, in execute\n    raise e\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/executor/_flow_nodes_scheduler.py\",
        line 58, in execute\n    self._dag_manager.complete_nodes(self._collect_outputs(completed_futures))\n  File
        \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/executor/_flow_nodes_scheduler.py\",
        line 90, in _collect_outputs\n    each_node_result = each_future.result()\n  File
        \"/azureml-envs/prompt-flow/runtime/lib/python3.10/concurrent/futures/_base.py\",
        line 451, in result\n    return self.__get_result()\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/concurrent/futures/_base.py\",
        line 403, in __get_result\n    raise self._exception\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/concurrent/futures/thread.py\",
        line 58, in run\n    result = self.fn(*self.args, **self.kwargs)\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/executor/_flow_nodes_scheduler.py\",
        line 111, in _exec_single_node_in_thread\n    result = context.invoke_tool(node,
        f, kwargs=kwargs)\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/_core/flow_execution_context.py\",
        line 89, in invoke_tool\n    result = self._invoke_tool_with_timer(node, f,
        kwargs)\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/_core/flow_execution_context.py\",
        line 196, in _invoke_tool_with_timer\n    raise ToolExecutionError(node_name=node_name,
        module=module) from e\n", "innerException": {"type": "Exception", "message":
        "cannot mod 2!", "stackTrace": "Traceback (most recent call last):\n  File
        \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/_core/flow_execution_context.py\",
        line 185, in _invoke_tool_with_timer\n    return f(**kwargs)\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/_core/tool.py\",
        line 106, in decorated_tool\n    output = func(*args, **kwargs)\n  File \"/mnt/host/service/app/39571/requests/run1/mod_two.py\",
        line 7, in mod_two\n    raise Exception(\"cannot mod 2!\")\n", "innerException":
        null}}}, "inputs": {"number": 19, "line_number": 19}, "output": null, "metrics":
        null, "request": null, "parent_run_id": "run1", "root_run_id": "run1", "source_run_id":
        null, "flow_id": "default_flow_id", "start_time": "2023-12-26T10:12:48.137823Z",
        "end_time": "2023-12-26T10:12:48.142171Z", "index": 19, "api_calls": [{"name":
        "mod_two", "type": "Tool", "inputs": {"number": 19}, "output": null, "start_time":
        1703585568.138916, "end_time": 1703585568.139091, "error": {"message": "cannot
        mod 2!", "type": "Exception"}, "children": null, "node_name": "mod_two"}],
        "variant_id": "", "name": "", "description": "", "tags": null, "system_metrics":
        {"duration": 0.004348, "prompt_tokens": 0, "completion_tokens": 0, "total_tokens":
        0}, "result": null, "upload_metrics": false}]'
    headers:
      connection:
      - keep-alive
      content-length:
      - '57294'
      content-type:
      - application/json; charset=utf-8
      strict-transport-security:
      - max-age=15724800; includeSubDomains; preload
      transfer-encoding:
      - chunked
      vary:
      - Accept-Encoding
      x-content-type-options:
      - nosniff
      x-request-time:
      - '0.928'
    status:
      code: 200
      message: OK
- request:
    body: null
    headers:
      Accept:
      - application/json
      Accept-Encoding:
      - gzip, deflate
      Connection:
      - keep-alive
      User-Agent:
      - promptflow-sdk/0.0.1 azsdk-python-azuremachinelearningdesignerserviceclient/unknown
        Python/3.10.13 (Windows-10-10.0.22631-SP0)
    method: GET
    uri: https://eastus.api.azureml.ms/flow/api/subscriptions/00000000-0000-0000-0000-000000000000/resourceGroups/00000/providers/Microsoft.MachineLearningServices/workspaces/00000/BulkRuns/run1/childRuns?endIndex=49&startIndex=25
  response:
    body:
      string: '[]'
    headers:
      connection:
      - keep-alive
      content-length:
      - '2'
      content-type:
      - application/json; charset=utf-8
      strict-transport-security:
      - max-age=15724800; includeSubDomains; preload
      x-content-type-options:
      - nosniff
      x-request-time:
      - '0.897'
    status:
      code: 200
      message: OK
- request:
    body: null
    headers:
      Accept:
      - application/json
      Accept-Encoding:
      - gzip, deflate
      Connection:
      - keep-alive
      User-Agent:
      - promptflow-sdk/0.0.1 azure-ai-ml/1.12.1 azsdk-python-mgmt-machinelearningservices/0.1.0
        Python/3.10.13 (Windows-10-10.0.22631-SP0)
    method: GET
    uri: https://management.azure.com/subscriptions/00000000-0000-0000-0000-000000000000/resourceGroups/00000/providers/Microsoft.MachineLearningServices/workspaces/00000/datastores/workspaceblobstore
  response:
    body:
      string: '{"id": "/subscriptions/00000000-0000-0000-0000-000000000000/resourceGroups/00000/providers/Microsoft.MachineLearningServices/workspaces/00000/datastores/workspaceblobstore",
        "name": "workspaceblobstore", "type": "Microsoft.MachineLearningServices/workspaces/datastores",
        "properties": {"description": null, "tags": null, "properties": null, "isDefault":
        true, "credentials": {"credentialsType": "AccountKey"}, "intellectualProperty":
        null, "subscriptionId": "00000000-0000-0000-0000-000000000000", "resourceGroup":
        "00000", "datastoreType": "AzureBlob", "accountName": "fake_account_name",
        "containerName": "fake-container-name", "endpoint": "core.windows.net", "protocol":
        "https", "serviceDataAccessAuthIdentity": "WorkspaceSystemAssignedIdentity"},
        "systemData": {"createdAt": "2023-04-08T02:53:06.5886442+00:00", "createdBy":
        "779301c0-18b2-4cdc-801b-a0a3368fee0a", "createdByType": "Application", "lastModifiedAt":
        "2023-04-08T02:53:07.521127+00:00", "lastModifiedBy": "779301c0-18b2-4cdc-801b-a0a3368fee0a",
        "lastModifiedByType": "Application"}}'
    headers:
      cache-control:
      - no-cache
      content-length:
      - '1227'
      content-type:
      - application/json; charset=utf-8
      expires:
      - '-1'
      pragma:
      - no-cache
      strict-transport-security:
      - max-age=31536000; includeSubDomains
      transfer-encoding:
      - chunked
      vary:
      - Accept-Encoding,Accept-Encoding
      x-content-type-options:
      - nosniff
      x-request-time:
      - '0.084'
    status:
      code: 200
      message: OK
- request:
    body: null
    headers:
      Accept:
      - application/json
      Accept-Encoding:
      - gzip, deflate
      Connection:
      - keep-alive
      Content-Length:
      - '0'
      User-Agent:
      - promptflow-sdk/0.0.1 azure-ai-ml/1.12.1 azsdk-python-mgmt-machinelearningservices/0.1.0
        Python/3.10.13 (Windows-10-10.0.22631-SP0)
    method: POST
    uri: https://management.azure.com/subscriptions/00000000-0000-0000-0000-000000000000/resourceGroups/00000/providers/Microsoft.MachineLearningServices/workspaces/00000/datastores/workspaceblobstore/listSecrets
  response:
    body:
      string: '{"secretsType": "AccountKey", "key": "dGhpcyBpcyBmYWtlIGtleQ=="}'
    headers:
      cache-control:
      - no-cache
      content-length:
      - '134'
      content-type:
      - application/json; charset=utf-8
      expires:
      - '-1'
      pragma:
      - no-cache
      strict-transport-security:
      - max-age=31536000; includeSubDomains
      transfer-encoding:
      - chunked
      vary:
      - Accept-Encoding
      x-content-type-options:
      - nosniff
      x-request-time:
      - '0.092'
    status:
      code: 200
      message: OK
- request:
    body: null
    headers:
      Accept:
      - application/xml
      Accept-Encoding:
      - gzip, deflate
      Connection:
      - keep-alive
      User-Agent:
      - azsdk-python-storage-blob/12.19.0 Python/3.10.13 (Windows-10-10.0.22631-SP0)
      x-ms-date:
      - Tue, 26 Dec 2023 10:13:55 GMT
      x-ms-version:
      - '2023-11-03'
    method: HEAD
    uri: https://fake_account_name.blob.core.windows.net/fake-container-name/LocalUpload/000000000000000000000000000000000000/three/flow.dag.yaml
  response:
    body:
      string: ''
    headers:
      accept-ranges:
      - bytes
      content-length:
      - '248'
      content-md5:
      - B3pfhMEmUOazTzjlKaw6Sw==
      content-type:
      - application/octet-stream
      last-modified:
      - Tue, 26 Dec 2023 10:04:33 GMT
      server:
      - Windows-Azure-Blob/1.0 Microsoft-HTTPAPI/2.0
      vary:
      - Origin
      x-ms-blob-type:
      - BlockBlob
      x-ms-creation-time:
      - Tue, 26 Dec 2023 09:54:37 GMT
      x-ms-meta-name:
      - 613ead8f-69ca-4c47-9cba-01f0dd473279
      x-ms-meta-upload_status:
      - completed
      x-ms-meta-version:
      - '1'
      x-ms-version:
      - '2023-11-03'
    status:
      code: 200
      message: OK
- request:
    body: null
    headers:
      Accept:
      - application/xml
      Accept-Encoding:
      - gzip, deflate
      Connection:
      - keep-alive
      User-Agent:
      - azsdk-python-storage-blob/12.19.0 Python/3.10.13 (Windows-10-10.0.22631-SP0)
      x-ms-date:
      - Tue, 26 Dec 2023 10:13:56 GMT
      x-ms-version:
      - '2023-11-03'
    method: HEAD
    uri: https://fake_account_name.blob.core.windows.net/fake-container-name/az-ml-artifacts/000000000000000000000000000000000000/three/flow.dag.yaml
  response:
    body:
      string: ''
    headers:
      server:
      - Windows-Azure-Blob/1.0 Microsoft-HTTPAPI/2.0
      transfer-encoding:
      - chunked
      vary:
      - Origin
      x-ms-error-code:
      - BlobNotFound
      x-ms-version:
      - '2023-11-03'
    status:
      code: 404
      message: The specified blob does not exist.
- request:
    body: '{"flowDefinitionDataStoreName": "workspaceblobstore", "flowDefinitionBlobPath":
      "LocalUpload/000000000000000000000000000000000000/three/flow.dag.yaml", "runId":
      "run2", "runDisplayName": "run2", "runExperimentName": "", "variantRunId": "run1",
      "batchDataInput": {}, "inputsMapping": {"number": "${run.outputs.output}"},
      "connections": {}, "environmentVariables": {}, "runtimeName": "fake-runtime-name",
      "sessionId": "000000000000000000000000000000000000000000000000", "flowLineageId":
      "0000000000000000000000000000000000000000000000000000000000000000", "runDisplayNameGenerationType":
      "UserProvidedMacro"}'
    headers:
      Accept:
      - application/json
      Accept-Encoding:
      - gzip, deflate
      Connection:
      - keep-alive
      Content-Length:
      - '700'
      Content-Type:
      - application/json
      User-Agent:
      - promptflow-sdk/0.0.1 azsdk-python-azuremachinelearningdesignerserviceclient/unknown
        Python/3.10.13 (Windows-10-10.0.22631-SP0)
    method: POST
    uri: https://eastus.api.azureml.ms/flow/api/subscriptions/00000000-0000-0000-0000-000000000000/resourceGroups/00000/providers/Microsoft.MachineLearningServices/workspaces/00000/BulkRuns/submit
  response:
    body:
      string: '"run2"'
    headers:
      connection:
      - keep-alive
      content-length:
      - '38'
      content-type:
      - application/json; charset=utf-8
      strict-transport-security:
      - max-age=15724800; includeSubDomains; preload
      x-content-type-options:
      - nosniff
      x-request-time:
      - '5.766'
    status:
      code: 200
      message: OK
- request:
    body: null
    headers:
      Accept:
      - application/json
      Accept-Encoding:
      - gzip, deflate
      Connection:
      - keep-alive
      User-Agent:
      - promptflow-sdk/0.0.1 azsdk-python-azuremachinelearningdesignerserviceclient/unknown
        Python/3.10.13 (Windows-10-10.0.22631-SP0)
    method: GET
    uri: https://eastus.api.azureml.ms/flow/api/subscriptions/00000000-0000-0000-0000-000000000000/resourceGroups/00000/providers/Microsoft.MachineLearningServices/workspaces/00000/BulkRuns/run2
  response:
    body:
      string: '{"flowGraph": {"nodes": [{"name": "mod_three", "type": "python", "source":
        {"type": "code", "path": "mod_three.py"}, "inputs": {"number": "${inputs.number}"},
        "tool": "mod_three.py", "reduce": false}], "tools": [{"name": "Content Safety
        (Text Analyze)", "type": "python", "inputs": {"connection": {"type": ["AzureContentSafetyConnection"],
        "allow_manual_entry": false, "is_multi_select": false, "input_type": "default"},
        "hate_category": {"type": ["string"], "default": "medium_sensitivity", "enum":
        ["disable", "low_sensitivity", "medium_sensitivity", "high_sensitivity"],
        "allow_manual_entry": false, "is_multi_select": false, "input_type": "default"},
        "self_harm_category": {"type": ["string"], "default": "medium_sensitivity",
        "enum": ["disable", "low_sensitivity", "medium_sensitivity", "high_sensitivity"],
        "allow_manual_entry": false, "is_multi_select": false, "input_type": "default"},
        "sexual_category": {"type": ["string"], "default": "medium_sensitivity", "enum":
        ["disable", "low_sensitivity", "medium_sensitivity", "high_sensitivity"],
        "allow_manual_entry": false, "is_multi_select": false, "input_type": "default"},
        "text": {"type": ["string"], "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}, "violence_category": {"type": ["string"],
        "default": "medium_sensitivity", "enum": ["disable", "low_sensitivity", "medium_sensitivity",
        "high_sensitivity"], "allow_manual_entry": false, "is_multi_select": false,
        "input_type": "default"}}, "description": "Use Azure Content Safety to detect
        harmful content.", "module": "promptflow.tools.azure_content_safety", "function":
        "analyze_text", "is_builtin": true, "package": "promptflow-tools", "package_version":
        "0.0.216", "enable_kwargs": false, "deprecated_tools": ["content_safety_text.tools.content_safety_text_tool.analyze_text"],
        "tool_state": "stable"}, {"name": "Embedding", "type": "python", "inputs":
        {"connection": {"type": ["AzureOpenAIConnection", "OpenAIConnection"], "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "deployment_name":
        {"type": ["string"], "enabled_by": "connection", "enabled_by_type": ["AzureOpenAIConnection"],
        "model_list": ["text-embedding-ada-002", "text-search-ada-doc-001", "text-search-ada-query-001"],
        "capabilities": {"completion": false, "chat_completion": false, "embeddings":
        true}, "allow_manual_entry": false, "is_multi_select": false, "input_type":
        "default"}, "input": {"type": ["string"], "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}, "model": {"type": ["string"], "enum": ["text-embedding-ada-002",
        "text-search-ada-doc-001", "text-search-ada-query-001"], "enabled_by": "connection",
        "enabled_by_type": ["OpenAIConnection"], "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}}, "description": "Use Open AI''s embedding
        model to create an embedding vector representing the input text.", "module":
        "promptflow.tools.embedding", "function": "embedding", "is_builtin": true,
        "package": "promptflow-tools", "package_version": "0.0.216", "enable_kwargs":
        false, "tool_state": "stable"}, {"name": "Open Source LLM", "type": "custom_llm",
        "inputs": {"api": {"type": ["string"], "enum": ["chat", "completion"], "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "connection": {"type":
        ["CustomConnection"], "allow_manual_entry": false, "is_multi_select": false,
        "input_type": "default"}, "deployment_name": {"type": ["string"], "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "endpoint_name":
        {"type": ["string"], "default": "-- please enter an endpoint name --", "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "max_new_tokens":
        {"type": ["int"], "default": 500, "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}, "model_kwargs": {"type": ["object"], "default":
        "{}", "allow_manual_entry": false, "is_multi_select": false, "input_type":
        "default", "advanced": true}, "temperature": {"type": ["double"], "default":
        1.0, "allow_manual_entry": false, "is_multi_select": false, "input_type":
        "default"}, "top_p": {"type": ["double"], "default": 1.0, "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default", "advanced": true}},
        "description": "Use an Open Source model from the Azure Model catalog, deployed
        to an AzureML Online Endpoint for LLM Chat or Completion API calls.", "module":
        "promptflow.tools.open_source_llm", "class_name": "OpenSourceLLM", "function":
        "call", "icon": "data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAACgElEQVR4nGWSz2vcVRTFP/e9NzOZ1KDGohASslLEH6VLV0ak4l/QpeDCrfQPcNGliODKnVm4EBdBsIjQIlhciKW0ycKFVCSNbYnjdDLtmPnmO/nO9917XcxMkjYX3uLx7nnn3HOuMK2Nix4fP78ZdrYXVkLVWjf3l3B1B+HpcjzGFtmqa6cePz7/x0dnn1n5qhj3iBJPYREIURAJuCtpY8PjReDbrf9WG7H1fuefwQU9qKztTcMJT+PNnEFvjGVDBDlSsH6p/9MLzy6+NxwVqI8RAg4IPmWedMckdLYP6O6UpIaQfvyyXG012+e79/ZfHukoS1ISMT2hGTB1RkUmNgQ5QZ0w+a2VWDq73MbdEWmfnnv6UWe7oNzPaLapl5CwuLTXK9WUGBuCjqekzhP+z52ZXOrKMD3OJg0Hh778aiOuvpnYvp05d6GJO4iAO4QAe/eV36/X5LFRV4Zmn+AdkqlL8Vjp3oVioOz+WTPzzYEgsN+fgPLYyJVheSbPPVl2ikeGZRjtG52/8rHuaV9VOlpP2OtKyVndcRVCSqOhsvxa4vW359i6OuKdD+aP8Q4SYPdOzS/flGjt1JUSaMqZ5nwa1Y8qWb/Ud/eZZkHisYezEM0m+fcelDr8F1SqW2LNK6r1jXQwyLzy1hxvrLXZulry7ocL+FS6G4QIu3fG/Px1gdYeW7LIgXU2P/115TOA5G7e3Rmj2aS/m7l5pThiZzrCcE/d1XHzbln373nw7y6veeoUm5KCNKT/IPPwbiY1hYd/l5MIT65BMFt87sU4v9D7/JMflr44uV6hGh1+L4RCkg6z5iK2tAhNLeLsNGwYA4fDYnC/drvuuFxe86NV/x+Ut27g0FvykgAAAABJRU5ErkJggg==",
        "is_builtin": true, "package": "promptflow-tools", "package_version": "0.0.216",
        "enable_kwargs": false, "tool_state": "stable"}, {"name": "OpenAI GPT-4V",
        "type": "custom_llm", "inputs": {"connection": {"type": ["OpenAIConnection"],
        "allow_manual_entry": false, "is_multi_select": false, "input_type": "default"},
        "frequency_penalty": {"type": ["double"], "default": 0, "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "max_tokens": {"type":
        ["int"], "default": "", "allow_manual_entry": false, "is_multi_select": false,
        "input_type": "default"}, "model": {"type": ["string"], "enum": ["gpt-4-vision-preview"],
        "allow_manual_entry": true, "is_multi_select": false, "input_type": "default"},
        "presence_penalty": {"type": ["double"], "default": 0, "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "stop": {"type":
        ["list"], "default": "", "allow_manual_entry": false, "is_multi_select": false,
        "input_type": "default"}, "temperature": {"type": ["double"], "default": 1,
        "allow_manual_entry": false, "is_multi_select": false, "input_type": "default"},
        "top_p": {"type": ["double"], "default": 1, "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}}, "description": "Use OpenAI GPT-4V to leverage
        vision ability.", "module": "promptflow.tools.openai_gpt4v", "class_name":
        "OpenAI", "function": "chat", "is_builtin": true, "package": "promptflow-tools",
        "package_version": "0.0.216", "default_prompt": "# system:\nAs an AI assistant,
        your task involves interpreting images and responding to questions about the
        image.\nRemember to provide accurate answers based on the information present
        in the image.\n\n# user:\nCan you tell me what the image depicts?\n![image]({{image_input}})\n",
        "enable_kwargs": false, "tool_state": "stable"}, {"name": "Serp API", "type":
        "python", "inputs": {"connection": {"type": ["SerpConnection"], "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "engine": {"type":
        ["string"], "default": "google", "enum": ["google", "bing"], "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "location": {"type":
        ["string"], "default": "", "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}, "num": {"type": ["int"], "default": "10",
        "allow_manual_entry": false, "is_multi_select": false, "input_type": "default"},
        "query": {"type": ["string"], "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}, "safe": {"type": ["string"], "default": "off",
        "enum": ["active", "off"], "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}}, "description": "Use Serp API to obtain search
        results from a specific search engine.", "module": "promptflow.tools.serpapi",
        "class_name": "SerpAPI", "function": "search", "is_builtin": true, "package":
        "promptflow-tools", "package_version": "0.0.216", "enable_kwargs": false,
        "tool_state": "stable"}, {"name": "Faiss Index Lookup", "type": "python",
        "inputs": {"path": {"type": ["string"], "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}, "top_k": {"type": ["int"], "default": "3",
        "allow_manual_entry": false, "is_multi_select": false, "input_type": "default"},
        "vector": {"type": ["list"], "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}}, "description": "Search vector based query
        from the FAISS index file.", "module": "promptflow_vectordb.tool.faiss_index_lookup",
        "class_name": "FaissIndexLookup", "function": "search", "is_builtin": true,
        "package": "promptflow-vectordb", "package_version": "0.0.1", "enable_kwargs":
        false, "tool_state": "stable"}, {"name": "Vector DB Lookup", "type": "python",
        "inputs": {"class_name": {"type": ["string"], "enabled_by": "connection",
        "enabled_by_type": ["WeaviateConnection"], "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}, "collection_name": {"type": ["string"], "enabled_by":
        "connection", "enabled_by_type": ["QdrantConnection"], "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "connection": {"type":
        ["CognitiveSearchConnection", "QdrantConnection", "WeaviateConnection"], "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "index_name": {"type":
        ["string"], "enabled_by": "connection", "enabled_by_type": ["CognitiveSearchConnection"],
        "allow_manual_entry": false, "is_multi_select": false, "input_type": "default"},
        "search_filters": {"type": ["object"], "enabled_by": "connection", "enabled_by_type":
        ["CognitiveSearchConnection", "QdrantConnection"], "allow_manual_entry": false,
        "is_multi_select": false, "input_type": "default"}, "search_params": {"type":
        ["object"], "enabled_by": "connection", "enabled_by_type": ["CognitiveSearchConnection",
        "QdrantConnection"], "allow_manual_entry": false, "is_multi_select": false,
        "input_type": "default"}, "text_field": {"type": ["string"], "enabled_by":
        "connection", "enabled_by_type": ["CognitiveSearchConnection", "QdrantConnection",
        "WeaviateConnection"], "allow_manual_entry": false, "is_multi_select": false,
        "input_type": "default"}, "top_k": {"type": ["int"], "default": "3", "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "vector": {"type":
        ["list"], "allow_manual_entry": false, "is_multi_select": false, "input_type":
        "default"}, "vector_field": {"type": ["string"], "enabled_by": "connection",
        "enabled_by_type": ["CognitiveSearchConnection"], "allow_manual_entry": false,
        "is_multi_select": false, "input_type": "default"}}, "description": "Search
        vector based query from existing Vector Database.", "module": "promptflow_vectordb.tool.vector_db_lookup",
        "class_name": "VectorDBLookup", "function": "search", "is_builtin": true,
        "package": "promptflow-vectordb", "package_version": "0.0.1", "enable_kwargs":
        false, "tool_state": "stable"}, {"name": "Vector Index Lookup", "type": "python",
        "inputs": {"path": {"type": ["string"], "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}, "query": {"type": ["object"], "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "top_k": {"type":
        ["int"], "default": "3", "allow_manual_entry": false, "is_multi_select": false,
        "input_type": "default"}}, "description": "Search text or vector based query
        from AzureML Vector Index.", "module": "promptflow_vectordb.tool.vector_index_lookup",
        "class_name": "VectorIndexLookup", "function": "search", "is_builtin": true,
        "package": "promptflow-vectordb", "package_version": "0.0.1", "enable_kwargs":
        false, "tool_state": "stable"}, {"name": "mod_three.py", "type": "python",
        "inputs": {"number": {"type": ["int"], "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}}, "source": "mod_three.py", "function": "mod_three",
        "is_builtin": false, "enable_kwargs": false, "tool_state": "stable"}], "inputs":
        {"number": {"type": "int", "is_chat_input": false}}, "outputs": {"output":
        {"type": "int", "reference": "${mod_three.output.value}", "evaluation_only":
        false, "is_chat_output": false}}}, "flowRunResourceId": "azureml://locations/eastus/workspaces/00000/flows/run2/flowRuns/run2",
        "flowRunId": "run2", "flowRunDisplayName": "run2", "batchDataInput": {}, "flowRunType":
        "FlowRun", "flowType": "Default", "runtimeName": "test-runtime-ci", "inputsMapping":
        {"number": "${run.outputs.output}"}, "outputDatastoreName": "workspaceblobstore",
        "childRunBasePath": "promptflow/PromptFlowArtifacts/run2/flow_artifacts",
        "flowDagFileRelativePath": "flow.dag.yaml", "flowSnapshotId": "f29cc6c7-8cd6-4330-9194-d8818a21f8d8",
        "studioPortalEndpoint": "https://ml.azure.com/runs/run2?wsid=/subscriptions/00000000-0000-0000-0000-000000000000/resourcegroups/00000/providers/Microsoft.MachineLearningServices/workspaces/00000"}'
    headers:
      connection:
      - keep-alive
      content-length:
      - '12766'
      content-type:
      - application/json; charset=utf-8
      strict-transport-security:
      - max-age=15724800; includeSubDomains; preload
      transfer-encoding:
      - chunked
      vary:
      - Accept-Encoding
      x-content-type-options:
      - nosniff
      x-request-time:
      - '0.278'
    status:
      code: 200
      message: OK
- request:
    body: null
    headers:
      Accept:
      - application/json
      Accept-Encoding:
      - gzip, deflate
      Connection:
      - keep-alive
      User-Agent:
      - promptflow-sdk/0.0.1 azsdk-python-azuremachinelearningdesignerserviceclient/unknown
        Python/3.10.13 (Windows-10-10.0.22631-SP0)
    method: GET
    uri: https://eastus.api.azureml.ms/flow/api/subscriptions/00000000-0000-0000-0000-000000000000/resourceGroups/00000/providers/Microsoft.MachineLearningServices/workspaces/00000/BulkRuns/run2
  response:
    body:
      string: '{"flowGraph": {"nodes": [{"name": "mod_three", "type": "python", "source":
        {"type": "code", "path": "mod_three.py"}, "inputs": {"number": "${inputs.number}"},
        "tool": "mod_three.py", "reduce": false}], "tools": [{"name": "Content Safety
        (Text Analyze)", "type": "python", "inputs": {"connection": {"type": ["AzureContentSafetyConnection"],
        "allow_manual_entry": false, "is_multi_select": false, "input_type": "default"},
        "hate_category": {"type": ["string"], "default": "medium_sensitivity", "enum":
        ["disable", "low_sensitivity", "medium_sensitivity", "high_sensitivity"],
        "allow_manual_entry": false, "is_multi_select": false, "input_type": "default"},
        "self_harm_category": {"type": ["string"], "default": "medium_sensitivity",
        "enum": ["disable", "low_sensitivity", "medium_sensitivity", "high_sensitivity"],
        "allow_manual_entry": false, "is_multi_select": false, "input_type": "default"},
        "sexual_category": {"type": ["string"], "default": "medium_sensitivity", "enum":
        ["disable", "low_sensitivity", "medium_sensitivity", "high_sensitivity"],
        "allow_manual_entry": false, "is_multi_select": false, "input_type": "default"},
        "text": {"type": ["string"], "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}, "violence_category": {"type": ["string"],
        "default": "medium_sensitivity", "enum": ["disable", "low_sensitivity", "medium_sensitivity",
        "high_sensitivity"], "allow_manual_entry": false, "is_multi_select": false,
        "input_type": "default"}}, "description": "Use Azure Content Safety to detect
        harmful content.", "module": "promptflow.tools.azure_content_safety", "function":
        "analyze_text", "is_builtin": true, "package": "promptflow-tools", "package_version":
        "0.0.216", "enable_kwargs": false, "deprecated_tools": ["content_safety_text.tools.content_safety_text_tool.analyze_text"],
        "tool_state": "stable"}, {"name": "Embedding", "type": "python", "inputs":
        {"connection": {"type": ["AzureOpenAIConnection", "OpenAIConnection"], "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "deployment_name":
        {"type": ["string"], "enabled_by": "connection", "enabled_by_type": ["AzureOpenAIConnection"],
        "model_list": ["text-embedding-ada-002", "text-search-ada-doc-001", "text-search-ada-query-001"],
        "capabilities": {"completion": false, "chat_completion": false, "embeddings":
        true}, "allow_manual_entry": false, "is_multi_select": false, "input_type":
        "default"}, "input": {"type": ["string"], "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}, "model": {"type": ["string"], "enum": ["text-embedding-ada-002",
        "text-search-ada-doc-001", "text-search-ada-query-001"], "enabled_by": "connection",
        "enabled_by_type": ["OpenAIConnection"], "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}}, "description": "Use Open AI''s embedding
        model to create an embedding vector representing the input text.", "module":
        "promptflow.tools.embedding", "function": "embedding", "is_builtin": true,
        "package": "promptflow-tools", "package_version": "0.0.216", "enable_kwargs":
        false, "tool_state": "stable"}, {"name": "Open Source LLM", "type": "custom_llm",
        "inputs": {"api": {"type": ["string"], "enum": ["chat", "completion"], "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "connection": {"type":
        ["CustomConnection"], "allow_manual_entry": false, "is_multi_select": false,
        "input_type": "default"}, "deployment_name": {"type": ["string"], "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "endpoint_name":
        {"type": ["string"], "default": "-- please enter an endpoint name --", "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "max_new_tokens":
        {"type": ["int"], "default": 500, "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}, "model_kwargs": {"type": ["object"], "default":
        "{}", "allow_manual_entry": false, "is_multi_select": false, "input_type":
        "default", "advanced": true}, "temperature": {"type": ["double"], "default":
        1.0, "allow_manual_entry": false, "is_multi_select": false, "input_type":
        "default"}, "top_p": {"type": ["double"], "default": 1.0, "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default", "advanced": true}},
        "description": "Use an Open Source model from the Azure Model catalog, deployed
        to an AzureML Online Endpoint for LLM Chat or Completion API calls.", "module":
        "promptflow.tools.open_source_llm", "class_name": "OpenSourceLLM", "function":
        "call", "icon": "data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAACgElEQVR4nGWSz2vcVRTFP/e9NzOZ1KDGohASslLEH6VLV0ak4l/QpeDCrfQPcNGliODKnVm4EBdBsIjQIlhciKW0ycKFVCSNbYnjdDLtmPnmO/nO9917XcxMkjYX3uLx7nnn3HOuMK2Nix4fP78ZdrYXVkLVWjf3l3B1B+HpcjzGFtmqa6cePz7/x0dnn1n5qhj3iBJPYREIURAJuCtpY8PjReDbrf9WG7H1fuefwQU9qKztTcMJT+PNnEFvjGVDBDlSsH6p/9MLzy6+NxwVqI8RAg4IPmWedMckdLYP6O6UpIaQfvyyXG012+e79/ZfHukoS1ISMT2hGTB1RkUmNgQ5QZ0w+a2VWDq73MbdEWmfnnv6UWe7oNzPaLapl5CwuLTXK9WUGBuCjqekzhP+z52ZXOrKMD3OJg0Hh778aiOuvpnYvp05d6GJO4iAO4QAe/eV36/X5LFRV4Zmn+AdkqlL8Vjp3oVioOz+WTPzzYEgsN+fgPLYyJVheSbPPVl2ikeGZRjtG52/8rHuaV9VOlpP2OtKyVndcRVCSqOhsvxa4vW359i6OuKdD+aP8Q4SYPdOzS/flGjt1JUSaMqZ5nwa1Y8qWb/Ud/eZZkHisYezEM0m+fcelDr8F1SqW2LNK6r1jXQwyLzy1hxvrLXZulry7ocL+FS6G4QIu3fG/Px1gdYeW7LIgXU2P/115TOA5G7e3Rmj2aS/m7l5pThiZzrCcE/d1XHzbln373nw7y6veeoUm5KCNKT/IPPwbiY1hYd/l5MIT65BMFt87sU4v9D7/JMflr44uV6hGh1+L4RCkg6z5iK2tAhNLeLsNGwYA4fDYnC/drvuuFxe86NV/x+Ut27g0FvykgAAAABJRU5ErkJggg==",
        "is_builtin": true, "package": "promptflow-tools", "package_version": "0.0.216",
        "enable_kwargs": false, "tool_state": "stable"}, {"name": "OpenAI GPT-4V",
        "type": "custom_llm", "inputs": {"connection": {"type": ["OpenAIConnection"],
        "allow_manual_entry": false, "is_multi_select": false, "input_type": "default"},
        "frequency_penalty": {"type": ["double"], "default": 0, "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "max_tokens": {"type":
        ["int"], "default": "", "allow_manual_entry": false, "is_multi_select": false,
        "input_type": "default"}, "model": {"type": ["string"], "enum": ["gpt-4-vision-preview"],
        "allow_manual_entry": true, "is_multi_select": false, "input_type": "default"},
        "presence_penalty": {"type": ["double"], "default": 0, "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "stop": {"type":
        ["list"], "default": "", "allow_manual_entry": false, "is_multi_select": false,
        "input_type": "default"}, "temperature": {"type": ["double"], "default": 1,
        "allow_manual_entry": false, "is_multi_select": false, "input_type": "default"},
        "top_p": {"type": ["double"], "default": 1, "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}}, "description": "Use OpenAI GPT-4V to leverage
        vision ability.", "module": "promptflow.tools.openai_gpt4v", "class_name":
        "OpenAI", "function": "chat", "is_builtin": true, "package": "promptflow-tools",
        "package_version": "0.0.216", "default_prompt": "# system:\nAs an AI assistant,
        your task involves interpreting images and responding to questions about the
        image.\nRemember to provide accurate answers based on the information present
        in the image.\n\n# user:\nCan you tell me what the image depicts?\n![image]({{image_input}})\n",
        "enable_kwargs": false, "tool_state": "stable"}, {"name": "Serp API", "type":
        "python", "inputs": {"connection": {"type": ["SerpConnection"], "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "engine": {"type":
        ["string"], "default": "google", "enum": ["google", "bing"], "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "location": {"type":
        ["string"], "default": "", "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}, "num": {"type": ["int"], "default": "10",
        "allow_manual_entry": false, "is_multi_select": false, "input_type": "default"},
        "query": {"type": ["string"], "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}, "safe": {"type": ["string"], "default": "off",
        "enum": ["active", "off"], "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}}, "description": "Use Serp API to obtain search
        results from a specific search engine.", "module": "promptflow.tools.serpapi",
        "class_name": "SerpAPI", "function": "search", "is_builtin": true, "package":
        "promptflow-tools", "package_version": "0.0.216", "enable_kwargs": false,
        "tool_state": "stable"}, {"name": "Faiss Index Lookup", "type": "python",
        "inputs": {"path": {"type": ["string"], "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}, "top_k": {"type": ["int"], "default": "3",
        "allow_manual_entry": false, "is_multi_select": false, "input_type": "default"},
        "vector": {"type": ["list"], "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}}, "description": "Search vector based query
        from the FAISS index file.", "module": "promptflow_vectordb.tool.faiss_index_lookup",
        "class_name": "FaissIndexLookup", "function": "search", "is_builtin": true,
        "package": "promptflow-vectordb", "package_version": "0.0.1", "enable_kwargs":
        false, "tool_state": "stable"}, {"name": "Vector DB Lookup", "type": "python",
        "inputs": {"class_name": {"type": ["string"], "enabled_by": "connection",
        "enabled_by_type": ["WeaviateConnection"], "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}, "collection_name": {"type": ["string"], "enabled_by":
        "connection", "enabled_by_type": ["QdrantConnection"], "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "connection": {"type":
        ["CognitiveSearchConnection", "QdrantConnection", "WeaviateConnection"], "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "index_name": {"type":
        ["string"], "enabled_by": "connection", "enabled_by_type": ["CognitiveSearchConnection"],
        "allow_manual_entry": false, "is_multi_select": false, "input_type": "default"},
        "search_filters": {"type": ["object"], "enabled_by": "connection", "enabled_by_type":
        ["CognitiveSearchConnection", "QdrantConnection"], "allow_manual_entry": false,
        "is_multi_select": false, "input_type": "default"}, "search_params": {"type":
        ["object"], "enabled_by": "connection", "enabled_by_type": ["CognitiveSearchConnection",
        "QdrantConnection"], "allow_manual_entry": false, "is_multi_select": false,
        "input_type": "default"}, "text_field": {"type": ["string"], "enabled_by":
        "connection", "enabled_by_type": ["CognitiveSearchConnection", "QdrantConnection",
        "WeaviateConnection"], "allow_manual_entry": false, "is_multi_select": false,
        "input_type": "default"}, "top_k": {"type": ["int"], "default": "3", "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "vector": {"type":
        ["list"], "allow_manual_entry": false, "is_multi_select": false, "input_type":
        "default"}, "vector_field": {"type": ["string"], "enabled_by": "connection",
        "enabled_by_type": ["CognitiveSearchConnection"], "allow_manual_entry": false,
        "is_multi_select": false, "input_type": "default"}}, "description": "Search
        vector based query from existing Vector Database.", "module": "promptflow_vectordb.tool.vector_db_lookup",
        "class_name": "VectorDBLookup", "function": "search", "is_builtin": true,
        "package": "promptflow-vectordb", "package_version": "0.0.1", "enable_kwargs":
        false, "tool_state": "stable"}, {"name": "Vector Index Lookup", "type": "python",
        "inputs": {"path": {"type": ["string"], "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}, "query": {"type": ["object"], "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "top_k": {"type":
        ["int"], "default": "3", "allow_manual_entry": false, "is_multi_select": false,
        "input_type": "default"}}, "description": "Search text or vector based query
        from AzureML Vector Index.", "module": "promptflow_vectordb.tool.vector_index_lookup",
        "class_name": "VectorIndexLookup", "function": "search", "is_builtin": true,
        "package": "promptflow-vectordb", "package_version": "0.0.1", "enable_kwargs":
        false, "tool_state": "stable"}, {"name": "mod_three.py", "type": "python",
        "inputs": {"number": {"type": ["int"], "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}}, "source": "mod_three.py", "function": "mod_three",
        "is_builtin": false, "enable_kwargs": false, "tool_state": "stable"}], "inputs":
        {"number": {"type": "int", "is_chat_input": false}}, "outputs": {"output":
        {"type": "int", "reference": "${mod_three.output.value}", "evaluation_only":
        false, "is_chat_output": false}}}, "flowRunResourceId": "azureml://locations/eastus/workspaces/00000/flows/run2/flowRuns/run2",
        "flowRunId": "run2", "flowRunDisplayName": "run2", "batchDataInput": {}, "flowRunType":
        "FlowRun", "flowType": "Default", "runtimeName": "test-runtime-ci", "inputsMapping":
        {"number": "${run.outputs.output}"}, "outputDatastoreName": "workspaceblobstore",
        "childRunBasePath": "promptflow/PromptFlowArtifacts/run2/flow_artifacts",
        "flowDagFileRelativePath": "flow.dag.yaml", "flowSnapshotId": "f29cc6c7-8cd6-4330-9194-d8818a21f8d8",
        "studioPortalEndpoint": "https://ml.azure.com/runs/run2?wsid=/subscriptions/00000000-0000-0000-0000-000000000000/resourcegroups/00000/providers/Microsoft.MachineLearningServices/workspaces/00000"}'
    headers:
      connection:
      - keep-alive
      content-length:
      - '12766'
      content-type:
      - application/json; charset=utf-8
      strict-transport-security:
      - max-age=15724800; includeSubDomains; preload
      transfer-encoding:
      - chunked
      vary:
      - Accept-Encoding
      x-content-type-options:
      - nosniff
      x-request-time:
      - '0.282'
    status:
      code: 200
      message: OK
- request:
    body: null
    headers:
      Accept:
      - application/json
      Accept-Encoding:
      - gzip, deflate
      Connection:
      - keep-alive
      User-Agent:
      - promptflow-sdk/0.0.1 azsdk-python-azuremachinelearningdesignerserviceclient/unknown
        Python/3.10.13 (Windows-10-10.0.22631-SP0)
    method: GET
    uri: https://eastus.api.azureml.ms/flow/api/subscriptions/00000000-0000-0000-0000-000000000000/resourceGroups/00000/providers/Microsoft.MachineLearningServices/workspaces/00000/BulkRuns/run2
  response:
    body:
      string: '{"flowGraph": {"nodes": [{"name": "mod_three", "type": "python", "source":
        {"type": "code", "path": "mod_three.py"}, "inputs": {"number": "${inputs.number}"},
        "tool": "mod_three.py", "reduce": false}], "tools": [{"name": "Content Safety
        (Text Analyze)", "type": "python", "inputs": {"connection": {"type": ["AzureContentSafetyConnection"],
        "allow_manual_entry": false, "is_multi_select": false, "input_type": "default"},
        "hate_category": {"type": ["string"], "default": "medium_sensitivity", "enum":
        ["disable", "low_sensitivity", "medium_sensitivity", "high_sensitivity"],
        "allow_manual_entry": false, "is_multi_select": false, "input_type": "default"},
        "self_harm_category": {"type": ["string"], "default": "medium_sensitivity",
        "enum": ["disable", "low_sensitivity", "medium_sensitivity", "high_sensitivity"],
        "allow_manual_entry": false, "is_multi_select": false, "input_type": "default"},
        "sexual_category": {"type": ["string"], "default": "medium_sensitivity", "enum":
        ["disable", "low_sensitivity", "medium_sensitivity", "high_sensitivity"],
        "allow_manual_entry": false, "is_multi_select": false, "input_type": "default"},
        "text": {"type": ["string"], "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}, "violence_category": {"type": ["string"],
        "default": "medium_sensitivity", "enum": ["disable", "low_sensitivity", "medium_sensitivity",
        "high_sensitivity"], "allow_manual_entry": false, "is_multi_select": false,
        "input_type": "default"}}, "description": "Use Azure Content Safety to detect
        harmful content.", "module": "promptflow.tools.azure_content_safety", "function":
        "analyze_text", "is_builtin": true, "package": "promptflow-tools", "package_version":
        "0.0.216", "enable_kwargs": false, "deprecated_tools": ["content_safety_text.tools.content_safety_text_tool.analyze_text"],
        "tool_state": "stable"}, {"name": "Embedding", "type": "python", "inputs":
        {"connection": {"type": ["AzureOpenAIConnection", "OpenAIConnection"], "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "deployment_name":
        {"type": ["string"], "enabled_by": "connection", "enabled_by_type": ["AzureOpenAIConnection"],
        "model_list": ["text-embedding-ada-002", "text-search-ada-doc-001", "text-search-ada-query-001"],
        "capabilities": {"completion": false, "chat_completion": false, "embeddings":
        true}, "allow_manual_entry": false, "is_multi_select": false, "input_type":
        "default"}, "input": {"type": ["string"], "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}, "model": {"type": ["string"], "enum": ["text-embedding-ada-002",
        "text-search-ada-doc-001", "text-search-ada-query-001"], "enabled_by": "connection",
        "enabled_by_type": ["OpenAIConnection"], "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}}, "description": "Use Open AI''s embedding
        model to create an embedding vector representing the input text.", "module":
        "promptflow.tools.embedding", "function": "embedding", "is_builtin": true,
        "package": "promptflow-tools", "package_version": "0.0.216", "enable_kwargs":
        false, "tool_state": "stable"}, {"name": "Open Source LLM", "type": "custom_llm",
        "inputs": {"api": {"type": ["string"], "enum": ["chat", "completion"], "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "connection": {"type":
        ["CustomConnection"], "allow_manual_entry": false, "is_multi_select": false,
        "input_type": "default"}, "deployment_name": {"type": ["string"], "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "endpoint_name":
        {"type": ["string"], "default": "-- please enter an endpoint name --", "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "max_new_tokens":
        {"type": ["int"], "default": 500, "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}, "model_kwargs": {"type": ["object"], "default":
        "{}", "allow_manual_entry": false, "is_multi_select": false, "input_type":
        "default", "advanced": true}, "temperature": {"type": ["double"], "default":
        1.0, "allow_manual_entry": false, "is_multi_select": false, "input_type":
        "default"}, "top_p": {"type": ["double"], "default": 1.0, "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default", "advanced": true}},
        "description": "Use an Open Source model from the Azure Model catalog, deployed
        to an AzureML Online Endpoint for LLM Chat or Completion API calls.", "module":
        "promptflow.tools.open_source_llm", "class_name": "OpenSourceLLM", "function":
        "call", "icon": "data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAACgElEQVR4nGWSz2vcVRTFP/e9NzOZ1KDGohASslLEH6VLV0ak4l/QpeDCrfQPcNGliODKnVm4EBdBsIjQIlhciKW0ycKFVCSNbYnjdDLtmPnmO/nO9917XcxMkjYX3uLx7nnn3HOuMK2Nix4fP78ZdrYXVkLVWjf3l3B1B+HpcjzGFtmqa6cePz7/x0dnn1n5qhj3iBJPYREIURAJuCtpY8PjReDbrf9WG7H1fuefwQU9qKztTcMJT+PNnEFvjGVDBDlSsH6p/9MLzy6+NxwVqI8RAg4IPmWedMckdLYP6O6UpIaQfvyyXG012+e79/ZfHukoS1ISMT2hGTB1RkUmNgQ5QZ0w+a2VWDq73MbdEWmfnnv6UWe7oNzPaLapl5CwuLTXK9WUGBuCjqekzhP+z52ZXOrKMD3OJg0Hh778aiOuvpnYvp05d6GJO4iAO4QAe/eV36/X5LFRV4Zmn+AdkqlL8Vjp3oVioOz+WTPzzYEgsN+fgPLYyJVheSbPPVl2ikeGZRjtG52/8rHuaV9VOlpP2OtKyVndcRVCSqOhsvxa4vW359i6OuKdD+aP8Q4SYPdOzS/flGjt1JUSaMqZ5nwa1Y8qWb/Ud/eZZkHisYezEM0m+fcelDr8F1SqW2LNK6r1jXQwyLzy1hxvrLXZulry7ocL+FS6G4QIu3fG/Px1gdYeW7LIgXU2P/115TOA5G7e3Rmj2aS/m7l5pThiZzrCcE/d1XHzbln373nw7y6veeoUm5KCNKT/IPPwbiY1hYd/l5MIT65BMFt87sU4v9D7/JMflr44uV6hGh1+L4RCkg6z5iK2tAhNLeLsNGwYA4fDYnC/drvuuFxe86NV/x+Ut27g0FvykgAAAABJRU5ErkJggg==",
        "is_builtin": true, "package": "promptflow-tools", "package_version": "0.0.216",
        "enable_kwargs": false, "tool_state": "stable"}, {"name": "OpenAI GPT-4V",
        "type": "custom_llm", "inputs": {"connection": {"type": ["OpenAIConnection"],
        "allow_manual_entry": false, "is_multi_select": false, "input_type": "default"},
        "frequency_penalty": {"type": ["double"], "default": 0, "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "max_tokens": {"type":
        ["int"], "default": "", "allow_manual_entry": false, "is_multi_select": false,
        "input_type": "default"}, "model": {"type": ["string"], "enum": ["gpt-4-vision-preview"],
        "allow_manual_entry": true, "is_multi_select": false, "input_type": "default"},
        "presence_penalty": {"type": ["double"], "default": 0, "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "stop": {"type":
        ["list"], "default": "", "allow_manual_entry": false, "is_multi_select": false,
        "input_type": "default"}, "temperature": {"type": ["double"], "default": 1,
        "allow_manual_entry": false, "is_multi_select": false, "input_type": "default"},
        "top_p": {"type": ["double"], "default": 1, "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}}, "description": "Use OpenAI GPT-4V to leverage
        vision ability.", "module": "promptflow.tools.openai_gpt4v", "class_name":
        "OpenAI", "function": "chat", "is_builtin": true, "package": "promptflow-tools",
        "package_version": "0.0.216", "default_prompt": "# system:\nAs an AI assistant,
        your task involves interpreting images and responding to questions about the
        image.\nRemember to provide accurate answers based on the information present
        in the image.\n\n# user:\nCan you tell me what the image depicts?\n![image]({{image_input}})\n",
        "enable_kwargs": false, "tool_state": "stable"}, {"name": "Serp API", "type":
        "python", "inputs": {"connection": {"type": ["SerpConnection"], "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "engine": {"type":
        ["string"], "default": "google", "enum": ["google", "bing"], "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "location": {"type":
        ["string"], "default": "", "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}, "num": {"type": ["int"], "default": "10",
        "allow_manual_entry": false, "is_multi_select": false, "input_type": "default"},
        "query": {"type": ["string"], "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}, "safe": {"type": ["string"], "default": "off",
        "enum": ["active", "off"], "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}}, "description": "Use Serp API to obtain search
        results from a specific search engine.", "module": "promptflow.tools.serpapi",
        "class_name": "SerpAPI", "function": "search", "is_builtin": true, "package":
        "promptflow-tools", "package_version": "0.0.216", "enable_kwargs": false,
        "tool_state": "stable"}, {"name": "Faiss Index Lookup", "type": "python",
        "inputs": {"path": {"type": ["string"], "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}, "top_k": {"type": ["int"], "default": "3",
        "allow_manual_entry": false, "is_multi_select": false, "input_type": "default"},
        "vector": {"type": ["list"], "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}}, "description": "Search vector based query
        from the FAISS index file.", "module": "promptflow_vectordb.tool.faiss_index_lookup",
        "class_name": "FaissIndexLookup", "function": "search", "is_builtin": true,
        "package": "promptflow-vectordb", "package_version": "0.0.1", "enable_kwargs":
        false, "tool_state": "stable"}, {"name": "Vector DB Lookup", "type": "python",
        "inputs": {"class_name": {"type": ["string"], "enabled_by": "connection",
        "enabled_by_type": ["WeaviateConnection"], "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}, "collection_name": {"type": ["string"], "enabled_by":
        "connection", "enabled_by_type": ["QdrantConnection"], "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "connection": {"type":
        ["CognitiveSearchConnection", "QdrantConnection", "WeaviateConnection"], "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "index_name": {"type":
        ["string"], "enabled_by": "connection", "enabled_by_type": ["CognitiveSearchConnection"],
        "allow_manual_entry": false, "is_multi_select": false, "input_type": "default"},
        "search_filters": {"type": ["object"], "enabled_by": "connection", "enabled_by_type":
        ["CognitiveSearchConnection", "QdrantConnection"], "allow_manual_entry": false,
        "is_multi_select": false, "input_type": "default"}, "search_params": {"type":
        ["object"], "enabled_by": "connection", "enabled_by_type": ["CognitiveSearchConnection",
        "QdrantConnection"], "allow_manual_entry": false, "is_multi_select": false,
        "input_type": "default"}, "text_field": {"type": ["string"], "enabled_by":
        "connection", "enabled_by_type": ["CognitiveSearchConnection", "QdrantConnection",
        "WeaviateConnection"], "allow_manual_entry": false, "is_multi_select": false,
        "input_type": "default"}, "top_k": {"type": ["int"], "default": "3", "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "vector": {"type":
        ["list"], "allow_manual_entry": false, "is_multi_select": false, "input_type":
        "default"}, "vector_field": {"type": ["string"], "enabled_by": "connection",
        "enabled_by_type": ["CognitiveSearchConnection"], "allow_manual_entry": false,
        "is_multi_select": false, "input_type": "default"}}, "description": "Search
        vector based query from existing Vector Database.", "module": "promptflow_vectordb.tool.vector_db_lookup",
        "class_name": "VectorDBLookup", "function": "search", "is_builtin": true,
        "package": "promptflow-vectordb", "package_version": "0.0.1", "enable_kwargs":
        false, "tool_state": "stable"}, {"name": "Vector Index Lookup", "type": "python",
        "inputs": {"path": {"type": ["string"], "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}, "query": {"type": ["object"], "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "top_k": {"type":
        ["int"], "default": "3", "allow_manual_entry": false, "is_multi_select": false,
        "input_type": "default"}}, "description": "Search text or vector based query
        from AzureML Vector Index.", "module": "promptflow_vectordb.tool.vector_index_lookup",
        "class_name": "VectorIndexLookup", "function": "search", "is_builtin": true,
        "package": "promptflow-vectordb", "package_version": "0.0.1", "enable_kwargs":
        false, "tool_state": "stable"}, {"name": "mod_three.py", "type": "python",
        "inputs": {"number": {"type": ["int"], "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}}, "source": "mod_three.py", "function": "mod_three",
        "is_builtin": false, "enable_kwargs": false, "tool_state": "stable"}], "inputs":
        {"number": {"type": "int", "is_chat_input": false}}, "outputs": {"output":
        {"type": "int", "reference": "${mod_three.output.value}", "evaluation_only":
        false, "is_chat_output": false}}}, "flowRunResourceId": "azureml://locations/eastus/workspaces/00000/flows/run2/flowRuns/run2",
        "flowRunId": "run2", "flowRunDisplayName": "run2", "batchDataInput": {}, "flowRunType":
        "FlowRun", "flowType": "Default", "runtimeName": "test-runtime-ci", "inputsMapping":
        {"number": "${run.outputs.output}"}, "outputDatastoreName": "workspaceblobstore",
        "childRunBasePath": "promptflow/PromptFlowArtifacts/run2/flow_artifacts",
        "flowDagFileRelativePath": "flow.dag.yaml", "flowSnapshotId": "f29cc6c7-8cd6-4330-9194-d8818a21f8d8",
        "studioPortalEndpoint": "https://ml.azure.com/runs/run2?wsid=/subscriptions/00000000-0000-0000-0000-000000000000/resourcegroups/00000/providers/Microsoft.MachineLearningServices/workspaces/00000"}'
    headers:
      connection:
      - keep-alive
      content-length:
      - '12766'
      content-type:
      - application/json; charset=utf-8
      strict-transport-security:
      - max-age=15724800; includeSubDomains; preload
      transfer-encoding:
      - chunked
      vary:
      - Accept-Encoding
      x-content-type-options:
      - nosniff
      x-request-time:
      - '0.251'
    status:
      code: 200
      message: OK
- request:
    body: null
    headers:
      Accept:
      - application/json
      Accept-Encoding:
      - gzip, deflate
      Connection:
      - keep-alive
      User-Agent:
      - promptflow-sdk/0.0.1 azsdk-python-azuremachinelearningdesignerserviceclient/unknown
        Python/3.10.13 (Windows-10-10.0.22631-SP0)
    method: GET
    uri: https://eastus.api.azureml.ms/flow/api/subscriptions/00000000-0000-0000-0000-000000000000/resourceGroups/00000/providers/Microsoft.MachineLearningServices/workspaces/00000/BulkRuns/run2
  response:
    body:
      string: '{"flowGraph": {"nodes": [{"name": "mod_three", "type": "python", "source":
        {"type": "code", "path": "mod_three.py"}, "inputs": {"number": "${inputs.number}"},
        "tool": "mod_three.py", "reduce": false}], "tools": [{"name": "Content Safety
        (Text Analyze)", "type": "python", "inputs": {"connection": {"type": ["AzureContentSafetyConnection"],
        "allow_manual_entry": false, "is_multi_select": false, "input_type": "default"},
        "hate_category": {"type": ["string"], "default": "medium_sensitivity", "enum":
        ["disable", "low_sensitivity", "medium_sensitivity", "high_sensitivity"],
        "allow_manual_entry": false, "is_multi_select": false, "input_type": "default"},
        "self_harm_category": {"type": ["string"], "default": "medium_sensitivity",
        "enum": ["disable", "low_sensitivity", "medium_sensitivity", "high_sensitivity"],
        "allow_manual_entry": false, "is_multi_select": false, "input_type": "default"},
        "sexual_category": {"type": ["string"], "default": "medium_sensitivity", "enum":
        ["disable", "low_sensitivity", "medium_sensitivity", "high_sensitivity"],
        "allow_manual_entry": false, "is_multi_select": false, "input_type": "default"},
        "text": {"type": ["string"], "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}, "violence_category": {"type": ["string"],
        "default": "medium_sensitivity", "enum": ["disable", "low_sensitivity", "medium_sensitivity",
        "high_sensitivity"], "allow_manual_entry": false, "is_multi_select": false,
        "input_type": "default"}}, "description": "Use Azure Content Safety to detect
        harmful content.", "module": "promptflow.tools.azure_content_safety", "function":
        "analyze_text", "is_builtin": true, "package": "promptflow-tools", "package_version":
        "0.0.216", "enable_kwargs": false, "deprecated_tools": ["content_safety_text.tools.content_safety_text_tool.analyze_text"],
        "tool_state": "stable"}, {"name": "Embedding", "type": "python", "inputs":
        {"connection": {"type": ["AzureOpenAIConnection", "OpenAIConnection"], "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "deployment_name":
        {"type": ["string"], "enabled_by": "connection", "enabled_by_type": ["AzureOpenAIConnection"],
        "model_list": ["text-embedding-ada-002", "text-search-ada-doc-001", "text-search-ada-query-001"],
        "capabilities": {"completion": false, "chat_completion": false, "embeddings":
        true}, "allow_manual_entry": false, "is_multi_select": false, "input_type":
        "default"}, "input": {"type": ["string"], "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}, "model": {"type": ["string"], "enum": ["text-embedding-ada-002",
        "text-search-ada-doc-001", "text-search-ada-query-001"], "enabled_by": "connection",
        "enabled_by_type": ["OpenAIConnection"], "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}}, "description": "Use Open AI''s embedding
        model to create an embedding vector representing the input text.", "module":
        "promptflow.tools.embedding", "function": "embedding", "is_builtin": true,
        "package": "promptflow-tools", "package_version": "0.0.216", "enable_kwargs":
        false, "tool_state": "stable"}, {"name": "Open Source LLM", "type": "custom_llm",
        "inputs": {"api": {"type": ["string"], "enum": ["chat", "completion"], "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "connection": {"type":
        ["CustomConnection"], "allow_manual_entry": false, "is_multi_select": false,
        "input_type": "default"}, "deployment_name": {"type": ["string"], "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "endpoint_name":
        {"type": ["string"], "default": "-- please enter an endpoint name --", "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "max_new_tokens":
        {"type": ["int"], "default": 500, "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}, "model_kwargs": {"type": ["object"], "default":
        "{}", "allow_manual_entry": false, "is_multi_select": false, "input_type":
        "default", "advanced": true}, "temperature": {"type": ["double"], "default":
        1.0, "allow_manual_entry": false, "is_multi_select": false, "input_type":
        "default"}, "top_p": {"type": ["double"], "default": 1.0, "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default", "advanced": true}},
        "description": "Use an Open Source model from the Azure Model catalog, deployed
        to an AzureML Online Endpoint for LLM Chat or Completion API calls.", "module":
        "promptflow.tools.open_source_llm", "class_name": "OpenSourceLLM", "function":
        "call", "icon": "data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAACgElEQVR4nGWSz2vcVRTFP/e9NzOZ1KDGohASslLEH6VLV0ak4l/QpeDCrfQPcNGliODKnVm4EBdBsIjQIlhciKW0ycKFVCSNbYnjdDLtmPnmO/nO9917XcxMkjYX3uLx7nnn3HOuMK2Nix4fP78ZdrYXVkLVWjf3l3B1B+HpcjzGFtmqa6cePz7/x0dnn1n5qhj3iBJPYREIURAJuCtpY8PjReDbrf9WG7H1fuefwQU9qKztTcMJT+PNnEFvjGVDBDlSsH6p/9MLzy6+NxwVqI8RAg4IPmWedMckdLYP6O6UpIaQfvyyXG012+e79/ZfHukoS1ISMT2hGTB1RkUmNgQ5QZ0w+a2VWDq73MbdEWmfnnv6UWe7oNzPaLapl5CwuLTXK9WUGBuCjqekzhP+z52ZXOrKMD3OJg0Hh778aiOuvpnYvp05d6GJO4iAO4QAe/eV36/X5LFRV4Zmn+AdkqlL8Vjp3oVioOz+WTPzzYEgsN+fgPLYyJVheSbPPVl2ikeGZRjtG52/8rHuaV9VOlpP2OtKyVndcRVCSqOhsvxa4vW359i6OuKdD+aP8Q4SYPdOzS/flGjt1JUSaMqZ5nwa1Y8qWb/Ud/eZZkHisYezEM0m+fcelDr8F1SqW2LNK6r1jXQwyLzy1hxvrLXZulry7ocL+FS6G4QIu3fG/Px1gdYeW7LIgXU2P/115TOA5G7e3Rmj2aS/m7l5pThiZzrCcE/d1XHzbln373nw7y6veeoUm5KCNKT/IPPwbiY1hYd/l5MIT65BMFt87sU4v9D7/JMflr44uV6hGh1+L4RCkg6z5iK2tAhNLeLsNGwYA4fDYnC/drvuuFxe86NV/x+Ut27g0FvykgAAAABJRU5ErkJggg==",
        "is_builtin": true, "package": "promptflow-tools", "package_version": "0.0.216",
        "enable_kwargs": false, "tool_state": "stable"}, {"name": "OpenAI GPT-4V",
        "type": "custom_llm", "inputs": {"connection": {"type": ["OpenAIConnection"],
        "allow_manual_entry": false, "is_multi_select": false, "input_type": "default"},
        "frequency_penalty": {"type": ["double"], "default": 0, "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "max_tokens": {"type":
        ["int"], "default": "", "allow_manual_entry": false, "is_multi_select": false,
        "input_type": "default"}, "model": {"type": ["string"], "enum": ["gpt-4-vision-preview"],
        "allow_manual_entry": true, "is_multi_select": false, "input_type": "default"},
        "presence_penalty": {"type": ["double"], "default": 0, "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "stop": {"type":
        ["list"], "default": "", "allow_manual_entry": false, "is_multi_select": false,
        "input_type": "default"}, "temperature": {"type": ["double"], "default": 1,
        "allow_manual_entry": false, "is_multi_select": false, "input_type": "default"},
        "top_p": {"type": ["double"], "default": 1, "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}}, "description": "Use OpenAI GPT-4V to leverage
        vision ability.", "module": "promptflow.tools.openai_gpt4v", "class_name":
        "OpenAI", "function": "chat", "is_builtin": true, "package": "promptflow-tools",
        "package_version": "0.0.216", "default_prompt": "# system:\nAs an AI assistant,
        your task involves interpreting images and responding to questions about the
        image.\nRemember to provide accurate answers based on the information present
        in the image.\n\n# user:\nCan you tell me what the image depicts?\n![image]({{image_input}})\n",
        "enable_kwargs": false, "tool_state": "stable"}, {"name": "Serp API", "type":
        "python", "inputs": {"connection": {"type": ["SerpConnection"], "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "engine": {"type":
        ["string"], "default": "google", "enum": ["google", "bing"], "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "location": {"type":
        ["string"], "default": "", "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}, "num": {"type": ["int"], "default": "10",
        "allow_manual_entry": false, "is_multi_select": false, "input_type": "default"},
        "query": {"type": ["string"], "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}, "safe": {"type": ["string"], "default": "off",
        "enum": ["active", "off"], "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}}, "description": "Use Serp API to obtain search
        results from a specific search engine.", "module": "promptflow.tools.serpapi",
        "class_name": "SerpAPI", "function": "search", "is_builtin": true, "package":
        "promptflow-tools", "package_version": "0.0.216", "enable_kwargs": false,
        "tool_state": "stable"}, {"name": "Faiss Index Lookup", "type": "python",
        "inputs": {"path": {"type": ["string"], "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}, "top_k": {"type": ["int"], "default": "3",
        "allow_manual_entry": false, "is_multi_select": false, "input_type": "default"},
        "vector": {"type": ["list"], "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}}, "description": "Search vector based query
        from the FAISS index file.", "module": "promptflow_vectordb.tool.faiss_index_lookup",
        "class_name": "FaissIndexLookup", "function": "search", "is_builtin": true,
        "package": "promptflow-vectordb", "package_version": "0.0.1", "enable_kwargs":
        false, "tool_state": "stable"}, {"name": "Vector DB Lookup", "type": "python",
        "inputs": {"class_name": {"type": ["string"], "enabled_by": "connection",
        "enabled_by_type": ["WeaviateConnection"], "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}, "collection_name": {"type": ["string"], "enabled_by":
        "connection", "enabled_by_type": ["QdrantConnection"], "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "connection": {"type":
        ["CognitiveSearchConnection", "QdrantConnection", "WeaviateConnection"], "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "index_name": {"type":
        ["string"], "enabled_by": "connection", "enabled_by_type": ["CognitiveSearchConnection"],
        "allow_manual_entry": false, "is_multi_select": false, "input_type": "default"},
        "search_filters": {"type": ["object"], "enabled_by": "connection", "enabled_by_type":
        ["CognitiveSearchConnection", "QdrantConnection"], "allow_manual_entry": false,
        "is_multi_select": false, "input_type": "default"}, "search_params": {"type":
        ["object"], "enabled_by": "connection", "enabled_by_type": ["CognitiveSearchConnection",
        "QdrantConnection"], "allow_manual_entry": false, "is_multi_select": false,
        "input_type": "default"}, "text_field": {"type": ["string"], "enabled_by":
        "connection", "enabled_by_type": ["CognitiveSearchConnection", "QdrantConnection",
        "WeaviateConnection"], "allow_manual_entry": false, "is_multi_select": false,
        "input_type": "default"}, "top_k": {"type": ["int"], "default": "3", "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "vector": {"type":
        ["list"], "allow_manual_entry": false, "is_multi_select": false, "input_type":
        "default"}, "vector_field": {"type": ["string"], "enabled_by": "connection",
        "enabled_by_type": ["CognitiveSearchConnection"], "allow_manual_entry": false,
        "is_multi_select": false, "input_type": "default"}}, "description": "Search
        vector based query from existing Vector Database.", "module": "promptflow_vectordb.tool.vector_db_lookup",
        "class_name": "VectorDBLookup", "function": "search", "is_builtin": true,
        "package": "promptflow-vectordb", "package_version": "0.0.1", "enable_kwargs":
        false, "tool_state": "stable"}, {"name": "Vector Index Lookup", "type": "python",
        "inputs": {"path": {"type": ["string"], "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}, "query": {"type": ["object"], "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "top_k": {"type":
        ["int"], "default": "3", "allow_manual_entry": false, "is_multi_select": false,
        "input_type": "default"}}, "description": "Search text or vector based query
        from AzureML Vector Index.", "module": "promptflow_vectordb.tool.vector_index_lookup",
        "class_name": "VectorIndexLookup", "function": "search", "is_builtin": true,
        "package": "promptflow-vectordb", "package_version": "0.0.1", "enable_kwargs":
        false, "tool_state": "stable"}, {"name": "mod_three.py", "type": "python",
        "inputs": {"number": {"type": ["int"], "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}}, "source": "mod_three.py", "function": "mod_three",
        "is_builtin": false, "enable_kwargs": false, "tool_state": "stable"}], "inputs":
        {"number": {"type": "int", "is_chat_input": false}}, "outputs": {"output":
        {"type": "int", "reference": "${mod_three.output.value}", "evaluation_only":
        false, "is_chat_output": false}}}, "flowRunResourceId": "azureml://locations/eastus/workspaces/00000/flows/run2/flowRuns/run2",
        "flowRunId": "run2", "flowRunDisplayName": "run2", "batchDataInput": {}, "flowRunType":
        "FlowRun", "flowType": "Default", "runtimeName": "test-runtime-ci", "inputsMapping":
        {"number": "${run.outputs.output}"}, "outputDatastoreName": "workspaceblobstore",
        "childRunBasePath": "promptflow/PromptFlowArtifacts/run2/flow_artifacts",
        "flowDagFileRelativePath": "flow.dag.yaml", "flowSnapshotId": "f29cc6c7-8cd6-4330-9194-d8818a21f8d8",
        "studioPortalEndpoint": "https://ml.azure.com/runs/run2?wsid=/subscriptions/00000000-0000-0000-0000-000000000000/resourcegroups/00000/providers/Microsoft.MachineLearningServices/workspaces/00000"}'
    headers:
      connection:
      - keep-alive
      content-length:
      - '12766'
      content-type:
      - application/json; charset=utf-8
      strict-transport-security:
      - max-age=15724800; includeSubDomains; preload
      transfer-encoding:
      - chunked
      vary:
      - Accept-Encoding
      x-content-type-options:
      - nosniff
      x-request-time:
      - '0.298'
    status:
      code: 200
      message: OK
- request:
    body: null
    headers:
      Accept:
      - application/json
      Accept-Encoding:
      - gzip, deflate
      Connection:
      - keep-alive
      User-Agent:
      - promptflow-sdk/0.0.1 azsdk-python-azuremachinelearningdesignerserviceclient/unknown
        Python/3.10.13 (Windows-10-10.0.22631-SP0)
    method: GET
    uri: https://eastus.api.azureml.ms/flow/api/subscriptions/00000000-0000-0000-0000-000000000000/resourceGroups/00000/providers/Microsoft.MachineLearningServices/workspaces/00000/BulkRuns/run2
  response:
    body:
      string: '{"flowGraph": {"nodes": [{"name": "mod_three", "type": "python", "source":
        {"type": "code", "path": "mod_three.py"}, "inputs": {"number": "${inputs.number}"},
        "tool": "mod_three.py", "reduce": false}], "tools": [{"name": "Content Safety
        (Text Analyze)", "type": "python", "inputs": {"connection": {"type": ["AzureContentSafetyConnection"],
        "allow_manual_entry": false, "is_multi_select": false, "input_type": "default"},
        "hate_category": {"type": ["string"], "default": "medium_sensitivity", "enum":
        ["disable", "low_sensitivity", "medium_sensitivity", "high_sensitivity"],
        "allow_manual_entry": false, "is_multi_select": false, "input_type": "default"},
        "self_harm_category": {"type": ["string"], "default": "medium_sensitivity",
        "enum": ["disable", "low_sensitivity", "medium_sensitivity", "high_sensitivity"],
        "allow_manual_entry": false, "is_multi_select": false, "input_type": "default"},
        "sexual_category": {"type": ["string"], "default": "medium_sensitivity", "enum":
        ["disable", "low_sensitivity", "medium_sensitivity", "high_sensitivity"],
        "allow_manual_entry": false, "is_multi_select": false, "input_type": "default"},
        "text": {"type": ["string"], "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}, "violence_category": {"type": ["string"],
        "default": "medium_sensitivity", "enum": ["disable", "low_sensitivity", "medium_sensitivity",
        "high_sensitivity"], "allow_manual_entry": false, "is_multi_select": false,
        "input_type": "default"}}, "description": "Use Azure Content Safety to detect
        harmful content.", "module": "promptflow.tools.azure_content_safety", "function":
        "analyze_text", "is_builtin": true, "package": "promptflow-tools", "package_version":
        "0.0.216", "enable_kwargs": false, "deprecated_tools": ["content_safety_text.tools.content_safety_text_tool.analyze_text"],
        "tool_state": "stable"}, {"name": "Embedding", "type": "python", "inputs":
        {"connection": {"type": ["AzureOpenAIConnection", "OpenAIConnection"], "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "deployment_name":
        {"type": ["string"], "enabled_by": "connection", "enabled_by_type": ["AzureOpenAIConnection"],
        "model_list": ["text-embedding-ada-002", "text-search-ada-doc-001", "text-search-ada-query-001"],
        "capabilities": {"completion": false, "chat_completion": false, "embeddings":
        true}, "allow_manual_entry": false, "is_multi_select": false, "input_type":
        "default"}, "input": {"type": ["string"], "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}, "model": {"type": ["string"], "enum": ["text-embedding-ada-002",
        "text-search-ada-doc-001", "text-search-ada-query-001"], "enabled_by": "connection",
        "enabled_by_type": ["OpenAIConnection"], "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}}, "description": "Use Open AI''s embedding
        model to create an embedding vector representing the input text.", "module":
        "promptflow.tools.embedding", "function": "embedding", "is_builtin": true,
        "package": "promptflow-tools", "package_version": "0.0.216", "enable_kwargs":
        false, "tool_state": "stable"}, {"name": "Open Source LLM", "type": "custom_llm",
        "inputs": {"api": {"type": ["string"], "enum": ["chat", "completion"], "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "connection": {"type":
        ["CustomConnection"], "allow_manual_entry": false, "is_multi_select": false,
        "input_type": "default"}, "deployment_name": {"type": ["string"], "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "endpoint_name":
        {"type": ["string"], "default": "-- please enter an endpoint name --", "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "max_new_tokens":
        {"type": ["int"], "default": 500, "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}, "model_kwargs": {"type": ["object"], "default":
        "{}", "allow_manual_entry": false, "is_multi_select": false, "input_type":
        "default", "advanced": true}, "temperature": {"type": ["double"], "default":
        1.0, "allow_manual_entry": false, "is_multi_select": false, "input_type":
        "default"}, "top_p": {"type": ["double"], "default": 1.0, "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default", "advanced": true}},
        "description": "Use an Open Source model from the Azure Model catalog, deployed
        to an AzureML Online Endpoint for LLM Chat or Completion API calls.", "module":
        "promptflow.tools.open_source_llm", "class_name": "OpenSourceLLM", "function":
        "call", "icon": "data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAACgElEQVR4nGWSz2vcVRTFP/e9NzOZ1KDGohASslLEH6VLV0ak4l/QpeDCrfQPcNGliODKnVm4EBdBsIjQIlhciKW0ycKFVCSNbYnjdDLtmPnmO/nO9917XcxMkjYX3uLx7nnn3HOuMK2Nix4fP78ZdrYXVkLVWjf3l3B1B+HpcjzGFtmqa6cePz7/x0dnn1n5qhj3iBJPYREIURAJuCtpY8PjReDbrf9WG7H1fuefwQU9qKztTcMJT+PNnEFvjGVDBDlSsH6p/9MLzy6+NxwVqI8RAg4IPmWedMckdLYP6O6UpIaQfvyyXG012+e79/ZfHukoS1ISMT2hGTB1RkUmNgQ5QZ0w+a2VWDq73MbdEWmfnnv6UWe7oNzPaLapl5CwuLTXK9WUGBuCjqekzhP+z52ZXOrKMD3OJg0Hh778aiOuvpnYvp05d6GJO4iAO4QAe/eV36/X5LFRV4Zmn+AdkqlL8Vjp3oVioOz+WTPzzYEgsN+fgPLYyJVheSbPPVl2ikeGZRjtG52/8rHuaV9VOlpP2OtKyVndcRVCSqOhsvxa4vW359i6OuKdD+aP8Q4SYPdOzS/flGjt1JUSaMqZ5nwa1Y8qWb/Ud/eZZkHisYezEM0m+fcelDr8F1SqW2LNK6r1jXQwyLzy1hxvrLXZulry7ocL+FS6G4QIu3fG/Px1gdYeW7LIgXU2P/115TOA5G7e3Rmj2aS/m7l5pThiZzrCcE/d1XHzbln373nw7y6veeoUm5KCNKT/IPPwbiY1hYd/l5MIT65BMFt87sU4v9D7/JMflr44uV6hGh1+L4RCkg6z5iK2tAhNLeLsNGwYA4fDYnC/drvuuFxe86NV/x+Ut27g0FvykgAAAABJRU5ErkJggg==",
        "is_builtin": true, "package": "promptflow-tools", "package_version": "0.0.216",
        "enable_kwargs": false, "tool_state": "stable"}, {"name": "OpenAI GPT-4V",
        "type": "custom_llm", "inputs": {"connection": {"type": ["OpenAIConnection"],
        "allow_manual_entry": false, "is_multi_select": false, "input_type": "default"},
        "frequency_penalty": {"type": ["double"], "default": 0, "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "max_tokens": {"type":
        ["int"], "default": "", "allow_manual_entry": false, "is_multi_select": false,
        "input_type": "default"}, "model": {"type": ["string"], "enum": ["gpt-4-vision-preview"],
        "allow_manual_entry": true, "is_multi_select": false, "input_type": "default"},
        "presence_penalty": {"type": ["double"], "default": 0, "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "stop": {"type":
        ["list"], "default": "", "allow_manual_entry": false, "is_multi_select": false,
        "input_type": "default"}, "temperature": {"type": ["double"], "default": 1,
        "allow_manual_entry": false, "is_multi_select": false, "input_type": "default"},
        "top_p": {"type": ["double"], "default": 1, "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}}, "description": "Use OpenAI GPT-4V to leverage
        vision ability.", "module": "promptflow.tools.openai_gpt4v", "class_name":
        "OpenAI", "function": "chat", "is_builtin": true, "package": "promptflow-tools",
        "package_version": "0.0.216", "default_prompt": "# system:\nAs an AI assistant,
        your task involves interpreting images and responding to questions about the
        image.\nRemember to provide accurate answers based on the information present
        in the image.\n\n# user:\nCan you tell me what the image depicts?\n![image]({{image_input}})\n",
        "enable_kwargs": false, "tool_state": "stable"}, {"name": "Serp API", "type":
        "python", "inputs": {"connection": {"type": ["SerpConnection"], "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "engine": {"type":
        ["string"], "default": "google", "enum": ["google", "bing"], "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "location": {"type":
        ["string"], "default": "", "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}, "num": {"type": ["int"], "default": "10",
        "allow_manual_entry": false, "is_multi_select": false, "input_type": "default"},
        "query": {"type": ["string"], "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}, "safe": {"type": ["string"], "default": "off",
        "enum": ["active", "off"], "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}}, "description": "Use Serp API to obtain search
        results from a specific search engine.", "module": "promptflow.tools.serpapi",
        "class_name": "SerpAPI", "function": "search", "is_builtin": true, "package":
        "promptflow-tools", "package_version": "0.0.216", "enable_kwargs": false,
        "tool_state": "stable"}, {"name": "Faiss Index Lookup", "type": "python",
        "inputs": {"path": {"type": ["string"], "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}, "top_k": {"type": ["int"], "default": "3",
        "allow_manual_entry": false, "is_multi_select": false, "input_type": "default"},
        "vector": {"type": ["list"], "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}}, "description": "Search vector based query
        from the FAISS index file.", "module": "promptflow_vectordb.tool.faiss_index_lookup",
        "class_name": "FaissIndexLookup", "function": "search", "is_builtin": true,
        "package": "promptflow-vectordb", "package_version": "0.0.1", "enable_kwargs":
        false, "tool_state": "stable"}, {"name": "Vector DB Lookup", "type": "python",
        "inputs": {"class_name": {"type": ["string"], "enabled_by": "connection",
        "enabled_by_type": ["WeaviateConnection"], "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}, "collection_name": {"type": ["string"], "enabled_by":
        "connection", "enabled_by_type": ["QdrantConnection"], "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "connection": {"type":
        ["CognitiveSearchConnection", "QdrantConnection", "WeaviateConnection"], "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "index_name": {"type":
        ["string"], "enabled_by": "connection", "enabled_by_type": ["CognitiveSearchConnection"],
        "allow_manual_entry": false, "is_multi_select": false, "input_type": "default"},
        "search_filters": {"type": ["object"], "enabled_by": "connection", "enabled_by_type":
        ["CognitiveSearchConnection", "QdrantConnection"], "allow_manual_entry": false,
        "is_multi_select": false, "input_type": "default"}, "search_params": {"type":
        ["object"], "enabled_by": "connection", "enabled_by_type": ["CognitiveSearchConnection",
        "QdrantConnection"], "allow_manual_entry": false, "is_multi_select": false,
        "input_type": "default"}, "text_field": {"type": ["string"], "enabled_by":
        "connection", "enabled_by_type": ["CognitiveSearchConnection", "QdrantConnection",
        "WeaviateConnection"], "allow_manual_entry": false, "is_multi_select": false,
        "input_type": "default"}, "top_k": {"type": ["int"], "default": "3", "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "vector": {"type":
        ["list"], "allow_manual_entry": false, "is_multi_select": false, "input_type":
        "default"}, "vector_field": {"type": ["string"], "enabled_by": "connection",
        "enabled_by_type": ["CognitiveSearchConnection"], "allow_manual_entry": false,
        "is_multi_select": false, "input_type": "default"}}, "description": "Search
        vector based query from existing Vector Database.", "module": "promptflow_vectordb.tool.vector_db_lookup",
        "class_name": "VectorDBLookup", "function": "search", "is_builtin": true,
        "package": "promptflow-vectordb", "package_version": "0.0.1", "enable_kwargs":
        false, "tool_state": "stable"}, {"name": "Vector Index Lookup", "type": "python",
        "inputs": {"path": {"type": ["string"], "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}, "query": {"type": ["object"], "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "top_k": {"type":
        ["int"], "default": "3", "allow_manual_entry": false, "is_multi_select": false,
        "input_type": "default"}}, "description": "Search text or vector based query
        from AzureML Vector Index.", "module": "promptflow_vectordb.tool.vector_index_lookup",
        "class_name": "VectorIndexLookup", "function": "search", "is_builtin": true,
        "package": "promptflow-vectordb", "package_version": "0.0.1", "enable_kwargs":
        false, "tool_state": "stable"}, {"name": "mod_three.py", "type": "python",
        "inputs": {"number": {"type": ["int"], "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}}, "source": "mod_three.py", "function": "mod_three",
        "is_builtin": false, "enable_kwargs": false, "tool_state": "stable"}], "inputs":
        {"number": {"type": "int", "is_chat_input": false}}, "outputs": {"output":
        {"type": "int", "reference": "${mod_three.output.value}", "evaluation_only":
        false, "is_chat_output": false}}}, "flowRunResourceId": "azureml://locations/eastus/workspaces/00000/flows/run2/flowRuns/run2",
        "flowRunId": "run2", "flowRunDisplayName": "run2", "batchDataInput": {}, "flowRunType":
        "FlowRun", "flowType": "Default", "runtimeName": "test-runtime-ci", "inputsMapping":
        {"number": "${run.outputs.output}"}, "outputDatastoreName": "workspaceblobstore",
        "childRunBasePath": "promptflow/PromptFlowArtifacts/run2/flow_artifacts",
        "flowDagFileRelativePath": "flow.dag.yaml", "flowSnapshotId": "f29cc6c7-8cd6-4330-9194-d8818a21f8d8",
        "studioPortalEndpoint": "https://ml.azure.com/runs/run2?wsid=/subscriptions/00000000-0000-0000-0000-000000000000/resourcegroups/00000/providers/Microsoft.MachineLearningServices/workspaces/00000"}'
    headers:
      connection:
      - keep-alive
      content-length:
      - '12766'
      content-type:
      - application/json; charset=utf-8
      strict-transport-security:
      - max-age=15724800; includeSubDomains; preload
      transfer-encoding:
      - chunked
      vary:
      - Accept-Encoding
      x-content-type-options:
      - nosniff
      x-request-time:
      - '0.234'
    status:
      code: 200
      message: OK
- request:
    body: null
    headers:
      Accept:
      - application/json
      Accept-Encoding:
      - gzip, deflate
      Connection:
      - keep-alive
      User-Agent:
      - promptflow-sdk/0.0.1 azsdk-python-azuremachinelearningdesignerserviceclient/unknown
        Python/3.10.13 (Windows-10-10.0.22631-SP0)
    method: GET
    uri: https://eastus.api.azureml.ms/flow/api/subscriptions/00000000-0000-0000-0000-000000000000/resourceGroups/00000/providers/Microsoft.MachineLearningServices/workspaces/00000/BulkRuns/run2
  response:
    body:
      string: '{"flowGraph": {"nodes": [{"name": "mod_three", "type": "python", "source":
        {"type": "code", "path": "mod_three.py"}, "inputs": {"number": "${inputs.number}"},
        "tool": "mod_three.py", "reduce": false}], "tools": [{"name": "Content Safety
        (Text Analyze)", "type": "python", "inputs": {"connection": {"type": ["AzureContentSafetyConnection"],
        "allow_manual_entry": false, "is_multi_select": false, "input_type": "default"},
        "hate_category": {"type": ["string"], "default": "medium_sensitivity", "enum":
        ["disable", "low_sensitivity", "medium_sensitivity", "high_sensitivity"],
        "allow_manual_entry": false, "is_multi_select": false, "input_type": "default"},
        "self_harm_category": {"type": ["string"], "default": "medium_sensitivity",
        "enum": ["disable", "low_sensitivity", "medium_sensitivity", "high_sensitivity"],
        "allow_manual_entry": false, "is_multi_select": false, "input_type": "default"},
        "sexual_category": {"type": ["string"], "default": "medium_sensitivity", "enum":
        ["disable", "low_sensitivity", "medium_sensitivity", "high_sensitivity"],
        "allow_manual_entry": false, "is_multi_select": false, "input_type": "default"},
        "text": {"type": ["string"], "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}, "violence_category": {"type": ["string"],
        "default": "medium_sensitivity", "enum": ["disable", "low_sensitivity", "medium_sensitivity",
        "high_sensitivity"], "allow_manual_entry": false, "is_multi_select": false,
        "input_type": "default"}}, "description": "Use Azure Content Safety to detect
        harmful content.", "module": "promptflow.tools.azure_content_safety", "function":
        "analyze_text", "is_builtin": true, "package": "promptflow-tools", "package_version":
        "0.0.216", "enable_kwargs": false, "deprecated_tools": ["content_safety_text.tools.content_safety_text_tool.analyze_text"],
        "tool_state": "stable"}, {"name": "Embedding", "type": "python", "inputs":
        {"connection": {"type": ["AzureOpenAIConnection", "OpenAIConnection"], "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "deployment_name":
        {"type": ["string"], "enabled_by": "connection", "enabled_by_type": ["AzureOpenAIConnection"],
        "model_list": ["text-embedding-ada-002", "text-search-ada-doc-001", "text-search-ada-query-001"],
        "capabilities": {"completion": false, "chat_completion": false, "embeddings":
        true}, "allow_manual_entry": false, "is_multi_select": false, "input_type":
        "default"}, "input": {"type": ["string"], "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}, "model": {"type": ["string"], "enum": ["text-embedding-ada-002",
        "text-search-ada-doc-001", "text-search-ada-query-001"], "enabled_by": "connection",
        "enabled_by_type": ["OpenAIConnection"], "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}}, "description": "Use Open AI''s embedding
        model to create an embedding vector representing the input text.", "module":
        "promptflow.tools.embedding", "function": "embedding", "is_builtin": true,
        "package": "promptflow-tools", "package_version": "0.0.216", "enable_kwargs":
        false, "tool_state": "stable"}, {"name": "Open Source LLM", "type": "custom_llm",
        "inputs": {"api": {"type": ["string"], "enum": ["chat", "completion"], "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "connection": {"type":
        ["CustomConnection"], "allow_manual_entry": false, "is_multi_select": false,
        "input_type": "default"}, "deployment_name": {"type": ["string"], "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "endpoint_name":
        {"type": ["string"], "default": "-- please enter an endpoint name --", "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "max_new_tokens":
        {"type": ["int"], "default": 500, "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}, "model_kwargs": {"type": ["object"], "default":
        "{}", "allow_manual_entry": false, "is_multi_select": false, "input_type":
        "default", "advanced": true}, "temperature": {"type": ["double"], "default":
        1.0, "allow_manual_entry": false, "is_multi_select": false, "input_type":
        "default"}, "top_p": {"type": ["double"], "default": 1.0, "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default", "advanced": true}},
        "description": "Use an Open Source model from the Azure Model catalog, deployed
        to an AzureML Online Endpoint for LLM Chat or Completion API calls.", "module":
        "promptflow.tools.open_source_llm", "class_name": "OpenSourceLLM", "function":
        "call", "icon": "data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAACgElEQVR4nGWSz2vcVRTFP/e9NzOZ1KDGohASslLEH6VLV0ak4l/QpeDCrfQPcNGliODKnVm4EBdBsIjQIlhciKW0ycKFVCSNbYnjdDLtmPnmO/nO9917XcxMkjYX3uLx7nnn3HOuMK2Nix4fP78ZdrYXVkLVWjf3l3B1B+HpcjzGFtmqa6cePz7/x0dnn1n5qhj3iBJPYREIURAJuCtpY8PjReDbrf9WG7H1fuefwQU9qKztTcMJT+PNnEFvjGVDBDlSsH6p/9MLzy6+NxwVqI8RAg4IPmWedMckdLYP6O6UpIaQfvyyXG012+e79/ZfHukoS1ISMT2hGTB1RkUmNgQ5QZ0w+a2VWDq73MbdEWmfnnv6UWe7oNzPaLapl5CwuLTXK9WUGBuCjqekzhP+z52ZXOrKMD3OJg0Hh778aiOuvpnYvp05d6GJO4iAO4QAe/eV36/X5LFRV4Zmn+AdkqlL8Vjp3oVioOz+WTPzzYEgsN+fgPLYyJVheSbPPVl2ikeGZRjtG52/8rHuaV9VOlpP2OtKyVndcRVCSqOhsvxa4vW359i6OuKdD+aP8Q4SYPdOzS/flGjt1JUSaMqZ5nwa1Y8qWb/Ud/eZZkHisYezEM0m+fcelDr8F1SqW2LNK6r1jXQwyLzy1hxvrLXZulry7ocL+FS6G4QIu3fG/Px1gdYeW7LIgXU2P/115TOA5G7e3Rmj2aS/m7l5pThiZzrCcE/d1XHzbln373nw7y6veeoUm5KCNKT/IPPwbiY1hYd/l5MIT65BMFt87sU4v9D7/JMflr44uV6hGh1+L4RCkg6z5iK2tAhNLeLsNGwYA4fDYnC/drvuuFxe86NV/x+Ut27g0FvykgAAAABJRU5ErkJggg==",
        "is_builtin": true, "package": "promptflow-tools", "package_version": "0.0.216",
        "enable_kwargs": false, "tool_state": "stable"}, {"name": "OpenAI GPT-4V",
        "type": "custom_llm", "inputs": {"connection": {"type": ["OpenAIConnection"],
        "allow_manual_entry": false, "is_multi_select": false, "input_type": "default"},
        "frequency_penalty": {"type": ["double"], "default": 0, "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "max_tokens": {"type":
        ["int"], "default": "", "allow_manual_entry": false, "is_multi_select": false,
        "input_type": "default"}, "model": {"type": ["string"], "enum": ["gpt-4-vision-preview"],
        "allow_manual_entry": true, "is_multi_select": false, "input_type": "default"},
        "presence_penalty": {"type": ["double"], "default": 0, "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "stop": {"type":
        ["list"], "default": "", "allow_manual_entry": false, "is_multi_select": false,
        "input_type": "default"}, "temperature": {"type": ["double"], "default": 1,
        "allow_manual_entry": false, "is_multi_select": false, "input_type": "default"},
        "top_p": {"type": ["double"], "default": 1, "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}}, "description": "Use OpenAI GPT-4V to leverage
        vision ability.", "module": "promptflow.tools.openai_gpt4v", "class_name":
        "OpenAI", "function": "chat", "is_builtin": true, "package": "promptflow-tools",
        "package_version": "0.0.216", "default_prompt": "# system:\nAs an AI assistant,
        your task involves interpreting images and responding to questions about the
        image.\nRemember to provide accurate answers based on the information present
        in the image.\n\n# user:\nCan you tell me what the image depicts?\n![image]({{image_input}})\n",
        "enable_kwargs": false, "tool_state": "stable"}, {"name": "Serp API", "type":
        "python", "inputs": {"connection": {"type": ["SerpConnection"], "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "engine": {"type":
        ["string"], "default": "google", "enum": ["google", "bing"], "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "location": {"type":
        ["string"], "default": "", "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}, "num": {"type": ["int"], "default": "10",
        "allow_manual_entry": false, "is_multi_select": false, "input_type": "default"},
        "query": {"type": ["string"], "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}, "safe": {"type": ["string"], "default": "off",
        "enum": ["active", "off"], "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}}, "description": "Use Serp API to obtain search
        results from a specific search engine.", "module": "promptflow.tools.serpapi",
        "class_name": "SerpAPI", "function": "search", "is_builtin": true, "package":
        "promptflow-tools", "package_version": "0.0.216", "enable_kwargs": false,
        "tool_state": "stable"}, {"name": "Faiss Index Lookup", "type": "python",
        "inputs": {"path": {"type": ["string"], "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}, "top_k": {"type": ["int"], "default": "3",
        "allow_manual_entry": false, "is_multi_select": false, "input_type": "default"},
        "vector": {"type": ["list"], "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}}, "description": "Search vector based query
        from the FAISS index file.", "module": "promptflow_vectordb.tool.faiss_index_lookup",
        "class_name": "FaissIndexLookup", "function": "search", "is_builtin": true,
        "package": "promptflow-vectordb", "package_version": "0.0.1", "enable_kwargs":
        false, "tool_state": "stable"}, {"name": "Vector DB Lookup", "type": "python",
        "inputs": {"class_name": {"type": ["string"], "enabled_by": "connection",
        "enabled_by_type": ["WeaviateConnection"], "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}, "collection_name": {"type": ["string"], "enabled_by":
        "connection", "enabled_by_type": ["QdrantConnection"], "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "connection": {"type":
        ["CognitiveSearchConnection", "QdrantConnection", "WeaviateConnection"], "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "index_name": {"type":
        ["string"], "enabled_by": "connection", "enabled_by_type": ["CognitiveSearchConnection"],
        "allow_manual_entry": false, "is_multi_select": false, "input_type": "default"},
        "search_filters": {"type": ["object"], "enabled_by": "connection", "enabled_by_type":
        ["CognitiveSearchConnection", "QdrantConnection"], "allow_manual_entry": false,
        "is_multi_select": false, "input_type": "default"}, "search_params": {"type":
        ["object"], "enabled_by": "connection", "enabled_by_type": ["CognitiveSearchConnection",
        "QdrantConnection"], "allow_manual_entry": false, "is_multi_select": false,
        "input_type": "default"}, "text_field": {"type": ["string"], "enabled_by":
        "connection", "enabled_by_type": ["CognitiveSearchConnection", "QdrantConnection",
        "WeaviateConnection"], "allow_manual_entry": false, "is_multi_select": false,
        "input_type": "default"}, "top_k": {"type": ["int"], "default": "3", "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "vector": {"type":
        ["list"], "allow_manual_entry": false, "is_multi_select": false, "input_type":
        "default"}, "vector_field": {"type": ["string"], "enabled_by": "connection",
        "enabled_by_type": ["CognitiveSearchConnection"], "allow_manual_entry": false,
        "is_multi_select": false, "input_type": "default"}}, "description": "Search
        vector based query from existing Vector Database.", "module": "promptflow_vectordb.tool.vector_db_lookup",
        "class_name": "VectorDBLookup", "function": "search", "is_builtin": true,
        "package": "promptflow-vectordb", "package_version": "0.0.1", "enable_kwargs":
        false, "tool_state": "stable"}, {"name": "Vector Index Lookup", "type": "python",
        "inputs": {"path": {"type": ["string"], "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}, "query": {"type": ["object"], "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "top_k": {"type":
        ["int"], "default": "3", "allow_manual_entry": false, "is_multi_select": false,
        "input_type": "default"}}, "description": "Search text or vector based query
        from AzureML Vector Index.", "module": "promptflow_vectordb.tool.vector_index_lookup",
        "class_name": "VectorIndexLookup", "function": "search", "is_builtin": true,
        "package": "promptflow-vectordb", "package_version": "0.0.1", "enable_kwargs":
        false, "tool_state": "stable"}, {"name": "mod_three.py", "type": "python",
        "inputs": {"number": {"type": ["int"], "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}}, "source": "mod_three.py", "function": "mod_three",
        "is_builtin": false, "enable_kwargs": false, "tool_state": "stable"}], "inputs":
        {"number": {"type": "int", "is_chat_input": false}}, "outputs": {"output":
        {"type": "int", "reference": "${mod_three.output.value}", "evaluation_only":
        false, "is_chat_output": false}}}, "flowRunResourceId": "azureml://locations/eastus/workspaces/00000/flows/run2/flowRuns/run2",
        "flowRunId": "run2", "flowRunDisplayName": "run2", "batchDataInput": {}, "flowRunType":
        "FlowRun", "flowType": "Default", "runtimeName": "test-runtime-ci", "inputsMapping":
        {"number": "${run.outputs.output}"}, "outputDatastoreName": "workspaceblobstore",
        "childRunBasePath": "promptflow/PromptFlowArtifacts/run2/flow_artifacts",
        "flowDagFileRelativePath": "flow.dag.yaml", "flowSnapshotId": "f29cc6c7-8cd6-4330-9194-d8818a21f8d8",
        "studioPortalEndpoint": "https://ml.azure.com/runs/run2?wsid=/subscriptions/00000000-0000-0000-0000-000000000000/resourcegroups/00000/providers/Microsoft.MachineLearningServices/workspaces/00000"}'
    headers:
      connection:
      - keep-alive
      content-length:
      - '12766'
      content-type:
      - application/json; charset=utf-8
      strict-transport-security:
      - max-age=15724800; includeSubDomains; preload
      transfer-encoding:
      - chunked
      vary:
      - Accept-Encoding
      x-content-type-options:
      - nosniff
      x-request-time:
      - '0.413'
    status:
      code: 200
      message: OK
- request:
    body: null
    headers:
      Accept:
      - application/json
      Accept-Encoding:
      - gzip, deflate
      Connection:
      - keep-alive
      User-Agent:
      - promptflow-sdk/0.0.1 azsdk-python-azuremachinelearningdesignerserviceclient/unknown
        Python/3.10.13 (Windows-10-10.0.22631-SP0)
    method: GET
    uri: https://eastus.api.azureml.ms/flow/api/subscriptions/00000000-0000-0000-0000-000000000000/resourceGroups/00000/providers/Microsoft.MachineLearningServices/workspaces/00000/BulkRuns/run2
  response:
    body:
      string: '{"flowGraph": {"nodes": [{"name": "mod_three", "type": "python", "source":
        {"type": "code", "path": "mod_three.py"}, "inputs": {"number": "${inputs.number}"},
        "tool": "mod_three.py", "reduce": false}], "tools": [{"name": "Content Safety
        (Text Analyze)", "type": "python", "inputs": {"connection": {"type": ["AzureContentSafetyConnection"],
        "allow_manual_entry": false, "is_multi_select": false, "input_type": "default"},
        "hate_category": {"type": ["string"], "default": "medium_sensitivity", "enum":
        ["disable", "low_sensitivity", "medium_sensitivity", "high_sensitivity"],
        "allow_manual_entry": false, "is_multi_select": false, "input_type": "default"},
        "self_harm_category": {"type": ["string"], "default": "medium_sensitivity",
        "enum": ["disable", "low_sensitivity", "medium_sensitivity", "high_sensitivity"],
        "allow_manual_entry": false, "is_multi_select": false, "input_type": "default"},
        "sexual_category": {"type": ["string"], "default": "medium_sensitivity", "enum":
        ["disable", "low_sensitivity", "medium_sensitivity", "high_sensitivity"],
        "allow_manual_entry": false, "is_multi_select": false, "input_type": "default"},
        "text": {"type": ["string"], "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}, "violence_category": {"type": ["string"],
        "default": "medium_sensitivity", "enum": ["disable", "low_sensitivity", "medium_sensitivity",
        "high_sensitivity"], "allow_manual_entry": false, "is_multi_select": false,
        "input_type": "default"}}, "description": "Use Azure Content Safety to detect
        harmful content.", "module": "promptflow.tools.azure_content_safety", "function":
        "analyze_text", "is_builtin": true, "package": "promptflow-tools", "package_version":
        "0.0.216", "enable_kwargs": false, "deprecated_tools": ["content_safety_text.tools.content_safety_text_tool.analyze_text"],
        "tool_state": "stable"}, {"name": "Embedding", "type": "python", "inputs":
        {"connection": {"type": ["AzureOpenAIConnection", "OpenAIConnection"], "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "deployment_name":
        {"type": ["string"], "enabled_by": "connection", "enabled_by_type": ["AzureOpenAIConnection"],
        "model_list": ["text-embedding-ada-002", "text-search-ada-doc-001", "text-search-ada-query-001"],
        "capabilities": {"completion": false, "chat_completion": false, "embeddings":
        true}, "allow_manual_entry": false, "is_multi_select": false, "input_type":
        "default"}, "input": {"type": ["string"], "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}, "model": {"type": ["string"], "enum": ["text-embedding-ada-002",
        "text-search-ada-doc-001", "text-search-ada-query-001"], "enabled_by": "connection",
        "enabled_by_type": ["OpenAIConnection"], "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}}, "description": "Use Open AI''s embedding
        model to create an embedding vector representing the input text.", "module":
        "promptflow.tools.embedding", "function": "embedding", "is_builtin": true,
        "package": "promptflow-tools", "package_version": "0.0.216", "enable_kwargs":
        false, "tool_state": "stable"}, {"name": "Open Source LLM", "type": "custom_llm",
        "inputs": {"api": {"type": ["string"], "enum": ["chat", "completion"], "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "connection": {"type":
        ["CustomConnection"], "allow_manual_entry": false, "is_multi_select": false,
        "input_type": "default"}, "deployment_name": {"type": ["string"], "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "endpoint_name":
        {"type": ["string"], "default": "-- please enter an endpoint name --", "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "max_new_tokens":
        {"type": ["int"], "default": 500, "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}, "model_kwargs": {"type": ["object"], "default":
        "{}", "allow_manual_entry": false, "is_multi_select": false, "input_type":
        "default", "advanced": true}, "temperature": {"type": ["double"], "default":
        1.0, "allow_manual_entry": false, "is_multi_select": false, "input_type":
        "default"}, "top_p": {"type": ["double"], "default": 1.0, "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default", "advanced": true}},
        "description": "Use an Open Source model from the Azure Model catalog, deployed
        to an AzureML Online Endpoint for LLM Chat or Completion API calls.", "module":
        "promptflow.tools.open_source_llm", "class_name": "OpenSourceLLM", "function":
        "call", "icon": "data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAACgElEQVR4nGWSz2vcVRTFP/e9NzOZ1KDGohASslLEH6VLV0ak4l/QpeDCrfQPcNGliODKnVm4EBdBsIjQIlhciKW0ycKFVCSNbYnjdDLtmPnmO/nO9917XcxMkjYX3uLx7nnn3HOuMK2Nix4fP78ZdrYXVkLVWjf3l3B1B+HpcjzGFtmqa6cePz7/x0dnn1n5qhj3iBJPYREIURAJuCtpY8PjReDbrf9WG7H1fuefwQU9qKztTcMJT+PNnEFvjGVDBDlSsH6p/9MLzy6+NxwVqI8RAg4IPmWedMckdLYP6O6UpIaQfvyyXG012+e79/ZfHukoS1ISMT2hGTB1RkUmNgQ5QZ0w+a2VWDq73MbdEWmfnnv6UWe7oNzPaLapl5CwuLTXK9WUGBuCjqekzhP+z52ZXOrKMD3OJg0Hh778aiOuvpnYvp05d6GJO4iAO4QAe/eV36/X5LFRV4Zmn+AdkqlL8Vjp3oVioOz+WTPzzYEgsN+fgPLYyJVheSbPPVl2ikeGZRjtG52/8rHuaV9VOlpP2OtKyVndcRVCSqOhsvxa4vW359i6OuKdD+aP8Q4SYPdOzS/flGjt1JUSaMqZ5nwa1Y8qWb/Ud/eZZkHisYezEM0m+fcelDr8F1SqW2LNK6r1jXQwyLzy1hxvrLXZulry7ocL+FS6G4QIu3fG/Px1gdYeW7LIgXU2P/115TOA5G7e3Rmj2aS/m7l5pThiZzrCcE/d1XHzbln373nw7y6veeoUm5KCNKT/IPPwbiY1hYd/l5MIT65BMFt87sU4v9D7/JMflr44uV6hGh1+L4RCkg6z5iK2tAhNLeLsNGwYA4fDYnC/drvuuFxe86NV/x+Ut27g0FvykgAAAABJRU5ErkJggg==",
        "is_builtin": true, "package": "promptflow-tools", "package_version": "0.0.216",
        "enable_kwargs": false, "tool_state": "stable"}, {"name": "OpenAI GPT-4V",
        "type": "custom_llm", "inputs": {"connection": {"type": ["OpenAIConnection"],
        "allow_manual_entry": false, "is_multi_select": false, "input_type": "default"},
        "frequency_penalty": {"type": ["double"], "default": 0, "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "max_tokens": {"type":
        ["int"], "default": "", "allow_manual_entry": false, "is_multi_select": false,
        "input_type": "default"}, "model": {"type": ["string"], "enum": ["gpt-4-vision-preview"],
        "allow_manual_entry": true, "is_multi_select": false, "input_type": "default"},
        "presence_penalty": {"type": ["double"], "default": 0, "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "stop": {"type":
        ["list"], "default": "", "allow_manual_entry": false, "is_multi_select": false,
        "input_type": "default"}, "temperature": {"type": ["double"], "default": 1,
        "allow_manual_entry": false, "is_multi_select": false, "input_type": "default"},
        "top_p": {"type": ["double"], "default": 1, "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}}, "description": "Use OpenAI GPT-4V to leverage
        vision ability.", "module": "promptflow.tools.openai_gpt4v", "class_name":
        "OpenAI", "function": "chat", "is_builtin": true, "package": "promptflow-tools",
        "package_version": "0.0.216", "default_prompt": "# system:\nAs an AI assistant,
        your task involves interpreting images and responding to questions about the
        image.\nRemember to provide accurate answers based on the information present
        in the image.\n\n# user:\nCan you tell me what the image depicts?\n![image]({{image_input}})\n",
        "enable_kwargs": false, "tool_state": "stable"}, {"name": "Serp API", "type":
        "python", "inputs": {"connection": {"type": ["SerpConnection"], "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "engine": {"type":
        ["string"], "default": "google", "enum": ["google", "bing"], "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "location": {"type":
        ["string"], "default": "", "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}, "num": {"type": ["int"], "default": "10",
        "allow_manual_entry": false, "is_multi_select": false, "input_type": "default"},
        "query": {"type": ["string"], "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}, "safe": {"type": ["string"], "default": "off",
        "enum": ["active", "off"], "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}}, "description": "Use Serp API to obtain search
        results from a specific search engine.", "module": "promptflow.tools.serpapi",
        "class_name": "SerpAPI", "function": "search", "is_builtin": true, "package":
        "promptflow-tools", "package_version": "0.0.216", "enable_kwargs": false,
        "tool_state": "stable"}, {"name": "Faiss Index Lookup", "type": "python",
        "inputs": {"path": {"type": ["string"], "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}, "top_k": {"type": ["int"], "default": "3",
        "allow_manual_entry": false, "is_multi_select": false, "input_type": "default"},
        "vector": {"type": ["list"], "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}}, "description": "Search vector based query
        from the FAISS index file.", "module": "promptflow_vectordb.tool.faiss_index_lookup",
        "class_name": "FaissIndexLookup", "function": "search", "is_builtin": true,
        "package": "promptflow-vectordb", "package_version": "0.0.1", "enable_kwargs":
        false, "tool_state": "stable"}, {"name": "Vector DB Lookup", "type": "python",
        "inputs": {"class_name": {"type": ["string"], "enabled_by": "connection",
        "enabled_by_type": ["WeaviateConnection"], "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}, "collection_name": {"type": ["string"], "enabled_by":
        "connection", "enabled_by_type": ["QdrantConnection"], "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "connection": {"type":
        ["CognitiveSearchConnection", "QdrantConnection", "WeaviateConnection"], "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "index_name": {"type":
        ["string"], "enabled_by": "connection", "enabled_by_type": ["CognitiveSearchConnection"],
        "allow_manual_entry": false, "is_multi_select": false, "input_type": "default"},
        "search_filters": {"type": ["object"], "enabled_by": "connection", "enabled_by_type":
        ["CognitiveSearchConnection", "QdrantConnection"], "allow_manual_entry": false,
        "is_multi_select": false, "input_type": "default"}, "search_params": {"type":
        ["object"], "enabled_by": "connection", "enabled_by_type": ["CognitiveSearchConnection",
        "QdrantConnection"], "allow_manual_entry": false, "is_multi_select": false,
        "input_type": "default"}, "text_field": {"type": ["string"], "enabled_by":
        "connection", "enabled_by_type": ["CognitiveSearchConnection", "QdrantConnection",
        "WeaviateConnection"], "allow_manual_entry": false, "is_multi_select": false,
        "input_type": "default"}, "top_k": {"type": ["int"], "default": "3", "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "vector": {"type":
        ["list"], "allow_manual_entry": false, "is_multi_select": false, "input_type":
        "default"}, "vector_field": {"type": ["string"], "enabled_by": "connection",
        "enabled_by_type": ["CognitiveSearchConnection"], "allow_manual_entry": false,
        "is_multi_select": false, "input_type": "default"}}, "description": "Search
        vector based query from existing Vector Database.", "module": "promptflow_vectordb.tool.vector_db_lookup",
        "class_name": "VectorDBLookup", "function": "search", "is_builtin": true,
        "package": "promptflow-vectordb", "package_version": "0.0.1", "enable_kwargs":
        false, "tool_state": "stable"}, {"name": "Vector Index Lookup", "type": "python",
        "inputs": {"path": {"type": ["string"], "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}, "query": {"type": ["object"], "allow_manual_entry":
        false, "is_multi_select": false, "input_type": "default"}, "top_k": {"type":
        ["int"], "default": "3", "allow_manual_entry": false, "is_multi_select": false,
        "input_type": "default"}}, "description": "Search text or vector based query
        from AzureML Vector Index.", "module": "promptflow_vectordb.tool.vector_index_lookup",
        "class_name": "VectorIndexLookup", "function": "search", "is_builtin": true,
        "package": "promptflow-vectordb", "package_version": "0.0.1", "enable_kwargs":
        false, "tool_state": "stable"}, {"name": "mod_three.py", "type": "python",
        "inputs": {"number": {"type": ["int"], "allow_manual_entry": false, "is_multi_select":
        false, "input_type": "default"}}, "source": "mod_three.py", "function": "mod_three",
        "is_builtin": false, "enable_kwargs": false, "tool_state": "stable"}], "inputs":
        {"number": {"type": "int", "is_chat_input": false}}, "outputs": {"output":
        {"type": "int", "reference": "${mod_three.output.value}", "evaluation_only":
        false, "is_chat_output": false}}}, "flowRunResourceId": "azureml://locations/eastus/workspaces/00000/flows/run2/flowRuns/run2",
        "flowRunId": "run2", "flowRunDisplayName": "run2", "batchDataInput": {}, "flowRunType":
        "FlowRun", "flowType": "Default", "runtimeName": "test-runtime-ci", "inputsMapping":
        {"number": "${run.outputs.output}"}, "outputDatastoreName": "workspaceblobstore",
        "childRunBasePath": "promptflow/PromptFlowArtifacts/run2/flow_artifacts",
        "flowDagFileRelativePath": "flow.dag.yaml", "flowSnapshotId": "f29cc6c7-8cd6-4330-9194-d8818a21f8d8",
        "studioPortalEndpoint": "https://ml.azure.com/runs/run2?wsid=/subscriptions/00000000-0000-0000-0000-000000000000/resourcegroups/00000/providers/Microsoft.MachineLearningServices/workspaces/00000"}'
    headers:
      connection:
      - keep-alive
      content-length:
      - '12766'
      content-type:
      - application/json; charset=utf-8
      strict-transport-security:
      - max-age=15724800; includeSubDomains; preload
      transfer-encoding:
      - chunked
      vary:
      - Accept-Encoding
      x-content-type-options:
      - nosniff
      x-request-time:
      - '0.337'
    status:
      code: 200
      message: OK
- request:
    body: null
    headers:
      Accept:
      - application/json
      Accept-Encoding:
      - gzip, deflate
      Connection:
      - keep-alive
      User-Agent:
      - promptflow-sdk/0.0.1 azsdk-python-azuremachinelearningdesignerserviceclient/unknown
        Python/3.10.13 (Windows-10-10.0.22631-SP0)
    method: GET
    uri: https://eastus.api.azureml.ms/flow/api/subscriptions/00000000-0000-0000-0000-000000000000/resourceGroups/00000/providers/Microsoft.MachineLearningServices/workspaces/00000/BulkRuns/run2/childRuns?endIndex=24&startIndex=0
  response:
    body:
      string: '[{"run_id": "run2_0", "status": "Completed", "error": null, "inputs":
        {"number": 0, "line_number": 0}, "output": {"output": 0}, "metrics": null,
        "request": null, "parent_run_id": "run2", "root_run_id": "run2", "source_run_id":
        null, "flow_id": "default_flow_id", "start_time": "2023-12-26T10:14:19.391282Z",
        "end_time": "2023-12-26T10:14:19.409283Z", "index": 0, "api_calls": [{"name":
        "mod_three", "type": "Tool", "inputs": {"number": 0}, "output": {"value":
        0}, "start_time": 1703585659.405796, "end_time": 1703585659.406684, "error":
        null, "children": null, "node_name": "mod_three"}], "variant_id": "", "name":
        "", "description": "", "tags": null, "system_metrics": {"duration": 0.018001,
        "prompt_tokens": 0, "completion_tokens": 0, "total_tokens": 0}, "result":
        {"output": 0}, "upload_metrics": false}, {"run_id": "run2_8", "status": "Failed",
        "error": {"message": "Execution failure in ''mod_three'': (Exception) cannot
        mod 3!", "messageFormat": "Execution failure in ''{node_name}'': {error_type_and_message}",
        "messageParameters": {"node_name": "mod_three", "error_type_and_message":
        "(Exception) cannot mod 3!"}, "referenceCode": "Tool/__pf_main__", "code":
        "UserError", "innerError": {"code": "ToolExecutionError", "innerError": null},
        "additionalInfo": [{"type": "ToolExecutionErrorDetails", "info": {"type":
        "Exception", "message": "cannot mod 3!", "traceback": "Traceback (most recent
        call last):\n  File \"/mnt/host/service/app/39571/requests/run2/mod_three.py\",
        line 7, in mod_three\n    raise Exception(\"cannot mod 3!\")\nException: cannot
        mod 3!\n", "filename": "/mnt/host/service/app/39571/requests/run2/mod_three.py",
        "lineno": 7, "name": "mod_three"}}], "debugInfo": {"type": "ToolExecutionError",
        "message": "Execution failure in ''mod_three'': (Exception) cannot mod 3!",
        "stackTrace": "\nThe above exception was the direct cause of the following
        exception:\n\nTraceback (most recent call last):\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/executor/flow_executor.py\",
        line 804, in _exec\n    output, nodes_outputs = self._traverse_nodes(inputs,
        context)\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/executor/flow_executor.py\",
        line 890, in _traverse_nodes\n    nodes_outputs, bypassed_nodes = self._submit_to_scheduler(context,
        inputs, batch_nodes)\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/executor/flow_executor.py\",
        line 910, in _submit_to_scheduler\n    return FlowNodesScheduler(self._tools_manager,
        inputs, nodes, self._node_concurrency, context).execute()\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/executor/_flow_nodes_scheduler.py\",
        line 69, in execute\n    raise e\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/executor/_flow_nodes_scheduler.py\",
        line 58, in execute\n    self._dag_manager.complete_nodes(self._collect_outputs(completed_futures))\n  File
        \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/executor/_flow_nodes_scheduler.py\",
        line 90, in _collect_outputs\n    each_node_result = each_future.result()\n  File
        \"/azureml-envs/prompt-flow/runtime/lib/python3.10/concurrent/futures/_base.py\",
        line 451, in result\n    return self.__get_result()\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/concurrent/futures/_base.py\",
        line 403, in __get_result\n    raise self._exception\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/concurrent/futures/thread.py\",
        line 58, in run\n    result = self.fn(*self.args, **self.kwargs)\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/executor/_flow_nodes_scheduler.py\",
        line 111, in _exec_single_node_in_thread\n    result = context.invoke_tool(node,
        f, kwargs=kwargs)\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/_core/flow_execution_context.py\",
        line 89, in invoke_tool\n    result = self._invoke_tool_with_timer(node, f,
        kwargs)\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/_core/flow_execution_context.py\",
        line 196, in _invoke_tool_with_timer\n    raise ToolExecutionError(node_name=node_name,
        module=module) from e\n", "innerException": {"type": "Exception", "message":
        "cannot mod 3!", "stackTrace": "Traceback (most recent call last):\n  File
        \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/_core/flow_execution_context.py\",
        line 185, in _invoke_tool_with_timer\n    return f(**kwargs)\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/_core/tool.py\",
        line 106, in decorated_tool\n    output = func(*args, **kwargs)\n  File \"/mnt/host/service/app/39571/requests/run2/mod_three.py\",
        line 7, in mod_three\n    raise Exception(\"cannot mod 3!\")\n", "innerException":
        null}}}, "inputs": {"number": 8, "line_number": 8}, "output": null, "metrics":
        null, "request": null, "parent_run_id": "run2", "root_run_id": "run2", "source_run_id":
        null, "flow_id": "default_flow_id", "start_time": "2023-12-26T10:14:19.483496Z",
        "end_time": "2023-12-26T10:14:19.589549Z", "index": 8, "api_calls": [{"name":
        "mod_three", "type": "Tool", "inputs": {"number": 8}, "output": null, "start_time":
        1703585659.49226, "end_time": 1703585659.493211, "error": {"message": "cannot
        mod 3!", "type": "Exception"}, "children": null, "node_name": "mod_three"}],
        "variant_id": "", "name": "", "description": "", "tags": null, "system_metrics":
        {"duration": 0.106053, "prompt_tokens": 0, "completion_tokens": 0, "total_tokens":
        0}, "result": null, "upload_metrics": false}, {"run_id": "run2_6", "status":
        "Completed", "error": null, "inputs": {"number": 6, "line_number": 6}, "output":
        {"output": 6}, "metrics": null, "request": null, "parent_run_id": "run2",
        "root_run_id": "run2", "source_run_id": null, "flow_id": "default_flow_id",
        "start_time": "2023-12-26T10:14:19.481789Z", "end_time": "2023-12-26T10:14:19.49945Z",
        "index": 6, "api_calls": [{"name": "mod_three", "type": "Tool", "inputs":
        {"number": 6}, "output": {"value": 6}, "start_time": 1703585659.495965, "end_time":
        1703585659.496901, "error": null, "children": null, "node_name": "mod_three"}],
        "variant_id": "", "name": "", "description": "", "tags": null, "system_metrics":
        {"duration": 0.017661, "prompt_tokens": 0, "completion_tokens": 0, "total_tokens":
        0}, "result": {"output": 6}, "upload_metrics": false}, {"run_id": "run2_16",
        "status": "Failed", "error": {"message": "Execution failure in ''mod_three'':
        (Exception) cannot mod 3!", "messageFormat": "Execution failure in ''{node_name}'':
        {error_type_and_message}", "messageParameters": {"node_name": "mod_three",
        "error_type_and_message": "(Exception) cannot mod 3!"}, "referenceCode": "Tool/__pf_main__",
        "code": "UserError", "innerError": {"code": "ToolExecutionError", "innerError":
        null}, "additionalInfo": [{"type": "ToolExecutionErrorDetails", "info": {"type":
        "Exception", "message": "cannot mod 3!", "traceback": "Traceback (most recent
        call last):\n  File \"/mnt/host/service/app/39571/requests/run2/mod_three.py\",
        line 7, in mod_three\n    raise Exception(\"cannot mod 3!\")\nException: cannot
        mod 3!\n", "filename": "/mnt/host/service/app/39571/requests/run2/mod_three.py",
        "lineno": 7, "name": "mod_three"}}], "debugInfo": {"type": "ToolExecutionError",
        "message": "Execution failure in ''mod_three'': (Exception) cannot mod 3!",
        "stackTrace": "\nThe above exception was the direct cause of the following
        exception:\n\nTraceback (most recent call last):\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/executor/flow_executor.py\",
        line 804, in _exec\n    output, nodes_outputs = self._traverse_nodes(inputs,
        context)\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/executor/flow_executor.py\",
        line 890, in _traverse_nodes\n    nodes_outputs, bypassed_nodes = self._submit_to_scheduler(context,
        inputs, batch_nodes)\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/executor/flow_executor.py\",
        line 910, in _submit_to_scheduler\n    return FlowNodesScheduler(self._tools_manager,
        inputs, nodes, self._node_concurrency, context).execute()\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/executor/_flow_nodes_scheduler.py\",
        line 69, in execute\n    raise e\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/executor/_flow_nodes_scheduler.py\",
        line 58, in execute\n    self._dag_manager.complete_nodes(self._collect_outputs(completed_futures))\n  File
        \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/executor/_flow_nodes_scheduler.py\",
        line 90, in _collect_outputs\n    each_node_result = each_future.result()\n  File
        \"/azureml-envs/prompt-flow/runtime/lib/python3.10/concurrent/futures/_base.py\",
        line 451, in result\n    return self.__get_result()\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/concurrent/futures/_base.py\",
        line 403, in __get_result\n    raise self._exception\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/concurrent/futures/thread.py\",
        line 58, in run\n    result = self.fn(*self.args, **self.kwargs)\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/executor/_flow_nodes_scheduler.py\",
        line 111, in _exec_single_node_in_thread\n    result = context.invoke_tool(node,
        f, kwargs=kwargs)\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/_core/flow_execution_context.py\",
        line 89, in invoke_tool\n    result = self._invoke_tool_with_timer(node, f,
        kwargs)\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/_core/flow_execution_context.py\",
        line 196, in _invoke_tool_with_timer\n    raise ToolExecutionError(node_name=node_name,
        module=module) from e\n", "innerException": {"type": "Exception", "message":
        "cannot mod 3!", "stackTrace": "Traceback (most recent call last):\n  File
        \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/_core/flow_execution_context.py\",
        line 185, in _invoke_tool_with_timer\n    return f(**kwargs)\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/_core/tool.py\",
        line 106, in decorated_tool\n    output = func(*args, **kwargs)\n  File \"/mnt/host/service/app/39571/requests/run2/mod_three.py\",
        line 7, in mod_three\n    raise Exception(\"cannot mod 3!\")\n", "innerException":
        null}}}, "inputs": {"number": 16, "line_number": 16}, "output": null, "metrics":
        null, "request": null, "parent_run_id": "run2", "root_run_id": "run2", "source_run_id":
        null, "flow_id": "default_flow_id", "start_time": "2023-12-26T10:14:19.579943Z",
        "end_time": "2023-12-26T10:14:19.591747Z", "index": 16, "api_calls": [{"name":
        "mod_three", "type": "Tool", "inputs": {"number": 16}, "output": null, "start_time":
        1703585659.583265, "end_time": 1703585659.584093, "error": {"message": "cannot
        mod 3!", "type": "Exception"}, "children": null, "node_name": "mod_three"}],
        "variant_id": "", "name": "", "description": "", "tags": null, "system_metrics":
        {"duration": 0.011804, "prompt_tokens": 0, "completion_tokens": 0, "total_tokens":
        0}, "result": null, "upload_metrics": false}, {"run_id": "run2_12", "status":
        "Completed", "error": null, "inputs": {"number": 12, "line_number": 12}, "output":
        {"output": 12}, "metrics": null, "request": null, "parent_run_id": "run2",
        "root_run_id": "run2", "source_run_id": null, "flow_id": "default_flow_id",
        "start_time": "2023-12-26T10:14:19.538014Z", "end_time": "2023-12-26T10:14:19.555993Z",
        "index": 12, "api_calls": [{"name": "mod_three", "type": "Tool", "inputs":
        {"number": 12}, "output": {"value": 12}, "start_time": 1703585659.552402,
        "end_time": 1703585659.553292, "error": null, "children": null, "node_name":
        "mod_three"}], "variant_id": "", "name": "", "description": "", "tags": null,
        "system_metrics": {"duration": 0.017979, "prompt_tokens": 0, "completion_tokens":
        0, "total_tokens": 0}, "result": {"output": 12}, "upload_metrics": false},
        {"run_id": "run2_10", "status": "Failed", "error": {"message": "Execution
        failure in ''mod_three'': (Exception) cannot mod 3!", "messageFormat": "Execution
        failure in ''{node_name}'': {error_type_and_message}", "messageParameters":
        {"node_name": "mod_three", "error_type_and_message": "(Exception) cannot mod
        3!"}, "referenceCode": "Tool/__pf_main__", "code": "UserError", "innerError":
        {"code": "ToolExecutionError", "innerError": null}, "additionalInfo": [{"type":
        "ToolExecutionErrorDetails", "info": {"type": "Exception", "message": "cannot
        mod 3!", "traceback": "Traceback (most recent call last):\n  File \"/mnt/host/service/app/39571/requests/run2/mod_three.py\",
        line 7, in mod_three\n    raise Exception(\"cannot mod 3!\")\nException: cannot
        mod 3!\n", "filename": "/mnt/host/service/app/39571/requests/run2/mod_three.py",
        "lineno": 7, "name": "mod_three"}}], "debugInfo": {"type": "ToolExecutionError",
        "message": "Execution failure in ''mod_three'': (Exception) cannot mod 3!",
        "stackTrace": "\nThe above exception was the direct cause of the following
        exception:\n\nTraceback (most recent call last):\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/executor/flow_executor.py\",
        line 804, in _exec\n    output, nodes_outputs = self._traverse_nodes(inputs,
        context)\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/executor/flow_executor.py\",
        line 890, in _traverse_nodes\n    nodes_outputs, bypassed_nodes = self._submit_to_scheduler(context,
        inputs, batch_nodes)\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/executor/flow_executor.py\",
        line 910, in _submit_to_scheduler\n    return FlowNodesScheduler(self._tools_manager,
        inputs, nodes, self._node_concurrency, context).execute()\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/executor/_flow_nodes_scheduler.py\",
        line 69, in execute\n    raise e\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/executor/_flow_nodes_scheduler.py\",
        line 58, in execute\n    self._dag_manager.complete_nodes(self._collect_outputs(completed_futures))\n  File
        \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/executor/_flow_nodes_scheduler.py\",
        line 90, in _collect_outputs\n    each_node_result = each_future.result()\n  File
        \"/azureml-envs/prompt-flow/runtime/lib/python3.10/concurrent/futures/_base.py\",
        line 451, in result\n    return self.__get_result()\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/concurrent/futures/_base.py\",
        line 403, in __get_result\n    raise self._exception\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/concurrent/futures/thread.py\",
        line 58, in run\n    result = self.fn(*self.args, **self.kwargs)\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/executor/_flow_nodes_scheduler.py\",
        line 111, in _exec_single_node_in_thread\n    result = context.invoke_tool(node,
        f, kwargs=kwargs)\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/_core/flow_execution_context.py\",
        line 89, in invoke_tool\n    result = self._invoke_tool_with_timer(node, f,
        kwargs)\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/_core/flow_execution_context.py\",
        line 196, in _invoke_tool_with_timer\n    raise ToolExecutionError(node_name=node_name,
        module=module) from e\n", "innerException": {"type": "Exception", "message":
        "cannot mod 3!", "stackTrace": "Traceback (most recent call last):\n  File
        \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/_core/flow_execution_context.py\",
        line 185, in _invoke_tool_with_timer\n    return f(**kwargs)\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/_core/tool.py\",
        line 106, in decorated_tool\n    output = func(*args, **kwargs)\n  File \"/mnt/host/service/app/39571/requests/run2/mod_three.py\",
        line 7, in mod_three\n    raise Exception(\"cannot mod 3!\")\n", "innerException":
        null}}}, "inputs": {"number": 10, "line_number": 10}, "output": null, "metrics":
        null, "request": null, "parent_run_id": "run2", "root_run_id": "run2", "source_run_id":
        null, "flow_id": "default_flow_id", "start_time": "2023-12-26T10:14:19.514085Z",
        "end_time": "2023-12-26T10:14:19.606305Z", "index": 10, "api_calls": [{"name":
        "mod_three", "type": "Tool", "inputs": {"number": 10}, "output": null, "start_time":
        1703585659.517488, "end_time": 1703585659.518439, "error": {"message": "cannot
        mod 3!", "type": "Exception"}, "children": null, "node_name": "mod_three"}],
        "variant_id": "", "name": "", "description": "", "tags": null, "system_metrics":
        {"duration": 0.09222, "prompt_tokens": 0, "completion_tokens": 0, "total_tokens":
        0}, "result": null, "upload_metrics": false}, {"run_id": "run2_14", "status":
        "Failed", "error": {"message": "Execution failure in ''mod_three'': (Exception)
        cannot mod 3!", "messageFormat": "Execution failure in ''{node_name}'': {error_type_and_message}",
        "messageParameters": {"node_name": "mod_three", "error_type_and_message":
        "(Exception) cannot mod 3!"}, "referenceCode": "Tool/__pf_main__", "code":
        "UserError", "innerError": {"code": "ToolExecutionError", "innerError": null},
        "additionalInfo": [{"type": "ToolExecutionErrorDetails", "info": {"type":
        "Exception", "message": "cannot mod 3!", "traceback": "Traceback (most recent
        call last):\n  File \"/mnt/host/service/app/39571/requests/run2/mod_three.py\",
        line 7, in mod_three\n    raise Exception(\"cannot mod 3!\")\nException: cannot
        mod 3!\n", "filename": "/mnt/host/service/app/39571/requests/run2/mod_three.py",
        "lineno": 7, "name": "mod_three"}}], "debugInfo": {"type": "ToolExecutionError",
        "message": "Execution failure in ''mod_three'': (Exception) cannot mod 3!",
        "stackTrace": "\nThe above exception was the direct cause of the following
        exception:\n\nTraceback (most recent call last):\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/executor/flow_executor.py\",
        line 804, in _exec\n    output, nodes_outputs = self._traverse_nodes(inputs,
        context)\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/executor/flow_executor.py\",
        line 890, in _traverse_nodes\n    nodes_outputs, bypassed_nodes = self._submit_to_scheduler(context,
        inputs, batch_nodes)\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/executor/flow_executor.py\",
        line 910, in _submit_to_scheduler\n    return FlowNodesScheduler(self._tools_manager,
        inputs, nodes, self._node_concurrency, context).execute()\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/executor/_flow_nodes_scheduler.py\",
        line 69, in execute\n    raise e\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/executor/_flow_nodes_scheduler.py\",
        line 58, in execute\n    self._dag_manager.complete_nodes(self._collect_outputs(completed_futures))\n  File
        \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/executor/_flow_nodes_scheduler.py\",
        line 90, in _collect_outputs\n    each_node_result = each_future.result()\n  File
        \"/azureml-envs/prompt-flow/runtime/lib/python3.10/concurrent/futures/_base.py\",
        line 451, in result\n    return self.__get_result()\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/concurrent/futures/_base.py\",
        line 403, in __get_result\n    raise self._exception\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/concurrent/futures/thread.py\",
        line 58, in run\n    result = self.fn(*self.args, **self.kwargs)\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/executor/_flow_nodes_scheduler.py\",
        line 111, in _exec_single_node_in_thread\n    result = context.invoke_tool(node,
        f, kwargs=kwargs)\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/_core/flow_execution_context.py\",
        line 89, in invoke_tool\n    result = self._invoke_tool_with_timer(node, f,
        kwargs)\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/_core/flow_execution_context.py\",
        line 196, in _invoke_tool_with_timer\n    raise ToolExecutionError(node_name=node_name,
        module=module) from e\n", "innerException": {"type": "Exception", "message":
        "cannot mod 3!", "stackTrace": "Traceback (most recent call last):\n  File
        \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/_core/flow_execution_context.py\",
        line 185, in _invoke_tool_with_timer\n    return f(**kwargs)\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/_core/tool.py\",
        line 106, in decorated_tool\n    output = func(*args, **kwargs)\n  File \"/mnt/host/service/app/39571/requests/run2/mod_three.py\",
        line 7, in mod_three\n    raise Exception(\"cannot mod 3!\")\n", "innerException":
        null}}}, "inputs": {"number": 14, "line_number": 14}, "output": null, "metrics":
        null, "request": null, "parent_run_id": "run2", "root_run_id": "run2", "source_run_id":
        null, "flow_id": "default_flow_id", "start_time": "2023-12-26T10:14:19.578286Z",
        "end_time": "2023-12-26T10:14:19.589388Z", "index": 14, "api_calls": [{"name":
        "mod_three", "type": "Tool", "inputs": {"number": 14}, "output": null, "start_time":
        1703585659.58103, "end_time": 1703585659.581986, "error": {"message": "cannot
        mod 3!", "type": "Exception"}, "children": null, "node_name": "mod_three"}],
        "variant_id": "", "name": "", "description": "", "tags": null, "system_metrics":
        {"duration": 0.011102, "prompt_tokens": 0, "completion_tokens": 0, "total_tokens":
        0}, "result": null, "upload_metrics": false}, {"run_id": "run2_4", "status":
        "Failed", "error": {"message": "Execution failure in ''mod_three'': (Exception)
        cannot mod 3!", "messageFormat": "Execution failure in ''{node_name}'': {error_type_and_message}",
        "messageParameters": {"node_name": "mod_three", "error_type_and_message":
        "(Exception) cannot mod 3!"}, "referenceCode": "Tool/__pf_main__", "code":
        "UserError", "innerError": {"code": "ToolExecutionError", "innerError": null},
        "additionalInfo": [{"type": "ToolExecutionErrorDetails", "info": {"type":
        "Exception", "message": "cannot mod 3!", "traceback": "Traceback (most recent
        call last):\n  File \"/mnt/host/service/app/39571/requests/run2/mod_three.py\",
        line 7, in mod_three\n    raise Exception(\"cannot mod 3!\")\nException: cannot
        mod 3!\n", "filename": "/mnt/host/service/app/39571/requests/run2/mod_three.py",
        "lineno": 7, "name": "mod_three"}}], "debugInfo": {"type": "ToolExecutionError",
        "message": "Execution failure in ''mod_three'': (Exception) cannot mod 3!",
        "stackTrace": "\nThe above exception was the direct cause of the following
        exception:\n\nTraceback (most recent call last):\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/executor/flow_executor.py\",
        line 804, in _exec\n    output, nodes_outputs = self._traverse_nodes(inputs,
        context)\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/executor/flow_executor.py\",
        line 890, in _traverse_nodes\n    nodes_outputs, bypassed_nodes = self._submit_to_scheduler(context,
        inputs, batch_nodes)\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/executor/flow_executor.py\",
        line 910, in _submit_to_scheduler\n    return FlowNodesScheduler(self._tools_manager,
        inputs, nodes, self._node_concurrency, context).execute()\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/executor/_flow_nodes_scheduler.py\",
        line 69, in execute\n    raise e\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/executor/_flow_nodes_scheduler.py\",
        line 58, in execute\n    self._dag_manager.complete_nodes(self._collect_outputs(completed_futures))\n  File
        \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/executor/_flow_nodes_scheduler.py\",
        line 90, in _collect_outputs\n    each_node_result = each_future.result()\n  File
        \"/azureml-envs/prompt-flow/runtime/lib/python3.10/concurrent/futures/_base.py\",
        line 451, in result\n    return self.__get_result()\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/concurrent/futures/_base.py\",
        line 403, in __get_result\n    raise self._exception\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/concurrent/futures/thread.py\",
        line 58, in run\n    result = self.fn(*self.args, **self.kwargs)\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/executor/_flow_nodes_scheduler.py\",
        line 111, in _exec_single_node_in_thread\n    result = context.invoke_tool(node,
        f, kwargs=kwargs)\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/_core/flow_execution_context.py\",
        line 89, in invoke_tool\n    result = self._invoke_tool_with_timer(node, f,
        kwargs)\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/_core/flow_execution_context.py\",
        line 196, in _invoke_tool_with_timer\n    raise ToolExecutionError(node_name=node_name,
        module=module) from e\n", "innerException": {"type": "Exception", "message":
        "cannot mod 3!", "stackTrace": "Traceback (most recent call last):\n  File
        \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/_core/flow_execution_context.py\",
        line 185, in _invoke_tool_with_timer\n    return f(**kwargs)\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/_core/tool.py\",
        line 106, in decorated_tool\n    output = func(*args, **kwargs)\n  File \"/mnt/host/service/app/39571/requests/run2/mod_three.py\",
        line 7, in mod_three\n    raise Exception(\"cannot mod 3!\")\n", "innerException":
        null}}}, "inputs": {"number": 4, "line_number": 4}, "output": null, "metrics":
        null, "request": null, "parent_run_id": "run2", "root_run_id": "run2", "source_run_id":
        null, "flow_id": "default_flow_id", "start_time": "2023-12-26T10:14:19.418548Z",
        "end_time": "2023-12-26T10:14:19.515483Z", "index": 4, "api_calls": [{"name":
        "mod_three", "type": "Tool", "inputs": {"number": 4}, "output": null, "start_time":
        1703585659.42448, "end_time": 1703585659.425335, "error": {"message": "cannot
        mod 3!", "type": "Exception"}, "children": null, "node_name": "mod_three"}],
        "variant_id": "", "name": "", "description": "", "tags": null, "system_metrics":
        {"duration": 0.096935, "prompt_tokens": 0, "completion_tokens": 0, "total_tokens":
        0}, "result": null, "upload_metrics": false}, {"run_id": "run2_2", "status":
        "Failed", "error": {"message": "Execution failure in ''mod_three'': (Exception)
        cannot mod 3!", "messageFormat": "Execution failure in ''{node_name}'': {error_type_and_message}",
        "messageParameters": {"node_name": "mod_three", "error_type_and_message":
        "(Exception) cannot mod 3!"}, "referenceCode": "Tool/__pf_main__", "code":
        "UserError", "innerError": {"code": "ToolExecutionError", "innerError": null},
        "additionalInfo": [{"type": "ToolExecutionErrorDetails", "info": {"type":
        "Exception", "message": "cannot mod 3!", "traceback": "Traceback (most recent
        call last):\n  File \"/mnt/host/service/app/39571/requests/run2/mod_three.py\",
        line 7, in mod_three\n    raise Exception(\"cannot mod 3!\")\nException: cannot
        mod 3!\n", "filename": "/mnt/host/service/app/39571/requests/run2/mod_three.py",
        "lineno": 7, "name": "mod_three"}}], "debugInfo": {"type": "ToolExecutionError",
        "message": "Execution failure in ''mod_three'': (Exception) cannot mod 3!",
        "stackTrace": "\nThe above exception was the direct cause of the following
        exception:\n\nTraceback (most recent call last):\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/executor/flow_executor.py\",
        line 804, in _exec\n    output, nodes_outputs = self._traverse_nodes(inputs,
        context)\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/executor/flow_executor.py\",
        line 890, in _traverse_nodes\n    nodes_outputs, bypassed_nodes = self._submit_to_scheduler(context,
        inputs, batch_nodes)\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/executor/flow_executor.py\",
        line 910, in _submit_to_scheduler\n    return FlowNodesScheduler(self._tools_manager,
        inputs, nodes, self._node_concurrency, context).execute()\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/executor/_flow_nodes_scheduler.py\",
        line 69, in execute\n    raise e\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/executor/_flow_nodes_scheduler.py\",
        line 58, in execute\n    self._dag_manager.complete_nodes(self._collect_outputs(completed_futures))\n  File
        \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/executor/_flow_nodes_scheduler.py\",
        line 90, in _collect_outputs\n    each_node_result = each_future.result()\n  File
        \"/azureml-envs/prompt-flow/runtime/lib/python3.10/concurrent/futures/_base.py\",
        line 451, in result\n    return self.__get_result()\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/concurrent/futures/_base.py\",
        line 403, in __get_result\n    raise self._exception\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/concurrent/futures/thread.py\",
        line 58, in run\n    result = self.fn(*self.args, **self.kwargs)\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/executor/_flow_nodes_scheduler.py\",
        line 111, in _exec_single_node_in_thread\n    result = context.invoke_tool(node,
        f, kwargs=kwargs)\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/_core/flow_execution_context.py\",
        line 89, in invoke_tool\n    result = self._invoke_tool_with_timer(node, f,
        kwargs)\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/_core/flow_execution_context.py\",
        line 196, in _invoke_tool_with_timer\n    raise ToolExecutionError(node_name=node_name,
        module=module) from e\n", "innerException": {"type": "Exception", "message":
        "cannot mod 3!", "stackTrace": "Traceback (most recent call last):\n  File
        \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/_core/flow_execution_context.py\",
        line 185, in _invoke_tool_with_timer\n    return f(**kwargs)\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/_core/tool.py\",
        line 106, in decorated_tool\n    output = func(*args, **kwargs)\n  File \"/mnt/host/service/app/39571/requests/run2/mod_three.py\",
        line 7, in mod_three\n    raise Exception(\"cannot mod 3!\")\n", "innerException":
        null}}}, "inputs": {"number": 2, "line_number": 2}, "output": null, "metrics":
        null, "request": null, "parent_run_id": "run2", "root_run_id": "run2", "source_run_id":
        null, "flow_id": "default_flow_id", "start_time": "2023-12-26T10:14:19.431964Z",
        "end_time": "2023-12-26T10:14:19.675685Z", "index": 2, "api_calls": [{"name":
        "mod_three", "type": "Tool", "inputs": {"number": 2}, "output": null, "start_time":
        1703585659.438676, "end_time": 1703585659.439644, "error": {"message": "cannot
        mod 3!", "type": "Exception"}, "children": null, "node_name": "mod_three"}],
        "variant_id": "", "name": "", "description": "", "tags": null, "system_metrics":
        {"duration": 0.243721, "prompt_tokens": 0, "completion_tokens": 0, "total_tokens":
        0}, "result": null, "upload_metrics": false}, {"run_id": "run2_18", "status":
        "Completed", "error": null, "inputs": {"number": 18, "line_number": 18}, "output":
        {"output": 18}, "metrics": null, "request": null, "parent_run_id": "run2",
        "root_run_id": "run2", "source_run_id": null, "flow_id": "default_flow_id",
        "start_time": "2023-12-26T10:14:19.809792Z", "end_time": "2023-12-26T10:14:19.812254Z",
        "index": 18, "api_calls": [{"name": "mod_three", "type": "Tool", "inputs":
        {"number": 18}, "output": {"value": 18}, "start_time": 1703585659.811399,
        "end_time": 1703585659.811488, "error": null, "children": null, "node_name":
        "mod_three"}], "variant_id": "", "name": "", "description": "", "tags": null,
        "system_metrics": {"duration": 0.002462, "prompt_tokens": 0, "completion_tokens":
        0, "total_tokens": 0}, "result": {"output": 18}, "upload_metrics": false}]'
    headers:
      connection:
      - keep-alive
      content-length:
      - '32871'
      content-type:
      - application/json; charset=utf-8
      strict-transport-security:
      - max-age=15724800; includeSubDomains; preload
      transfer-encoding:
      - chunked
      vary:
      - Accept-Encoding
      x-content-type-options:
      - nosniff
      x-request-time:
      - '0.833'
    status:
      code: 200
      message: OK
- request:
    body: null
    headers:
      Accept:
      - application/json
      Accept-Encoding:
      - gzip, deflate
      Connection:
      - keep-alive
      User-Agent:
      - promptflow-sdk/0.0.1 azsdk-python-azuremachinelearningdesignerserviceclient/unknown
        Python/3.10.13 (Windows-10-10.0.22631-SP0)
    method: GET
    uri: https://eastus.api.azureml.ms/flow/api/subscriptions/00000000-0000-0000-0000-000000000000/resourceGroups/00000/providers/Microsoft.MachineLearningServices/workspaces/00000/BulkRuns/run2/childRuns?endIndex=49&startIndex=25
  response:
    body:
      string: '[]'
    headers:
      connection:
      - keep-alive
      content-length:
      - '2'
      content-type:
      - application/json; charset=utf-8
      strict-transport-security:
      - max-age=15724800; includeSubDomains; preload
      x-content-type-options:
      - nosniff
      x-request-time:
      - '0.754'
    status:
      code: 200
      message: OK
- request:
    body: '{"runId": "run1", "selectRunMetadata": true, "selectRunDefinition": true,
      "selectJobSpecification": true}'
    headers:
      Accept:
      - '*/*'
      Accept-Encoding:
      - gzip, deflate
      Connection:
      - keep-alive
      Content-Length:
      - '137'
      Content-Type:
      - application/json
      User-Agent:
      - python-requests/2.31.0
    method: POST
    uri: https://eastus.api.azureml.ms/history/v1.0/subscriptions/00000000-0000-0000-0000-000000000000/resourceGroups/00000/providers/Microsoft.MachineLearningServices/workspaces/00000/rundata
  response:
    body:
      string: '{"runMetadata": {"runNumber": 1703585550, "rootRunId": "run1", "createdUtc":
        "2023-12-26T10:12:30.6270284+00:00", "createdBy": {"userObjectId": "00000000-0000-0000-0000-000000000000",
        "userPuId": null, "userIdp": "https://sts.windows.net/00000000-0000-0000-0000-000000000000/",
        "userAltSecId": null, "userIss": "https://sts.windows.net/00000000-0000-0000-0000-000000000000/",
        "userTenantId": "00000000-0000-0000-0000-000000000000", "userName": "4cbd0e2e-aae4-4099-b4ba-94d3a4910587",
        "upn": null}, "userId": "00000000-0000-0000-0000-000000000000", "token": null,
        "tokenExpiryTimeUtc": null, "error": {"error": {"code": "UserError", "severity":
        null, "message": "Execution failure in ''mod_two'': (Exception) cannot mod
        2!", "messageFormat": "{\"totalChildRuns\": 20, \"userErrorChildRuns\": 10,
        \"systemErrorChildRuns\": 0, \"errorDetails\": [{\"code\": \"UserError/ToolExecutionError\",
        \"messageFormat\": \"Execution failure in ''{node_name}'': {error_type_and_message}\",
        \"count\": 10}]}", "messageParameters": {"node_name": "mod_two", "error_type_and_message":
        "(Exception) cannot mod 2!"}, "referenceCode": "Tool/__pf_main__", "detailsUri":
        null, "target": null, "details": [], "innerError": {"code": "ToolExecutionError",
        "innerError": null}, "debugInfo": {"type": "ToolExecutionError", "message":
        "Execution failure in ''mod_two'': (Exception) cannot mod 2!", "stackTrace":
        "\nThe above exception was the direct cause of the following exception:\n\nTraceback
        (most recent call last):\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/executor/flow_executor.py\",
        line 804, in _exec\n    output, nodes_outputs = self._traverse_nodes(inputs,
        context)\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/executor/flow_executor.py\",
        line 890, in _traverse_nodes\n    nodes_outputs, bypassed_nodes = self._submit_to_scheduler(context,
        inputs, batch_nodes)\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/executor/flow_executor.py\",
        line 910, in _submit_to_scheduler\n    return FlowNodesScheduler(self._tools_manager,
        inputs, nodes, self._node_concurrency, context).execute()\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/executor/_flow_nodes_scheduler.py\",
        line 69, in execute\n    raise e\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/executor/_flow_nodes_scheduler.py\",
        line 58, in execute\n    self._dag_manager.complete_nodes(self._collect_outputs(completed_futures))\n  File
        \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/executor/_flow_nodes_scheduler.py\",
        line 90, in _collect_outputs\n    each_node_result = each_future.result()\n  File
        \"/azureml-envs/prompt-flow/runtime/lib/python3.10/concurrent/futures/_base.py\",
        line 451, in result\n    return self.__get_result()\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/concurrent/futures/_base.py\",
        line 403, in __get_result\n    raise self._exception\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/concurrent/futures/thread.py\",
        line 58, in run\n    result = self.fn(*self.args, **self.kwargs)\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/executor/_flow_nodes_scheduler.py\",
        line 111, in _exec_single_node_in_thread\n    result = context.invoke_tool(node,
        f, kwargs=kwargs)\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/_core/flow_execution_context.py\",
        line 89, in invoke_tool\n    result = self._invoke_tool_with_timer(node, f,
        kwargs)\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/_core/flow_execution_context.py\",
        line 196, in _invoke_tool_with_timer\n    raise ToolExecutionError(node_name=node_name,
        module=module) from e\n", "innerException": {"type": "Exception", "message":
        "cannot mod 2!", "stackTrace": "Traceback (most recent call last):\n  File
        \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/_core/flow_execution_context.py\",
        line 185, in _invoke_tool_with_timer\n    return f(**kwargs)\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/_core/tool.py\",
        line 106, in decorated_tool\n    output = func(*args, **kwargs)\n  File \"/mnt/host/service/app/39571/requests/run1/mod_two.py\",
        line 7, in mod_two\n    raise Exception(\"cannot mod 2!\")\n", "innerException":
        null, "data": null, "errorResponse": null}, "data": null, "errorResponse":
        null}, "additionalInfo": [{"type": "ToolExecutionErrorDetails", "info": {"type":
        "Exception", "message": "cannot mod 2!", "traceback": "Traceback (most recent
        call last):\n  File \"/mnt/host/service/app/39571/requests/run1/mod_two.py\",
        line 7, in mod_two\n    raise Exception(\"cannot mod 2!\")\nException: cannot
        mod 2!\n", "filename": "/mnt/host/service/app/39571/requests/run1/mod_two.py",
        "lineno": 7, "name": "mod_two"}}]}, "correlation": null, "environment": null,
        "location": null, "time": "2023-12-26T10:13:20.976909+00:00", "componentName":
        "promptflow-runtime/20231204.v4 Designer/1.0 promptflow-sdk/0.0.1 azsdk-python-azuremachinelearningdesignerserviceclient/unknown
        Python/3.10.13 (Windows-10-10.0.22631-SP0) promptflow/1.2.0rc1"}, "warnings":
        null, "revision": 7, "statusRevision": 3, "runUuid": "38b91a77-1269-428a-8904-fd9d71685588",
        "parentRunUuid": null, "rootRunUuid": "38b91a77-1269-428a-8904-fd9d71685588",
        "lastStartTimeUtc": null, "currentComputeTime": null, "computeDuration": "00:00:34.1758074",
        "effectiveStartTimeUtc": null, "lastModifiedBy": {"userObjectId": "00000000-0000-0000-0000-000000000000",
        "userPuId": null, "userIdp": "https://sts.windows.net/00000000-0000-0000-0000-000000000000/",
        "userAltSecId": null, "userIss": "https://sts.windows.net/00000000-0000-0000-0000-000000000000/",
        "userTenantId": "00000000-0000-0000-0000-000000000000", "userName": "18a66f5f-dbdf-4c17-9dd7-1634712a9cbe",
        "upn": null}, "lastModifiedUtc": "2023-12-26T10:13:20.2418927+00:00", "duration":
        "00:00:34.1758074", "cancelationReason": null, "currentAttemptId": 1, "runId":
        "run1", "parentRunId": null, "experimentId": "f65cb39a-0d28-4b06-9ef9-b962ed9df8d0",
        "status": "Completed", "startTimeUtc": "2023-12-26T10:12:46.9998955+00:00",
        "endTimeUtc": "2023-12-26T10:13:21.1757029+00:00", "scheduleId": null, "displayName":
        "run1", "name": null, "dataContainerId": "dcid.run1", "description": null,
        "hidden": false, "runType": "azureml.promptflow.FlowRun", "runTypeV2": {"orchestrator":
        null, "traits": [], "attribution": "PromptFlow", "computeType": "AmlcDsi"},
        "properties": {"azureml.promptflow.runtime_name": "test-runtime-ci", "azureml.promptflow.runtime_version":
        "20231204.v4", "azureml.promptflow.definition_file_name": "flow.dag.yaml",
        "azureml.promptflow.session_id": "357876c0a66919ba9791ba9723d3eb045181f10b65c806ea",
        "azureml.promptflow.flow_lineage_id": "3df9ed48cf83e1a38799b0a91f06e0825173b507d07391d1d91ec0253c1cda5c",
        "azureml.promptflow.flow_definition_datastore_name": "workspaceblobstore",
        "azureml.promptflow.flow_definition_blob_path": "LocalUpload/ceb856845f8689bdee2da5a26bd95bab/two/flow.dag.yaml",
        "azureml.promptflow.input_data": "azureml://datastores/workspaceblobstore/paths/LocalUpload/7e5ac781513436b66626132fefb20d1f/numbers.jsonl",
        "azureml.promptflow.inputs_mapping": "{\"number\":\"${data.value}\"}", "_azureml.evaluation_run":
        "promptflow.BatchRun", "azureml.promptflow.snapshot_id": "9db0d05b-bc15-4802-9391-43ba16c34ae1",
        "azureml.promptflow.total_tokens": "0", "_azureml.evaluate_artifacts": "[{\"path\":
        \"instance_results.jsonl\", \"type\": \"table\"}]"}, "parameters": {}, "actionUris":
        {}, "scriptName": null, "target": null, "uniqueChildRunComputeTargets": [],
        "tags": {}, "settings": {}, "services": {}, "inputDatasets": [], "outputDatasets":
        [], "runDefinition": null, "jobSpecification": null, "primaryMetricName":
        null, "createdFrom": null, "cancelUri": null, "completeUri": null, "diagnosticsUri":
        null, "computeRequest": null, "compute": null, "retainForLifetimeOfWorkspace":
        false, "queueingInfo": null, "inputs": null, "outputs": {"debug_info": {"assetId":
        "azureml://locations/eastus/workspaces/00000/data/azureml_run1_output_data_debug_info/versions/1",
        "type": "UriFolder"}, "flow_outputs": {"assetId": "azureml://locations/eastus/workspaces/00000/data/azureml_run1_output_data_flow_outputs/versions/1",
        "type": "UriFolder"}}}, "runDefinition": null, "jobSpecification": null, "systemSettings":
        null}'
    headers:
      connection:
      - keep-alive
      content-length:
      - '9907'
      content-type:
      - application/json; charset=utf-8
      strict-transport-security:
      - max-age=15724800; includeSubDomains; preload
      transfer-encoding:
      - chunked
      vary:
      - Accept-Encoding
      x-content-type-options:
      - nosniff
      x-request-time:
      - '0.037'
    status:
      code: 200
      message: OK
- request:
    body: '{"runId": "run2", "selectRunMetadata": true, "selectRunDefinition": true,
      "selectJobSpecification": true}'
    headers:
      Accept:
      - '*/*'
      Accept-Encoding:
      - gzip, deflate
      Connection:
      - keep-alive
      Content-Length:
      - '137'
      Content-Type:
      - application/json
      User-Agent:
      - python-requests/2.31.0
    method: POST
    uri: https://eastus.api.azureml.ms/history/v1.0/subscriptions/00000000-0000-0000-0000-000000000000/resourceGroups/00000/providers/Microsoft.MachineLearningServices/workspaces/00000/rundata
  response:
    body:
      string: '{"runMetadata": {"runNumber": 1703585642, "rootRunId": "run2", "createdUtc":
        "2023-12-26T10:14:02.7038098+00:00", "createdBy": {"userObjectId": "00000000-0000-0000-0000-000000000000",
        "userPuId": null, "userIdp": "https://sts.windows.net/00000000-0000-0000-0000-000000000000/",
        "userAltSecId": null, "userIss": "https://sts.windows.net/00000000-0000-0000-0000-000000000000/",
        "userTenantId": "00000000-0000-0000-0000-000000000000", "userName": "4cbd0e2e-aae4-4099-b4ba-94d3a4910587",
        "upn": null}, "userId": "00000000-0000-0000-0000-000000000000", "token": null,
        "tokenExpiryTimeUtc": null, "error": {"error": {"code": "UserError", "severity":
        null, "message": "Execution failure in ''mod_three'': (Exception) cannot mod
        3!", "messageFormat": "{\"totalChildRuns\": 10, \"userErrorChildRuns\": 6,
        \"systemErrorChildRuns\": 0, \"errorDetails\": [{\"code\": \"UserError/ToolExecutionError\",
        \"messageFormat\": \"Execution failure in ''{node_name}'': {error_type_and_message}\",
        \"count\": 6}]}", "messageParameters": {"node_name": "mod_three", "error_type_and_message":
        "(Exception) cannot mod 3!"}, "referenceCode": "Tool/__pf_main__", "detailsUri":
        null, "target": null, "details": [], "innerError": {"code": "ToolExecutionError",
        "innerError": null}, "debugInfo": {"type": "ToolExecutionError", "message":
        "Execution failure in ''mod_three'': (Exception) cannot mod 3!", "stackTrace":
        "\nThe above exception was the direct cause of the following exception:\n\nTraceback
        (most recent call last):\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/executor/flow_executor.py\",
        line 804, in _exec\n    output, nodes_outputs = self._traverse_nodes(inputs,
        context)\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/executor/flow_executor.py\",
        line 890, in _traverse_nodes\n    nodes_outputs, bypassed_nodes = self._submit_to_scheduler(context,
        inputs, batch_nodes)\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/executor/flow_executor.py\",
        line 910, in _submit_to_scheduler\n    return FlowNodesScheduler(self._tools_manager,
        inputs, nodes, self._node_concurrency, context).execute()\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/executor/_flow_nodes_scheduler.py\",
        line 69, in execute\n    raise e\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/executor/_flow_nodes_scheduler.py\",
        line 58, in execute\n    self._dag_manager.complete_nodes(self._collect_outputs(completed_futures))\n  File
        \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/executor/_flow_nodes_scheduler.py\",
        line 90, in _collect_outputs\n    each_node_result = each_future.result()\n  File
        \"/azureml-envs/prompt-flow/runtime/lib/python3.10/concurrent/futures/_base.py\",
        line 451, in result\n    return self.__get_result()\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/concurrent/futures/_base.py\",
        line 403, in __get_result\n    raise self._exception\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/concurrent/futures/thread.py\",
        line 58, in run\n    result = self.fn(*self.args, **self.kwargs)\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/executor/_flow_nodes_scheduler.py\",
        line 111, in _exec_single_node_in_thread\n    result = context.invoke_tool(node,
        f, kwargs=kwargs)\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/_core/flow_execution_context.py\",
        line 89, in invoke_tool\n    result = self._invoke_tool_with_timer(node, f,
        kwargs)\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/_core/flow_execution_context.py\",
        line 196, in _invoke_tool_with_timer\n    raise ToolExecutionError(node_name=node_name,
        module=module) from e\n", "innerException": {"type": "Exception", "message":
        "cannot mod 3!", "stackTrace": "Traceback (most recent call last):\n  File
        \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/_core/flow_execution_context.py\",
        line 185, in _invoke_tool_with_timer\n    return f(**kwargs)\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/_core/tool.py\",
        line 106, in decorated_tool\n    output = func(*args, **kwargs)\n  File \"/mnt/host/service/app/39571/requests/run2/mod_three.py\",
        line 7, in mod_three\n    raise Exception(\"cannot mod 3!\")\n", "innerException":
        null, "data": null, "errorResponse": null}, "data": null, "errorResponse":
        null}, "additionalInfo": [{"type": "ToolExecutionErrorDetails", "info": {"type":
        "Exception", "message": "cannot mod 3!", "traceback": "Traceback (most recent
        call last):\n  File \"/mnt/host/service/app/39571/requests/run2/mod_three.py\",
        line 7, in mod_three\n    raise Exception(\"cannot mod 3!\")\nException: cannot
        mod 3!\n", "filename": "/mnt/host/service/app/39571/requests/run2/mod_three.py",
        "lineno": 7, "name": "mod_three"}}]}, "correlation": null, "environment":
        null, "location": null, "time": "2023-12-26T10:14:52.581669+00:00", "componentName":
        "promptflow-runtime/20231204.v4 Designer/1.0 promptflow-sdk/0.0.1 azsdk-python-azuremachinelearningdesignerserviceclient/unknown
        Python/3.10.13 (Windows-10-10.0.22631-SP0) promptflow/1.2.0rc1"}, "warnings":
        null, "revision": 7, "statusRevision": 3, "runUuid": "d4d327cd-3d6a-4cb0-a939-bae4a0568c94",
        "parentRunUuid": null, "rootRunUuid": "d4d327cd-3d6a-4cb0-a939-bae4a0568c94",
        "lastStartTimeUtc": null, "currentComputeTime": null, "computeDuration": "00:00:33.7932034",
        "effectiveStartTimeUtc": null, "lastModifiedBy": {"userObjectId": "00000000-0000-0000-0000-000000000000",
        "userPuId": null, "userIdp": "https://sts.windows.net/00000000-0000-0000-0000-000000000000/",
        "userAltSecId": null, "userIss": "https://sts.windows.net/00000000-0000-0000-0000-000000000000/",
        "userTenantId": "00000000-0000-0000-0000-000000000000", "userName": "18a66f5f-dbdf-4c17-9dd7-1634712a9cbe",
        "upn": null}, "lastModifiedUtc": "2023-12-26T10:14:51.9214739+00:00", "duration":
        "00:00:33.7932034", "cancelationReason": null, "currentAttemptId": 1, "runId":
        "run2", "parentRunId": null, "experimentId": "3a00e270-37b9-49be-a74e-ac675487979e",
        "status": "Completed", "startTimeUtc": "2023-12-26T10:14:19.0217232+00:00",
        "endTimeUtc": "2023-12-26T10:14:52.8149266+00:00", "scheduleId": null, "displayName":
        "run2", "name": null, "dataContainerId": "dcid.run2", "description": null,
        "hidden": false, "runType": "azureml.promptflow.FlowRun", "runTypeV2": {"orchestrator":
        null, "traits": [], "attribution": "PromptFlow", "computeType": "AmlcDsi"},
        "properties": {"azureml.promptflow.runtime_name": "test-runtime-ci", "azureml.promptflow.runtime_version":
        "20231204.v4", "azureml.promptflow.definition_file_name": "flow.dag.yaml",
        "azureml.promptflow.session_id": "c9399af7028d644e85f3624a0b026432068432621519ab8f",
        "azureml.promptflow.flow_lineage_id": "77a36a2606b22ee30674046884962374e57e822acdeccac7750905d98e944580",
        "azureml.promptflow.flow_definition_datastore_name": "workspaceblobstore",
        "azureml.promptflow.flow_definition_blob_path": "LocalUpload/f0722e3fb27e86b101670dbb5e85554c/three/flow.dag.yaml",
        "azureml.promptflow.input_run_id": "run1", "azureml.promptflow.inputs_mapping":
        "{\"number\":\"${run.outputs.output}\"}", "_azureml.evaluation_run": "promptflow.BatchRun",
        "azureml.promptflow.snapshot_id": "f29cc6c7-8cd6-4330-9194-d8818a21f8d8",
        "azureml.promptflow.total_tokens": "0", "_azureml.evaluate_artifacts": "[{\"path\":
        \"instance_results.jsonl\", \"type\": \"table\"}]"}, "parameters": {}, "actionUris":
        {}, "scriptName": null, "target": null, "uniqueChildRunComputeTargets": [],
        "tags": {}, "settings": {}, "services": {}, "inputDatasets": [], "outputDatasets":
        [], "runDefinition": null, "jobSpecification": null, "primaryMetricName":
        null, "createdFrom": null, "cancelUri": null, "completeUri": null, "diagnosticsUri":
        null, "computeRequest": null, "compute": null, "retainForLifetimeOfWorkspace":
        false, "queueingInfo": null, "inputs": null, "outputs": {"debug_info": {"assetId":
        "azureml://locations/eastus/workspaces/00000/data/azureml_run2_output_data_debug_info/versions/1",
        "type": "UriFolder"}, "flow_outputs": {"assetId": "azureml://locations/eastus/workspaces/00000/data/azureml_run2_output_data_flow_outputs/versions/1",
        "type": "UriFolder"}}}, "runDefinition": null, "jobSpecification": null, "systemSettings":
        null}'
    headers:
      connection:
      - keep-alive
      content-length:
      - '9867'
      content-type:
      - application/json; charset=utf-8
      strict-transport-security:
      - max-age=15724800; includeSubDomains; preload
      transfer-encoding:
      - chunked
      vary:
      - Accept-Encoding
      x-content-type-options:
      - nosniff
      x-request-time:
      - '0.046'
    status:
      code: 200
      message: OK
- request:
    body: null
    headers:
      Accept:
      - application/json
      Accept-Encoding:
      - gzip, deflate
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      User-Agent:
      - promptflow-sdk/0.0.1 azsdk-python-azuremachinelearningdesignerserviceclient/unknown
        Python/3.10.13 (Windows-10-10.0.22631-SP0)
    method: GET
    uri: https://eastus.api.azureml.ms/flow/api/subscriptions/00000000-0000-0000-0000-000000000000/resourceGroups/00000/providers/Microsoft.MachineLearningServices/workspaces/00000/BulkRuns/run1/logContent
  response:
    body:
      string: '"2023-12-26 10:12:34 +0000      79 promptflow-runtime INFO     [run1]
        Receiving v2 bulk run request 69ec06d9-200b-4bb1-9161-b8ed1c583790: {\"flow_id\":
        \"run1\", \"flow_run_id\": \"run1\", \"flow_source\": {\"flow_source_type\":
        1, \"flow_source_info\": {\"snapshot_id\": \"9db0d05b-bc15-4802-9391-43ba16c34ae1\"},
        \"flow_dag_file\": \"flow.dag.yaml\"}, \"log_path\": \"https://promptfloweast4063704120.blob.core.windows.net/azureml/ExperimentRun/dcid.run1/logs/azureml/executionlogs.txt?sv=2019-07-07&sr=b&sig=**data_scrubbed**&skoid=55b92eba-d7c7-4afd-ab76-7bb1cd345283&sktid=00000000-0000-0000-0000-000000000000&skt=2023-12-26T03%3A35%3A19Z&ske=2023-12-27T11%3A45%3A19Z&sks=b&skv=2019-07-07&st=2023-12-26T10%3A02%3A34Z&se=2023-12-26T18%3A12%3A34Z&sp=rcw\",
        \"app_insights_instrumentation_key\": \"InstrumentationKey=**data_scrubbed**;IngestionEndpoint=https://eastus-6.in.applicationinsights.azure.com/;LiveEndpoint=https://eastus.livediagnostics.monitor.azure.com/\",
        \"data_inputs\": {\"data\": \"azureml://datastores/workspaceblobstore/paths/LocalUpload/7e5ac781513436b66626132fefb20d1f/numbers.jsonl\"},
        \"inputs_mapping\": {\"number\": \"${data.value}\"}, \"azure_storage_setting\":
        {\"azure_storage_mode\": 1, \"storage_account_name\": \"promptfloweast4063704120\",
        \"blob_container_name\": \"azureml-blobstore-3e123da1-f9a5-4c91-9234-8d9ffbb39ff5\",
        \"flow_artifacts_root_path\": \"promptflow/PromptFlowArtifacts/run1\", \"blob_container_sas_token\":
        \"?sv=2019-07-07&sr=c&sig=**data_scrubbed**&skoid=55b92eba-d7c7-4afd-ab76-7bb1cd345283&sktid=00000000-0000-0000-0000-000000000000&skt=2023-12-26T10%3A12%3A34Z&ske=2024-01-02T10%3A12%3A34Z&sks=b&skv=2019-07-07&se=2024-01-02T10%3A12%3A34Z&sp=racwl\",
        \"output_datastore_name\": \"workspaceblobstore\"}}\n2023-12-26 10:12:34 +0000      79
        promptflow-runtime INFO     Runtime version: 20231204.v4. PromptFlow version:
        1.2.0rc1\n2023-12-26 10:12:34 +0000      79 promptflow-runtime INFO     Updating
        run1 to Status.Preparing...\n2023-12-26 10:12:34 +0000      79 promptflow-runtime
        INFO     Downloading snapshot to /mnt/host/service/app/39571/requests/run1\n2023-12-26
        10:12:34 +0000      79 promptflow-runtime INFO     Get snapshot sas url for
        9db0d05b-bc15-4802-9391-43ba16c34ae1...\n2023-12-26 10:12:41 +0000      79
        promptflow-runtime INFO     Downloading snapshot 9db0d05b-bc15-4802-9391-43ba16c34ae1
        from uri https://promptfloweast4063704120.blob.core.windows.net/snapshotzips/promptflow-eastus:3e123da1-f9a5-4c91-9234-8d9ffbb39ff5:snapshotzip/9db0d05b-bc15-4802-9391-43ba16c34ae1.zip...\n2023-12-26
        10:12:41 +0000      79 promptflow-runtime INFO     Downloaded file /mnt/host/service/app/39571/requests/run1/9db0d05b-bc15-4802-9391-43ba16c34ae1.zip
        with size 509 for snapshot 9db0d05b-bc15-4802-9391-43ba16c34ae1.\n2023-12-26
        10:12:41 +0000      79 promptflow-runtime INFO     Download snapshot 9db0d05b-bc15-4802-9391-43ba16c34ae1
        completed.\n2023-12-26 10:12:41 +0000      79 promptflow-runtime INFO     Successfully
        download snapshot to /mnt/host/service/app/39571/requests/run1\n2023-12-26
        10:12:41 +0000      79 promptflow-runtime INFO     About to execute a python
        flow.\n2023-12-26 10:12:41 +0000      79 promptflow-runtime INFO     Use spawn
        method to start child process.\n2023-12-26 10:12:41 +0000      79 promptflow-runtime
        INFO     Starting to check process 52610 status for run run1\n2023-12-26 10:12:41
        +0000      79 promptflow-runtime INFO     Start checking run status for run
        run1\n2023-12-26 10:12:45 +0000   52610 promptflow-runtime INFO     [79--52610]
        Start processing flowV2......\n2023-12-26 10:12:45 +0000   52610 promptflow-runtime
        INFO     Runtime version: 20231204.v4. PromptFlow version: 1.2.0rc1\n2023-12-26
        10:12:45 +0000   52610 promptflow-runtime INFO     Setting mlflow tracking
        uri...\n2023-12-26 10:12:45 +0000   52610 promptflow-runtime INFO     Validating
        ''AzureML Data Scientist'' user authentication...\n2023-12-26 10:12:45 +0000   52610
        promptflow-runtime INFO     Successfully validated ''AzureML Data Scientist''
        user authentication.\n2023-12-26 10:12:45 +0000   52610 promptflow-runtime
        INFO     Using AzureMLRunStorageV2\n2023-12-26 10:12:46 +0000   52610 promptflow-runtime
        INFO     Setting mlflow tracking uri to ''azureml://eastus.api.azureml.ms/mlflow/v1.0/subscriptions/00000000-0000-0000-0000-000000000000/resourceGroups/00000/providers/Microsoft.MachineLearningServices/workspaces/promptflow-eastus''\n2023-12-26
        10:12:46 +0000   52610 promptflow-runtime INFO     Initialized blob service
        client for AzureMLRunTracker.\n2023-12-26 10:12:46 +0000   52610 promptflow-runtime
        INFO     Setting mlflow tracking uri to ''azureml://eastus.api.azureml.ms/mlflow/v1.0/subscriptions/00000000-0000-0000-0000-000000000000/resourceGroups/00000/providers/Microsoft.MachineLearningServices/workspaces/promptflow-eastus''\n2023-12-26
        10:12:46 +0000   52610 promptflow-runtime INFO     Resolve data from url finished
        in 0.6449429979547858 seconds\n2023-12-26 10:12:46 +0000   52610 promptflow-runtime
        INFO     Starting the aml run ''run1''...\n2023-12-26 10:12:47 +0000   52610
        execution.bulk     INFO     Using fork, process count: 16\n2023-12-26 10:12:47
        +0000   52667 execution.bulk     INFO     Process 52667 started.\n2023-12-26
        10:12:47 +0000   52672 execution.bulk     INFO     Process 52672 started.\n2023-12-26
        10:12:47 +0000   52678 execution.bulk     INFO     Process 52678 started.\n2023-12-26
        10:12:47 +0000   52688 execution.bulk     INFO     Process 52688 started.\n2023-12-26
        10:12:47 +0000   52699 execution.bulk     INFO     Process 52699 started.\n2023-12-26
        10:12:47 +0000   52672 execution          ERROR    Node mod_two in line 1
        failed. Exception: Execution failure in ''mod_two'': (Exception) cannot mod
        2!.\nTraceback (most recent call last):\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/_core/flow_execution_context.py\",
        line 185, in _invoke_tool_with_timer\n    return f(**kwargs)\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/_core/tool.py\",
        line 106, in decorated_tool\n    output = func(*args, **kwargs)\n  File \"/mnt/host/service/app/39571/requests/run1/mod_two.py\",
        line 7, in mod_two\n    raise Exception(\"cannot mod 2!\")\nException: cannot
        mod 2!\n\nThe above exception was the direct cause of the following exception:\n\nTraceback
        (most recent call last):\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/_core/flow_execution_context.py\",
        line 89, in invoke_tool\n    result = self._invoke_tool_with_timer(node, f,
        kwargs)\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/_core/flow_execution_context.py\",
        line 196, in _invoke_tool_with_timer\n    raise ToolExecutionError(node_name=node_name,
        module=module) from e\npromptflow._core._errors.ToolExecutionError: Execution
        failure in ''mod_two'': (Exception) cannot mod 2!\n2023-12-26 10:12:47 +0000   52610
        execution.bulk     INFO     Process name: ForkProcess-104:2, Process id: 52667,
        Line number: 0 start execution.\n2023-12-26 10:12:47 +0000   52672 execution          ERROR    Execution
        of one node has failed. Cancelling all running nodes: mod_two.\n2023-12-26
        10:12:47 +0000   52708 execution.bulk     INFO     Process 52708 started.\n2023-12-26
        10:12:47 +0000   52713 execution.bulk     INFO     Process 52713 started.\n2023-12-26
        10:12:47 +0000   52714 execution.bulk     INFO     Process 52714 started.\n2023-12-26
        10:12:47 +0000   52721 execution.bulk     INFO     Process 52721 started.\n2023-12-26
        10:12:47 +0000   52725 execution.bulk     INFO     Process 52725 started.\n2023-12-26
        10:12:47 +0000   52732 execution.bulk     INFO     Process 52732 started.\n2023-12-26
        10:12:47 +0000   52699 execution          ERROR    Node mod_two in line 3
        failed. Exception: Execution failure in ''mod_two'': (Exception) cannot mod
        2!.\nTraceback (most recent call last):\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/_core/flow_execution_context.py\",
        line 185, in _invoke_tool_with_timer\n    return f(**kwargs)\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/_core/tool.py\",
        line 106, in decorated_tool\n    output = func(*args, **kwargs)\n  File \"/mnt/host/service/app/39571/requests/run1/mod_two.py\",
        line 7, in mod_two\n    raise Exception(\"cannot mod 2!\")\nException: cannot
        mod 2!\n\nThe above exception was the direct cause of the following exception:\n\nTraceback
        (most recent call last):\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/_core/flow_execution_context.py\",
        line 89, in invoke_tool\n    result = self._invoke_tool_with_timer(node, f,
        kwargs)\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/_core/flow_execution_context.py\",
        line 196, in _invoke_tool_with_timer\n    raise ToolExecutionError(node_name=node_name,
        module=module) from e\npromptflow._core._errors.ToolExecutionError: Execution
        failure in ''mod_two'': (Exception) cannot mod 2!\n2023-12-26 10:12:47 +0000   52737
        execution.bulk     INFO     Process 52737 started.\n2023-12-26 10:12:47 +0000   52699
        execution          ERROR    Execution of one node has failed. Cancelling all
        running nodes: mod_two.\n2023-12-26 10:12:47 +0000   52610 execution.bulk     INFO     Process
        name: ForkProcess-104:3, Process id: 52672, Line number: 1 start execution.\n2023-12-26
        10:12:47 +0000   52610 execution.bulk     INFO     Process name: ForkProcess-104:5,
        Process id: 52678, Line number: 2 start execution.\n2023-12-26 10:12:47 +0000   52749
        execution.bulk     INFO     Process 52749 started.\n2023-12-26 10:12:47 +0000   52610
        execution.bulk     INFO     Process name: ForkProcess-104:7, Process id: 52699,
        Line number: 3 start execution.\n2023-12-26 10:12:47 +0000   52755 execution.bulk     INFO     Process
        52755 started.\n2023-12-26 10:12:47 +0000   52737 execution          ERROR    Node
        mod_two in line 11 failed. Exception: Execution failure in ''mod_two'': (Exception)
        cannot mod 2!.\nTraceback (most recent call last):\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/_core/flow_execution_context.py\",
        line 185, in _invoke_tool_with_timer\n    return f(**kwargs)\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/_core/tool.py\",
        line 106, in decorated_tool\n    output = func(*args, **kwargs)\n  File \"/mnt/host/service/app/39571/requests/run1/mod_two.py\",
        line 7, in mod_two\n    raise Exception(\"cannot mod 2!\")\nException: cannot
        mod 2!\n\nThe above exception was the direct cause of the following exception:\n\nTraceback
        (most recent call last):\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/_core/flow_execution_context.py\",
        line 89, in invoke_tool\n    result = self._invoke_tool_with_timer(node, f,
        kwargs)\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/_core/flow_execution_context.py\",
        line 196, in _invoke_tool_with_timer\n    raise ToolExecutionError(node_name=node_name,
        module=module) from e\npromptflow._core._errors.ToolExecutionError: Execution
        failure in ''mod_two'': (Exception) cannot mod 2!\n2023-12-26 10:12:47 +0000   52610
        execution.bulk     INFO     Process name: ForkProcess-104:4, Process id: 52688,
        Line number: 4 start execution.\n2023-12-26 10:12:47 +0000   52737 execution          ERROR    Execution
        of one node has failed. Cancelling all running nodes: mod_two.\n2023-12-26
        10:12:47 +0000   52760 execution.bulk     INFO     Process 52760 started.\n2023-12-26
        10:12:47 +0000   52610 execution.bulk     INFO     Process name: ForkProcess-104:8,
        Process id: 52708, Line number: 5 start execution.\n2023-12-26 10:12:47 +0000   52610
        execution.bulk     INFO     Process name: ForkProcess-104:9, Process id: 52713,
        Line number: 6 start execution.\n2023-12-26 10:12:47 +0000   52610 execution.bulk     INFO     Process
        name: ForkProcess-104:6, Process id: 52714, Line number: 7 start execution.\n2023-12-26
        10:12:47 +0000   52610 execution.bulk     INFO     Process name: ForkProcess-104:10,
        Process id: 52721, Line number: 8 start execution.\n2023-12-26 10:12:47 +0000   52610
        execution.bulk     INFO     Process name: ForkProcess-104:11, Process id:
        52725, Line number: 9 start execution.\n2023-12-26 10:12:47 +0000   52610
        execution.bulk     INFO     Process name: ForkProcess-104:13, Process id:
        52732, Line number: 10 start execution.\n2023-12-26 10:12:47 +0000   52610
        execution.bulk     INFO     Process name: ForkProcess-104:16, Process id:
        52737, Line number: 11 start execution.\n2023-12-26 10:12:47 +0000   52610
        execution.bulk     INFO     Process name: ForkProcess-104:14, Process id:
        52760, Line number: 12 start execution.\n2023-12-26 10:12:47 +0000   52610
        execution.bulk     INFO     Process name: ForkProcess-104:3, Process id: 52672,
        Line number: 1 completed.\n2023-12-26 10:12:47 +0000   52610 execution.bulk     INFO     Process
        name: ForkProcess-104:2, Process id: 52667, Line number: 0 completed.\n2023-12-26
        10:12:47 +0000   52610 execution.bulk     INFO     Process name: ForkProcess-104:8,
        Process id: 52708, Line number: 5 completed.\n2023-12-26 10:12:47 +0000   52610
        execution.bulk     INFO     Process name: ForkProcess-104:7, Process id: 52699,
        Line number: 3 completed.\n2023-12-26 10:12:47 +0000   52610 execution.bulk     INFO     Process
        name: ForkProcess-104:4, Process id: 52688, Line number: 4 completed.\n2023-12-26
        10:12:48 +0000   52699 execution          ERROR    Node mod_two in line 13
        failed. Exception: Execution failure in ''mod_two'': (Exception) cannot mod
        2!.\nTraceback (most recent call last):\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/_core/flow_execution_context.py\",
        line 185, in _invoke_tool_with_timer\n    return f(**kwargs)\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/_core/tool.py\",
        line 106, in decorated_tool\n    output = func(*args, **kwargs)\n  File \"/mnt/host/service/app/39571/requests/run1/mod_two.py\",
        line 7, in mod_two\n    raise Exception(\"cannot mod 2!\")\nException: cannot
        mod 2!\n\nThe above exception was the direct cause of the following exception:\n\nTraceback
        (most recent call last):\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/_core/flow_execution_context.py\",
        line 89, in invoke_tool\n    result = self._invoke_tool_with_timer(node, f,
        kwargs)\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/_core/flow_execution_context.py\",
        line 196, in _invoke_tool_with_timer\n    raise ToolExecutionError(node_name=node_name,
        module=module) from e\npromptflow._core._errors.ToolExecutionError: Execution
        failure in ''mod_two'': (Exception) cannot mod 2!\n2023-12-26 10:12:47 +0000   52610
        execution.bulk     INFO     Process name: ForkProcess-104:5, Process id: 52678,
        Line number: 2 completed.\n2023-12-26 10:12:48 +0000   52699 execution          ERROR    Execution
        of one node has failed. Cancelling all running nodes: mod_two.\n2023-12-26
        10:12:47 +0000   52610 execution.bulk     INFO     Finished 6 / 20 lines.\n2023-12-26
        10:12:47 +0000   52610 execution.bulk     INFO     Process name: ForkProcess-104:9,
        Process id: 52713, Line number: 6 completed.\n2023-12-26 10:12:47 +0000   52610
        execution.bulk     INFO     Process name: ForkProcess-104:6, Process id: 52714,
        Line number: 7 completed.\n2023-12-26 10:12:47 +0000   52610 execution.bulk     INFO     Finished
        8 / 20 lines.\n2023-12-26 10:12:47 +0000   52610 execution.bulk     INFO     Process
        name: ForkProcess-104:10, Process id: 52721, Line number: 8 completed.\n2023-12-26
        10:12:47 +0000   52610 execution.bulk     INFO     Process name: ForkProcess-104:11,
        Process id: 52725, Line number: 9 completed.\n2023-12-26 10:12:47 +0000   52610
        execution.bulk     INFO     Finished 10 / 20 lines.\n2023-12-26 10:12:47 +0000   52610
        execution.bulk     INFO     Process name: ForkProcess-104:13, Process id:
        52732, Line number: 10 completed.\n2023-12-26 10:12:47 +0000   52610 execution.bulk     INFO     Process
        name: ForkProcess-104:7, Process id: 52699, Line number: 13 start execution.\n2023-12-26
        10:12:48 +0000   52610 execution.bulk     INFO     Process name: ForkProcess-104:14,
        Process id: 52760, Line number: 12 completed.\n2023-12-26 10:12:48 +0000   52610
        execution.bulk     INFO     Finished 12 / 20 lines.\n2023-12-26 10:12:48 +0000   52610
        execution.bulk     INFO     Process name: ForkProcess-104:16, Process id:
        52737, Line number: 11 completed.\n2023-12-26 10:12:48 +0000   52610 execution.bulk     INFO     Process
        name: ForkProcess-104:5, Process id: 52678, Line number: 14 start execution.\n2023-12-26
        10:12:48 +0000   52610 execution.bulk     INFO     Average execution time
        for completed lines: 0.11 seconds. Estimated time for incomplete lines: 1.54
        seconds.\n2023-12-26 10:12:48 +0000   52610 execution.bulk     INFO     Process
        name: ForkProcess-104:9, Process id: 52713, Line number: 15 start execution.\n2023-12-26
        10:12:48 +0000   52610 execution.bulk     INFO     Process name: ForkProcess-104:6,
        Process id: 52714, Line number: 16 start execution.\n2023-12-26 10:12:48 +0000   52610
        execution.bulk     INFO     Average execution time for completed lines: 0.09
        seconds. Estimated time for incomplete lines: 1.08 seconds.\n2023-12-26 10:12:48
        +0000   52610 execution.bulk     INFO     Process name: ForkProcess-104:10,
        Process id: 52721, Line number: 17 start execution.\n2023-12-26 10:12:48 +0000   52610
        execution.bulk     INFO     Process name: ForkProcess-104:11, Process id:
        52725, Line number: 18 start execution.\n2023-12-26 10:12:48 +0000   52610
        execution.bulk     INFO     Average execution time for completed lines: 0.07
        seconds. Estimated time for incomplete lines: 0.7 seconds.\n2023-12-26 10:12:48
        +0000   52610 execution.bulk     INFO     Process name: ForkProcess-104:13,
        Process id: 52732, Line number: 19 start execution.\n2023-12-26 10:12:48 +0000   52610
        execution.bulk     INFO     Average execution time for completed lines: 0.06
        seconds. Estimated time for incomplete lines: 0.48 seconds.\n2023-12-26 10:12:48
        +0000   52610 execution.bulk     INFO     Process name: ForkProcess-104:7,
        Process id: 52699, Line number: 13 completed.\n2023-12-26 10:12:48 +0000   52610
        execution.bulk     INFO     Process name: ForkProcess-104:5, Process id: 52678,
        Line number: 14 completed.\n2023-12-26 10:12:48 +0000   52610 execution.bulk     INFO     Process
        name: ForkProcess-104:9, Process id: 52713, Line number: 15 completed.\n2023-12-26
        10:12:48 +0000   52610 execution.bulk     INFO     Process name: ForkProcess-104:6,
        Process id: 52714, Line number: 16 completed.\n2023-12-26 10:12:48 +0000   52610
        execution.bulk     INFO     Process name: ForkProcess-104:10, Process id:
        52721, Line number: 17 completed.\n2023-12-26 10:12:48 +0000   52610 execution.bulk     INFO     Finished
        18 / 20 lines.\n2023-12-26 10:12:48 +0000   52610 execution.bulk     INFO     Process
        name: ForkProcess-104:11, Process id: 52725, Line number: 18 completed.\n2023-12-26
        10:12:48 +0000   52610 execution.bulk     INFO     Process name: ForkProcess-104:13,
        Process id: 52732, Line number: 19 completed.\n2023-12-26 10:12:48 +0000   52610
        execution.bulk     INFO     Finished 20 / 20 lines.\n2023-12-26 10:12:48 +0000   52610
        execution.bulk     INFO     Average execution time for completed lines: 0.06
        seconds. Estimated time for incomplete lines: 0.12 seconds.\n2023-12-26 10:12:48
        +0000   52610 execution.bulk     INFO     Finished 20 / 20 lines.\n2023-12-26
        10:12:48 +0000   52610 execution.bulk     INFO     Finished 20 / 20 lines.\n2023-12-26
        10:12:48 +0000   52610 execution.bulk     INFO     Average execution time
        for completed lines: 0.06 seconds. Estimated time for incomplete lines: 0.0
        seconds.\n2023-12-26 10:12:48 +0000   52610 execution.bulk     INFO     Average
        execution time for completed lines: 0.06 seconds. Estimated time for incomplete
        lines: 0.0 seconds.\n2023-12-26 10:12:48 +0000   52610 execution.bulk     INFO     Average
        execution time for completed lines: 0.06 seconds. Estimated time for incomplete
        lines: 0.0 seconds.\n2023-12-26 10:13:18 +0000   52610 execution          ERROR    10/20
        flow run failed, indexes: [1,3,5,7,9,11,13,15,17,19], exception of index 1:
        Execution failure in ''mod_two'': (Exception) cannot mod 2!\n2023-12-26 10:13:20
        +0000   52610 execution.bulk     INFO     Upload status summary metrics for
        run run1 finished in 1.4660483147017658 seconds\n2023-12-26 10:13:20 +0000   52610
        promptflow-runtime INFO     Successfully write run properties {\"azureml.promptflow.total_tokens\":
        0, \"_azureml.evaluate_artifacts\": \"[{\\\"path\\\": \\\"instance_results.jsonl\\\",
        \\\"type\\\": \\\"table\\\"}]\"} with run id ''run1''\n2023-12-26 10:13:20
        +0000   52610 execution.bulk     INFO     Upload RH properties for run run1
        finished in 0.09677773574367166 seconds\n2023-12-26 10:13:20 +0000   52610
        promptflow-runtime INFO     Creating unregistered output Asset for Run run1...\n2023-12-26
        10:13:20 +0000   52610 promptflow-runtime INFO     Created debug_info Asset:
        azureml://locations/eastus/workspaces/00000/data/azureml_run1_output_data_debug_info/versions/1\n2023-12-26
        10:13:20 +0000   52610 promptflow-runtime INFO     Creating unregistered output
        Asset for Run run1...\n2023-12-26 10:13:20 +0000   52610 promptflow-runtime
        INFO     Created flow_outputs output Asset: azureml://locations/eastus/workspaces/00000/data/azureml_run1_output_data_flow_outputs/versions/1\n2023-12-26
        10:13:20 +0000   52610 promptflow-runtime INFO     Creating Artifact for Run
        run1...\n2023-12-26 10:13:20 +0000   52610 promptflow-runtime INFO     Created
        instance_results.jsonl Artifact.\n2023-12-26 10:13:20 +0000   52610 promptflow-runtime
        INFO     Patching run1...\n2023-12-26 10:13:20 +0000   52610 promptflow-runtime
        WARNING  [run1] Run failed. Execution stackTrace: Traceback (most recent call
        last):\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/_core/flow_execution_context.py\",
        line 185, in _invoke_tool_with_timer\n    return f(**kwargs)\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/_core/tool.py\",
        line 106, in decorated_tool\n    output = func(*args, **kwargs)\n  [REDACTED:
        External StackTrace]\n\nThe above exception was the direct cause of the following
        exception:\n\nTraceback (most recent call last):\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/executor/flow_executor.py\",
        line 804, in _exec\n    output, nodes_outputs = self._traverse_nodes(inputs,
        context)\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/executor/flow_executor.py\",
        line 890, in _traverse_nodes\n    nodes_outputs, bypassed_nodes = self._submit_to_scheduler(context,
        inputs, batch_nodes)\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/executor/flow_executor.py\",
        line 910, in _submit_to_scheduler\n    return FlowNodesScheduler(self._tools_manager,
        inputs, nodes, self._node_concurrency, context).execute()\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/executor/_flow_nodes_scheduler.py\",
        line 69, in execute\n    raise e\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/executor/_flow_nodes_scheduler.py\",
        line 58, in execute\n    self._dag_manager.complete_nodes(self._collect_outputs(completed_futures))\n  File
        \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/executor/_flow_nodes_scheduler.py\",
        line 90, in _collect_outputs\n    each_node_result = each_future.result()\n  [REDACTED:
        External StackTrace]\n\n2023-12-26 10:13:21 +0000   52610 promptflow-runtime
        INFO     Ending the aml run ''run1'' with status ''Completed''...\n2023-12-26
        10:13:22 +0000      79 promptflow-runtime INFO     Process 52610 finished\n2023-12-26
        10:13:22 +0000      79 promptflow-runtime INFO     [79] Child process finished!\n2023-12-26
        10:13:22 +0000      79 promptflow-runtime INFO     [run1] End processing bulk
        run\n2023-12-26 10:13:22 +0000      79 promptflow-runtime INFO     Cleanup
        working dir /mnt/host/service/app/39571/requests/run1 for bulk run\n"'
    headers:
      connection:
      - keep-alive
      content-length:
      - '25293'
      content-type:
      - application/json; charset=utf-8
      strict-transport-security:
      - max-age=15724800; includeSubDomains; preload
      transfer-encoding:
      - chunked
      vary:
      - Accept-Encoding
      x-content-type-options:
      - nosniff
      x-request-time:
      - '0.525'
    status:
      code: 200
      message: OK
- request:
    body: null
    headers:
      Accept:
      - application/json
      Accept-Encoding:
      - gzip, deflate
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      User-Agent:
      - promptflow-sdk/0.0.1 azsdk-python-azuremachinelearningdesignerserviceclient/unknown
        Python/3.10.13 (Windows-10-10.0.22631-SP0)
    method: GET
    uri: https://eastus.api.azureml.ms/flow/api/subscriptions/00000000-0000-0000-0000-000000000000/resourceGroups/00000/providers/Microsoft.MachineLearningServices/workspaces/00000/BulkRuns/run2/logContent
  response:
    body:
      string: '"2023-12-26 10:14:06 +0000      79 promptflow-runtime INFO     [run2]
        Receiving v2 bulk run request c6a28915-6bda-4282-80d4-d981aedb285c: {\"flow_id\":
        \"run2\", \"flow_run_id\": \"run2\", \"flow_source\": {\"flow_source_type\":
        1, \"flow_source_info\": {\"snapshot_id\": \"f29cc6c7-8cd6-4330-9194-d8818a21f8d8\"},
        \"flow_dag_file\": \"flow.dag.yaml\"}, \"log_path\": \"https://promptfloweast4063704120.blob.core.windows.net/azureml/ExperimentRun/dcid.run2/logs/azureml/executionlogs.txt?sv=2019-07-07&sr=b&sig=**data_scrubbed**&skoid=55b92eba-d7c7-4afd-ab76-7bb1cd345283&sktid=00000000-0000-0000-0000-000000000000&skt=2023-12-26T09%3A24%3A53Z&ske=2023-12-27T17%3A34%3A53Z&sks=b&skv=2019-07-07&st=2023-12-26T10%3A04%3A05Z&se=2023-12-26T18%3A14%3A05Z&sp=rcw\",
        \"app_insights_instrumentation_key\": \"InstrumentationKey=**data_scrubbed**;IngestionEndpoint=https://eastus-6.in.applicationinsights.azure.com/;LiveEndpoint=https://eastus.livediagnostics.monitor.azure.com/\",
        \"data_inputs\": {\"run.outputs\": \"azureml:/subscriptions/00000000-0000-0000-0000-000000000000/resourceGroups/00000/providers/Microsoft.MachineLearningServices/workspaces/00000/data/azureml_run1_output_data_flow_outputs/versions/1\"},
        \"inputs_mapping\": {\"number\": \"${run.outputs.output}\"}, \"azure_storage_setting\":
        {\"azure_storage_mode\": 1, \"storage_account_name\": \"promptfloweast4063704120\",
        \"blob_container_name\": \"azureml-blobstore-3e123da1-f9a5-4c91-9234-8d9ffbb39ff5\",
        \"flow_artifacts_root_path\": \"promptflow/PromptFlowArtifacts/run2\", \"blob_container_sas_token\":
        \"?sv=2019-07-07&sr=c&sig=**data_scrubbed**&skoid=55b92eba-d7c7-4afd-ab76-7bb1cd345283&sktid=00000000-0000-0000-0000-000000000000&skt=2023-12-26T10%3A14%3A06Z&ske=2024-01-02T10%3A14%3A06Z&sks=b&skv=2019-07-07&se=2024-01-02T10%3A14%3A06Z&sp=racwl\",
        \"output_datastore_name\": \"workspaceblobstore\"}}\n2023-12-26 10:14:06 +0000      79
        promptflow-runtime INFO     Runtime version: 20231204.v4. PromptFlow version:
        1.2.0rc1\n2023-12-26 10:14:06 +0000      79 promptflow-runtime INFO     Updating
        run2 to Status.Preparing...\n2023-12-26 10:14:06 +0000      79 promptflow-runtime
        INFO     Downloading snapshot to /mnt/host/service/app/39571/requests/run2\n2023-12-26
        10:14:06 +0000      79 promptflow-runtime INFO     Get snapshot sas url for
        f29cc6c7-8cd6-4330-9194-d8818a21f8d8...\n2023-12-26 10:14:13 +0000      79
        promptflow-runtime INFO     Downloading snapshot f29cc6c7-8cd6-4330-9194-d8818a21f8d8
        from uri https://promptfloweast4063704120.blob.core.windows.net/snapshotzips/promptflow-eastus:3e123da1-f9a5-4c91-9234-8d9ffbb39ff5:snapshotzip/f29cc6c7-8cd6-4330-9194-d8818a21f8d8.zip...\n2023-12-26
        10:14:13 +0000      79 promptflow-runtime INFO     Downloaded file /mnt/host/service/app/39571/requests/run2/f29cc6c7-8cd6-4330-9194-d8818a21f8d8.zip
        with size 515 for snapshot f29cc6c7-8cd6-4330-9194-d8818a21f8d8.\n2023-12-26
        10:14:13 +0000      79 promptflow-runtime INFO     Download snapshot f29cc6c7-8cd6-4330-9194-d8818a21f8d8
        completed.\n2023-12-26 10:14:13 +0000      79 promptflow-runtime INFO     Successfully
        download snapshot to /mnt/host/service/app/39571/requests/run2\n2023-12-26
        10:14:13 +0000      79 promptflow-runtime INFO     About to execute a python
        flow.\n2023-12-26 10:14:13 +0000      79 promptflow-runtime INFO     Use spawn
        method to start child process.\n2023-12-26 10:14:13 +0000      79 promptflow-runtime
        INFO     Starting to check process 52847 status for run run2\n2023-12-26 10:14:13
        +0000      79 promptflow-runtime INFO     Start checking run status for run
        run2\n2023-12-26 10:14:17 +0000   52847 promptflow-runtime INFO     [79--52847]
        Start processing flowV2......\n2023-12-26 10:14:17 +0000   52847 promptflow-runtime
        INFO     Runtime version: 20231204.v4. PromptFlow version: 1.2.0rc1\n2023-12-26
        10:14:17 +0000   52847 promptflow-runtime INFO     Setting mlflow tracking
        uri...\n2023-12-26 10:14:17 +0000   52847 promptflow-runtime INFO     Validating
        ''AzureML Data Scientist'' user authentication...\n2023-12-26 10:14:17 +0000   52847
        promptflow-runtime INFO     Successfully validated ''AzureML Data Scientist''
        user authentication.\n2023-12-26 10:14:17 +0000   52847 promptflow-runtime
        INFO     Using AzureMLRunStorageV2\n2023-12-26 10:14:18 +0000   52847 promptflow-runtime
        INFO     Setting mlflow tracking uri to ''azureml://eastus.api.azureml.ms/mlflow/v1.0/subscriptions/00000000-0000-0000-0000-000000000000/resourceGroups/00000/providers/Microsoft.MachineLearningServices/workspaces/promptflow-eastus''\n2023-12-26
        10:14:18 +0000   52847 promptflow-runtime INFO     Initialized blob service
        client for AzureMLRunTracker.\n2023-12-26 10:14:18 +0000   52847 promptflow-runtime
        INFO     Setting mlflow tracking uri to ''azureml://eastus.api.azureml.ms/mlflow/v1.0/subscriptions/00000000-0000-0000-0000-000000000000/resourceGroups/00000/providers/Microsoft.MachineLearningServices/workspaces/promptflow-eastus''\n2023-12-26
        10:14:18 +0000   52847 promptflow-runtime INFO     Resolve data from url finished
        in 0.6174588957801461 seconds\n2023-12-26 10:14:18 +0000   52847 promptflow-runtime
        INFO     Starting the aml run ''run2''...\n2023-12-26 10:14:19 +0000   52847
        execution.bulk     INFO     Using fork, process count: 10\n2023-12-26 10:14:19
        +0000   52899 execution.bulk     INFO     Process 52899 started.\n2023-12-26
        10:14:19 +0000   52907 execution.bulk     INFO     Process 52907 started.\n2023-12-26
        10:14:19 +0000   52913 execution.bulk     INFO     Process 52913 started.\n2023-12-26
        10:14:19 +0000   52918 execution.bulk     INFO     Process 52918 started.\n2023-12-26
        10:14:19 +0000   52847 execution.bulk     INFO     Process name: ForkProcess-106:2,
        Process id: 52899, Line number: 0 start execution.\n2023-12-26 10:14:19 +0000   52924
        execution.bulk     INFO     Process 52924 started.\n2023-12-26 10:14:19 +0000   52913
        execution          ERROR    Node mod_three in line 4 failed. Exception: Execution
        failure in ''mod_three'': (Exception) cannot mod 3!.\nTraceback (most recent
        call last):\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/_core/flow_execution_context.py\",
        line 185, in _invoke_tool_with_timer\n    return f(**kwargs)\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/_core/tool.py\",
        line 106, in decorated_tool\n    output = func(*args, **kwargs)\n  File \"/mnt/host/service/app/39571/requests/run2/mod_three.py\",
        line 7, in mod_three\n    raise Exception(\"cannot mod 3!\")\nException: cannot
        mod 3!\n\nThe above exception was the direct cause of the following exception:\n\nTraceback
        (most recent call last):\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/_core/flow_execution_context.py\",
        line 89, in invoke_tool\n    result = self._invoke_tool_with_timer(node, f,
        kwargs)\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/_core/flow_execution_context.py\",
        line 196, in _invoke_tool_with_timer\n    raise ToolExecutionError(node_name=node_name,
        module=module) from e\npromptflow._core._errors.ToolExecutionError: Execution
        failure in ''mod_three'': (Exception) cannot mod 3!\n2023-12-26 10:14:19 +0000   52847
        execution.bulk     INFO     Process name: ForkProcess-106:3, Process id: 52907,
        Line number: 2 start execution.\n2023-12-26 10:14:19 +0000   52930 execution.bulk     INFO     Process
        52930 started.\n2023-12-26 10:14:19 +0000   52913 execution          ERROR    Execution
        of one node has failed. Cancelling all running nodes: mod_three.\n2023-12-26
        10:14:19 +0000   52847 execution.bulk     INFO     Process name: ForkProcess-106:6,
        Process id: 52913, Line number: 4 start execution.\n2023-12-26 10:14:19 +0000   52928
        execution.bulk     INFO     Process 52928 started.\n2023-12-26 10:14:19 +0000   52847
        execution.bulk     INFO     Process name: ForkProcess-106:7, Process id: 52918,
        Line number: 6 start execution.\n2023-12-26 10:14:19 +0000   52847 execution.bulk     INFO     Process
        name: ForkProcess-106:4, Process id: 52924, Line number: 8 start execution.\n2023-12-26
        10:14:19 +0000   52924 execution          ERROR    Node mod_three in line
        8 failed. Exception: Execution failure in ''mod_three'': (Exception) cannot
        mod 3!.\nTraceback (most recent call last):\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/_core/flow_execution_context.py\",
        line 185, in _invoke_tool_with_timer\n    return f(**kwargs)\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/_core/tool.py\",
        line 106, in decorated_tool\n    output = func(*args, **kwargs)\n  File \"/mnt/host/service/app/39571/requests/run2/mod_three.py\",
        line 7, in mod_three\n    raise Exception(\"cannot mod 3!\")\nException: cannot
        mod 3!\n\nThe above exception was the direct cause of the following exception:\n\nTraceback
        (most recent call last):\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/_core/flow_execution_context.py\",
        line 89, in invoke_tool\n    result = self._invoke_tool_with_timer(node, f,
        kwargs)\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/_core/flow_execution_context.py\",
        line 196, in _invoke_tool_with_timer\n    raise ToolExecutionError(node_name=node_name,
        module=module) from e\npromptflow._core._errors.ToolExecutionError: Execution
        failure in ''mod_three'': (Exception) cannot mod 3!\n2023-12-26 10:14:19 +0000   52945
        execution.bulk     INFO     Process 52945 started.\n2023-12-26 10:14:19 +0000   52951
        execution.bulk     INFO     Process 52951 started.\n2023-12-26 10:14:19 +0000   52930
        execution          ERROR    Node mod_three in line 10 failed. Exception: Execution
        failure in ''mod_three'': (Exception) cannot mod 3!.\nTraceback (most recent
        call last):\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/_core/flow_execution_context.py\",
        line 185, in _invoke_tool_with_timer\n    return f(**kwargs)\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/_core/tool.py\",
        line 106, in decorated_tool\n    output = func(*args, **kwargs)\n  File \"/mnt/host/service/app/39571/requests/run2/mod_three.py\",
        line 7, in mod_three\n    raise Exception(\"cannot mod 3!\")\nException: cannot
        mod 3!\n\nThe above exception was the direct cause of the following exception:\n\nTraceback
        (most recent call last):\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/_core/flow_execution_context.py\",
        line 89, in invoke_tool\n    result = self._invoke_tool_with_timer(node, f,
        kwargs)\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/_core/flow_execution_context.py\",
        line 196, in _invoke_tool_with_timer\n    raise ToolExecutionError(node_name=node_name,
        module=module) from e\npromptflow._core._errors.ToolExecutionError: Execution
        failure in ''mod_three'': (Exception) cannot mod 3!\n2023-12-26 10:14:19 +0000   52924
        execution          ERROR    Execution of one node has failed. Cancelling all
        running nodes: mod_three.\n2023-12-26 10:14:19 +0000   52847 execution.bulk     INFO     Process
        name: ForkProcess-106:5, Process id: 52930, Line number: 10 start execution.\n2023-12-26
        10:14:19 +0000   52930 execution          ERROR    Execution of one node has
        failed. Cancelling all running nodes: mod_three.\n2023-12-26 10:14:19 +0000   52847
        execution.bulk     INFO     Process name: ForkProcess-106:9, Process id: 52928,
        Line number: 12 start execution.\n2023-12-26 10:14:19 +0000   52847 execution.bulk     INFO     Process
        name: ForkProcess-106:11, Process id: 52945, Line number: 14 start execution.\n2023-12-26
        10:14:19 +0000   52847 execution.bulk     INFO     Process name: ForkProcess-106:8,
        Process id: 52951, Line number: 16 start execution.\n2023-12-26 10:14:19 +0000   52907
        execution          ERROR    Node mod_three in line 2 failed. Exception: Execution
        failure in ''mod_three'': (Exception) cannot mod 3!.\nTraceback (most recent
        call last):\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/_core/flow_execution_context.py\",
        line 185, in _invoke_tool_with_timer\n    return f(**kwargs)\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/_core/tool.py\",
        line 106, in decorated_tool\n    output = func(*args, **kwargs)\n  File \"/mnt/host/service/app/39571/requests/run2/mod_three.py\",
        line 7, in mod_three\n    raise Exception(\"cannot mod 3!\")\nException: cannot
        mod 3!\n\nThe above exception was the direct cause of the following exception:\n\nTraceback
        (most recent call last):\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/_core/flow_execution_context.py\",
        line 89, in invoke_tool\n    result = self._invoke_tool_with_timer(node, f,
        kwargs)\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/_core/flow_execution_context.py\",
        line 196, in _invoke_tool_with_timer\n    raise ToolExecutionError(node_name=node_name,
        module=module) from e\npromptflow._core._errors.ToolExecutionError: Execution
        failure in ''mod_three'': (Exception) cannot mod 3!\n2023-12-26 10:14:19 +0000   52907
        execution          ERROR    Execution of one node has failed. Cancelling all
        running nodes: mod_three.\n2023-12-26 10:14:19 +0000   52847 execution.bulk     INFO     Process
        name: ForkProcess-106:2, Process id: 52899, Line number: 0 completed.\n2023-12-26
        10:14:19 +0000   52847 execution.bulk     INFO     Finished 1 / 10 lines.\n2023-12-26
        10:14:19 +0000   52847 execution.bulk     INFO     Process name: ForkProcess-106:4,
        Process id: 52924, Line number: 8 completed.\n2023-12-26 10:14:19 +0000   52847
        execution.bulk     INFO     Process name: ForkProcess-106:7, Process id: 52918,
        Line number: 6 completed.\n2023-12-26 10:14:19 +0000   52847 execution.bulk     INFO     Average
        execution time for completed lines: 0.46 seconds. Estimated time for incomplete
        lines: 4.14 seconds.\n2023-12-26 10:14:19 +0000   52847 execution.bulk     INFO     Finished
        3 / 10 lines.\n2023-12-26 10:14:19 +0000   52847 execution.bulk     INFO     Process
        name: ForkProcess-106:9, Process id: 52928, Line number: 12 completed.\n2023-12-26
        10:14:19 +0000   52847 execution.bulk     INFO     Process name: ForkProcess-106:5,
        Process id: 52930, Line number: 10 completed.\n2023-12-26 10:14:19 +0000   52847
        execution.bulk     INFO     Process name: ForkProcess-106:8, Process id: 52951,
        Line number: 16 completed.\n2023-12-26 10:14:19 +0000   52847 execution.bulk     INFO     Process
        name: ForkProcess-106:11, Process id: 52945, Line number: 14 completed.\n2023-12-26
        10:14:19 +0000   52847 execution.bulk     INFO     Finished 7 / 10 lines.\n2023-12-26
        10:14:19 +0000   52847 execution.bulk     INFO     Process name: ForkProcess-106:6,
        Process id: 52913, Line number: 4 completed.\n2023-12-26 10:14:19 +0000   52847
        execution.bulk     INFO     Process name: ForkProcess-106:2, Process id: 52899,
        Line number: 18 start execution.\n2023-12-26 10:14:19 +0000   52847 execution.bulk     INFO     Process
        name: ForkProcess-106:3, Process id: 52907, Line number: 2 completed.\n2023-12-26
        10:14:19 +0000   52847 execution.bulk     INFO     Average execution time
        for completed lines: 0.17 seconds. Estimated time for incomplete lines: 1.19
        seconds.\n2023-12-26 10:14:19 +0000   52847 execution.bulk     INFO     Finished
        9 / 10 lines.\n2023-12-26 10:14:19 +0000   52847 execution.bulk     INFO     Finished
        9 / 10 lines.\n2023-12-26 10:14:19 +0000   52847 execution.bulk     INFO     Finished
        9 / 10 lines.\n2023-12-26 10:14:19 +0000   52847 execution.bulk     INFO     Finished
        9 / 10 lines.\n2023-12-26 10:14:19 +0000   52847 execution.bulk     INFO     Average
        execution time for completed lines: 0.08 seconds. Estimated time for incomplete
        lines: 0.24 seconds.\n2023-12-26 10:14:19 +0000   52847 execution.bulk     INFO     Finished
        9 / 10 lines.\n2023-12-26 10:14:19 +0000   52847 execution.bulk     INFO     Finished
        9 / 10 lines.\n2023-12-26 10:14:19 +0000   52847 execution.bulk     INFO     Average
        execution time for completed lines: 0.06 seconds. Estimated time for incomplete
        lines: 0.06 seconds.\n2023-12-26 10:14:19 +0000   52847 execution.bulk     INFO     Average
        execution time for completed lines: 0.07 seconds. Estimated time for incomplete
        lines: 0.07 seconds.\n2023-12-26 10:14:20 +0000   52847 execution.bulk     INFO     Process
        name: ForkProcess-106:2, Process id: 52899, Line number: 18 completed.\n2023-12-26
        10:14:20 +0000   52847 execution.bulk     INFO     Average execution time
        for completed lines: 0.07 seconds. Estimated time for incomplete lines: 0.07
        seconds.\n2023-12-26 10:14:20 +0000   52847 execution.bulk     INFO     Average
        execution time for completed lines: 0.07 seconds. Estimated time for incomplete
        lines: 0.07 seconds.\n2023-12-26 10:14:20 +0000   52847 execution.bulk     INFO     Average
        execution time for completed lines: 0.07 seconds. Estimated time for incomplete
        lines: 0.07 seconds.\n2023-12-26 10:14:20 +0000   52847 execution.bulk     INFO     Average
        execution time for completed lines: 0.08 seconds. Estimated time for incomplete
        lines: 0.08 seconds.\n2023-12-26 10:14:20 +0000   52847 execution.bulk     INFO     Finished
        10 / 10 lines.\n2023-12-26 10:14:20 +0000   52847 execution.bulk     INFO     Average
        execution time for completed lines: 0.08 seconds. Estimated time for incomplete
        lines: 0.0 seconds.\n2023-12-26 10:14:50 +0000   52847 execution          ERROR    6/10
        flow run failed, indexes: [1,2,4,5,7,8], exception of index 1: Execution failure
        in ''mod_three'': (Exception) cannot mod 3!\n2023-12-26 10:14:51 +0000   52847
        execution.bulk     INFO     Upload status summary metrics for run run2 finished
        in 1.3417330728843808 seconds\n2023-12-26 10:14:51 +0000   52847 promptflow-runtime
        INFO     Successfully write run properties {\"azureml.promptflow.total_tokens\":
        0, \"_azureml.evaluate_artifacts\": \"[{\\\"path\\\": \\\"instance_results.jsonl\\\",
        \\\"type\\\": \\\"table\\\"}]\"} with run id ''run2''\n2023-12-26 10:14:51
        +0000   52847 execution.bulk     INFO     Upload RH properties for run run2
        finished in 0.08251555310562253 seconds\n2023-12-26 10:14:51 +0000   52847
        promptflow-runtime INFO     Creating unregistered output Asset for Run run2...\n2023-12-26
        10:14:52 +0000   52847 promptflow-runtime INFO     Created debug_info Asset:
        azureml://locations/eastus/workspaces/00000/data/azureml_run2_output_data_debug_info/versions/1\n2023-12-26
        10:14:52 +0000   52847 promptflow-runtime INFO     Creating unregistered output
        Asset for Run run2...\n2023-12-26 10:14:52 +0000   52847 promptflow-runtime
        INFO     Created flow_outputs output Asset: azureml://locations/eastus/workspaces/00000/data/azureml_run2_output_data_flow_outputs/versions/1\n2023-12-26
        10:14:52 +0000   52847 promptflow-runtime INFO     Creating Artifact for Run
        run2...\n2023-12-26 10:14:52 +0000   52847 promptflow-runtime INFO     Created
        instance_results.jsonl Artifact.\n2023-12-26 10:14:52 +0000   52847 promptflow-runtime
        INFO     Patching run2...\n2023-12-26 10:14:52 +0000   52847 promptflow-runtime
        WARNING  [run2] Run failed. Execution stackTrace: Traceback (most recent call
        last):\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/_core/flow_execution_context.py\",
        line 185, in _invoke_tool_with_timer\n    return f(**kwargs)\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/_core/tool.py\",
        line 106, in decorated_tool\n    output = func(*args, **kwargs)\n  [REDACTED:
        External StackTrace]\n\nThe above exception was the direct cause of the following
        exception:\n\nTraceback (most recent call last):\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/executor/flow_executor.py\",
        line 804, in _exec\n    output, nodes_outputs = self._traverse_nodes(inputs,
        context)\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/executor/flow_executor.py\",
        line 890, in _traverse_nodes\n    nodes_outputs, bypassed_nodes = self._submit_to_scheduler(context,
        inputs, batch_nodes)\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/executor/flow_executor.py\",
        line 910, in _submit_to_scheduler\n    return FlowNodesScheduler(self._tools_manager,
        inputs, nodes, self._node_concurrency, context).execute()\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/executor/_flow_nodes_scheduler.py\",
        line 69, in execute\n    raise e\n  File \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/executor/_flow_nodes_scheduler.py\",
        line 58, in execute\n    self._dag_manager.complete_nodes(self._collect_outputs(completed_futures))\n  File
        \"/azureml-envs/prompt-flow/runtime/lib/python3.10/site-packages/promptflow/executor/_flow_nodes_scheduler.py\",
        line 90, in _collect_outputs\n    each_node_result = each_future.result()\n  [REDACTED:
        External StackTrace]\n\n2023-12-26 10:14:52 +0000   52847 promptflow-runtime
        INFO     Ending the aml run ''run2'' with status ''Completed''...\n2023-12-26
        10:14:54 +0000      79 promptflow-runtime INFO     Process 52847 finished\n2023-12-26
        10:14:54 +0000      79 promptflow-runtime INFO     [79] Child process finished!\n2023-12-26
        10:14:54 +0000      79 promptflow-runtime INFO     [run2] End processing bulk
        run\n2023-12-26 10:14:54 +0000      79 promptflow-runtime INFO     Cleanup
        working dir /mnt/host/service/app/39571/requests/run2 for bulk run\n"'
    headers:
      connection:
      - keep-alive
      content-length:
      - '22577'
      content-type:
      - application/json; charset=utf-8
      strict-transport-security:
      - max-age=15724800; includeSubDomains; preload
      transfer-encoding:
      - chunked
      vary:
      - Accept-Encoding
      x-content-type-options:
      - nosniff
      x-request-time:
      - '0.607'
    status:
      code: 200
      message: OK
version: 1
