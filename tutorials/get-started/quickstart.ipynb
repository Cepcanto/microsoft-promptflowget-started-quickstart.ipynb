{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get-started (Community version)\n",
    "\n",
    "**Requirements** - In order to benefit from this tutorial, you will need:\n",
    "- A basic understanding of Machine Learning\n",
    "- A python environment\n",
    "- Installed PromptFlow SDK\n",
    "\n",
    "**Learning Objectives** - By the end of this tutorial, you should be able to:\n",
    "- Create and develop a new promptflow batch run\n",
    "- Evaluate the batch run with a evaluation flow\n",
    "- Deploy the flow to a remote endpoint.\n",
    "\n",
    "**Motivations** - This guide will walk you through the main user journey of prompt flow code-first experience. You will learn how to create and develop your first prompt flow, test and evaluate it, then deploy it to production."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 0: Install promptflow sdk\n",
    "```bash\n",
    "pip install promptflow-sdk --extra-index-url https://azuremlsdktestpypi.azureedge.net/promptflow/\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Create necessary connections\n",
    "Connection helps securely store and manage secret keys or other sensitive credentials required for interacting with LLM and other external tools for example Azure Content Safety.\n",
    "\n",
    "In this notebook, we will use flow `web-classification` which uses connection `azure_open_ai_connection` inside, we need to set up the connection if we haven't added it before. After created, it's stored in local db and can be used in any flow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import promptflow as pf\n",
    "from promptflow.sdk.entities import AzureOpenAIConnection, BulkInputs, EvalInputs\n",
    "\n",
    "# client can help manage your runs and connections.\n",
    "client = pf.PFClient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "connection = AzureOpenAIConnection(\n",
    "    name=\"azure_open_ai_connection\",\n",
    "    type=\"AzureOpenAI\",\n",
    "    api_key=\"<test_key>\",\n",
    "    api_base=\"<test_base>\",\n",
    "    api_type=\"azure\",\n",
    "    api_version=\"<test_version>\",\n",
    ")\n",
    "\n",
    "client.connections.create_or_update(connection)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Create and develop a new batch run\n",
    "\n",
    "`web-classification` is a flow demonstrating multi-class classification with LLM. Given an url, it will classify the url into one web category with just a few shots, simple summarization and classification prompts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set flow path and bulk inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flow_path = \"../../flows/standard/web-classification\"\n",
    "bulk_inputs = BulkInputs(\n",
    "    data=\"../../flows/standard/web-classification/data.jsonl\",  # path to the data file\n",
    "    inputs_mapping={\"url\": \"${data.url}\"},  # map the url field from the data to the url input of the flow\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run bulk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the first variant of the summarize_text_content node.\n",
    "# if \"node_variant\" is not specified in \"run_bulk\" function, the default variant will be used.\n",
    "node_variant=\"${summarize_text_content.variant_1}\"\n",
    "\n",
    "run = pf.run_bulk(\n",
    "    flow=flow_path,\n",
    "    inputs=bulk_inputs,\n",
    "    node_variant=node_variant,  \n",
    ")\n",
    "\n",
    "# this name can be used for later evaluation run inputs\n",
    "bulk_run_name = run.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pf.stream(run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pf.show_details([run])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pf.visualize([run])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Evaluate your bulk flow run\n",
    "Then you can use an evaluation method to evaluate your flow. The evaluation methods are also flows which use Python or LLM etc., to calculate metrics like accuracy, relevance score.\n",
    "\n",
    "In this notebook, we use `classification-accuracy-eval` flow to evaluate. This is a flow illustrating how to evaluate the performance of a classification system. It involves comparing each prediction to the groundtruth and assigns a \"Correct\" or \"Incorrect\" grade, and aggregating the results to produce metrics such as accuracy, which reflects how good the system is at classifying the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_flow_path = \"../../flows/evaluate/classification-accuracy-eval\"\n",
    "eval_inputs = EvalInputs(\n",
    "    data=\"../../flows/standard/web-classification/data.jsonl\",  # path to the data file\n",
    "    inputs_mapping={\"groundtruth\": \"${data.answer}\",\"prediction\": \"${variant.outputs.category}\"},  # map the url field from the data to the url input of the flow\n",
    "    variant=bulk_run_name,  # use the bulk run name as the variant\n",
    ")\n",
    "\n",
    "eval_run = pf.run_eval(\n",
    "    flow=eval_flow_path,\n",
    "    inputs=eval_inputs,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pf.stream(eval_run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pf.show_details(eval_run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pf.show_metrics(eval_run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pf.visualize([run, eval_run])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Deploy the flow (WIP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
